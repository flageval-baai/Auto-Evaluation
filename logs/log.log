nohup: ignoring input
INFO:     Started server process [2382586]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:9000 (Press CTRL+C to quit)
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     172.31.125.164:40374 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.53.132:8000/v1/chat/completions' model='RoboBrain2.0-7B' eval_model='online_api_1106_EV_0' base_model_name='RoboBrain2.0-7B' tokenizer='' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://172.24.53.132:8000/v1/chat/completions' model='RoboBrain2.0-7B' eval_model='online_api_1106_EV_0' base_model_name='RoboBrain2.0-7B' tokenizer='' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
EmbodiedVerse ['ERQA', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'online_api_1106_EV_0', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.53.132:8000/v1/chat/completions', 'online_model_name': 'RoboBrain2.0-7B', 'base_model_name': 'RoboBrain2.0-7B', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['ERQA', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'online_api_1106_EV_0', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.53.132:8000/v1/chat/completions', 'online_model_name': 'RoboBrain2.0-7B', 'base_model_name': 'RoboBrain2.0-7B', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['ERQA', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28344,"evaluationId":1270}
{'id': 28344, 'evaluationId': 1270}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1270, 'batch_id': 28344, 'datasize': 22301}
mysql connect
insert success
INFO:     172.31.125.164:54516 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='https://spark-api-open.xf-yun.com/v1/chat/completions' model='4.0Ultra' eval_model='online_api_1106_llm' base_model_name='4.0Ultra' tokenizer='' api_key='7090834e3d9bb24a6ee543651d8fe6b3:NTI2ZmQ1MjU1OTUzY2Y3MTE0MWVmMGEx' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': ''}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'online_api_1106_llm', 'online_model_name': '4.0Ultra', 'base_model_name': '4.0Ultra', 'online_url': 'https://spark-api-open.xf-yun.com/v1/chat/completions', 'online_api_key': '7090834e3d9bb24a6ee543651d8fe6b3:NTI2ZmQ1MjU1OTUzY2Y3MTE0MWVmMGEx', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28345, 'evaluationId': 1271}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1271, 'batch_id': 28345, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1271, 'batch_id': 28345, 'datasize': 14920}
mysql connect
insert success
INFO:     172.31.125.164:45798 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     106.120.25.242:20077 - "GET / HTTP/1.1" 404 Not Found
INFO:     106.120.25.242:20087 - "GET /evaluation HTTP/1.1" 405 Method Not Allowed
WARNING:  Invalid HTTP request received.
nohup: ignoring input
INFO:     Started server process [2413806]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:9090 (Press CTRL+C to quit)
online_api_1106_EV_0 28344 81810a49-9b63-4c5c-a9ae-eb0cc103a07e
submit stop batch 28344
[{'status': 'S', 'dataset': 'ERQA', 'accuracy': 37.5, 'rawDetails': {'Other': 21.43, 'Pointing': 32.35, 'accuracy': 37.5, 'Task Reasoning': 55.26, 'average_tokens': 1259.145, 'Action Reasoning': 37.5, 'State Estimation': 40.0, 'Spatial Reasoning': 30.95, 'Multi-view Reasoning': 35.14, 'Trajectory Reasoning': 40.91, 'average_prompt_tokens': 1227.3575, 'average_completion_tokens': 31.7875}}, {'status': 'S', 'dataset': 'Where2Place', 'accuracy': 59.56, 'rawDetails': {'avg': {'num': 100, 'score': 59.55612511671335, 'accuracy': 59.56}, 'seen': {'num': 70, 'score': 44.13287581699347, 'accuracy': 63.05}, 'unseen': {'num': 30, 'score': 15.423249299719888, 'accuracy': 51.41}, 'accuracy': 59.56, 'average_tokens': 714.31, 'average_prompt_tokens': 595.78, 'average_completion_tokens': 118.53}}, {'status': 'S', 'dataset': 'Blink', 'accuracy': 57.8, 'rawDetails': {'Counting': 65.0, 'accuracy': 57.8, 'Relative Depth': 87.1, 'average_tokens': 1331.0650289017342, 'Spatial Relation': 83.22, 'Multi-view Reasoning': 8.27, 'Visual Correspondence': 48.84, 'average_prompt_tokens': 1313.1604046242774, 'average_completion_tokens': 17.904624277456648}}, {'status': 'S', 'dataset': 'CVBench', 'accuracy': 85.63, 'rawDetails': {'accuracy': 85.63, 'accuracy_2d': 78.34, 'accuracy_3d': 92.92, 'average_tokens': 947.2300985595148, 'accuracy_2d_ade': 73.46, 'accuracy_2d_coco': 83.23, 'accuracy_3d_omni': 92.92, 'average_prompt_tokens': 936.2300985595148, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'EmbspatialBench', 'accuracy': 76.1, 'rawDetails': {'accuracy': 76.1, 'distance': 62.77, 'direction': 82.7, 'average_tokens': 786.1824175824175, 'average_prompt_tokens': 775.1824175824175, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'SAT', 'accuracy': 75.33, 'rawDetails': {'accuracy': 75.33, 'goal_aim': 91.18, 'perspective': 57.58, 'ego_movement': 100.0, 'obj_movement': 69.57, 'action_conseq': 64.86, 'average_tokens': 10010.733333333334, 'average_prompt_tokens': 9934.286666666669, 'average_completion_tokens': 76.44666666666667}}, {'status': 'S', 'dataset': 'VSI-Bench', 'accuracy': 36.68, 'rawDetails': {'avg': {'num': 392, 'correct': 143.80000000000004, 'accuracy': 36.68}, 'accuracy': 36.68, 'average_tokens': 6431.90306122449, 'route_planning': {'num': 49, 'correct': 21, 'accuracy': 42.86}, 'object_counting': {'num': 49, 'correct': 21.0, 'accuracy': 42.86}, 'object_abs_distance': {'num': 47, 'correct': 12.500000000000002, 'accuracy': 26.6}, 'object_rel_distance': {'num': 50, 'correct': 16, 'accuracy': 32.0}, 'obj_appearance_order': {'num': 49, 'correct': 9, 'accuracy': 18.37}, 'room_size_estimation': {'num': 50, 'correct': 14.4, 'accuracy': 28.8}, 'average_prompt_tokens': 6417.614795918367, 'object_size_estimation': {'num': 48, 'correct': 26.899999999999995, 'accuracy': 56.04}, 'average_completion_tokens': 14.28826530612245, 'object_rel_direction_easy': {'num': 10, 'correct': 4, 'accuracy': 40.0}, 'object_rel_direction_hard': {'num': 13, 'correct': 7, 'accuracy': 53.85}, 'object_rel_direction_medium': {'num': 27, 'correct': 12, 'accuracy': 44.44}}}, {'status': 'S', 'dataset': 'RoboSpatial-Home', 'accuracy': 59.2576, 'rawDetails': {'accuracy': 59.2576, 'results_v2': {'context': {'total': 122, 'accuracy': 49.5096, 'num_correct': 60.40169934640524}, 'compatibility': {'total': 105, 'accuracy': 54.2857, 'num_correct': 57}, 'configuration': {'total': 123, 'accuracy': 73.1707, 'num_correct': 90}}, 'results_ori': {'context': {'total': 122, 'accuracy': 0.0, 'num_correct': 0, 'illformed_responses': 0}, 'compatibility': {'total': 105, 'accuracy': 54.2857, 'num_correct': 57, 'illformed_responses': 0}, 'configuration': {'total': 123, 'accuracy': 73.1707, 'num_correct': 90, 'illformed_responses': 0}}, 'accuracy_ori': 42.0, 'average_tokens': 3731.548571428571, 'average_prompt_tokens': 3657.3914285714286, 'average_completion_tokens': 74.15714285714286}}, {'status': 'R', 'dataset': 'All-Angles Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'EgoPlan-Bench2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'EmbodiedVerse-Open-Sampled', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.17.239:56224 - "POST /stop_evaluation HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [2431628]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 9999): address already in use
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
nohup: ignoring input
INFO:     Started server process [2436797]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
online_api_1106_llm 28345 af733db7-1e2c-4485-8951-2014d4261f53
submit stop batch 28345
[{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     219.143.147.2:52566 - "POST /stop_evaluation HTTP/1.1" 200 OK
[{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.55.16:20920 - "POST /resume_evaluation HTTP/1.1" 200 OK
INFO:     121.199.5.239:38758 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.5.239:39166 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.5.239:39168 - "GET /nmaplowercheck1762435330 HTTP/1.1" 404 Not Found
INFO:     121.199.5.239:39172 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     121.199.5.239:39174 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     121.199.5.239:39176 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.199.5.239:39708 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.5.239:39716 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.46:59454 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     121.41.166.50:40156 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.41.166.50:40166 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     205.210.31.253:63500 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.225:58362 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.199.163.118:46192 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.118:46302 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     121.199.163.118:46300 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.118:46292 - "GET /nmaplowercheck1762572952 HTTP/1.1" 404 Not Found
INFO:     121.199.163.118:46306 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     121.199.163.118:46310 - "GET /HNAP1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.199.163.118:46610 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.118:46616 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.183:58902 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.215:61698 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     113.141.95.205:33232 - "GET / HTTP/1.1" 404 Not Found
INFO:     125.122.33.108:53450 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.46:62426 - "GET / HTTP/1.1" 404 Not Found
INFO:     39.98.125.168:60348 - "GET / HTTP/1.0" 404 Not Found
INFO:     39.98.125.168:60356 - "GET / HTTP/1.1" 404 Not Found
INFO:     39.98.125.168:60370 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     147.185.132.24:62834 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.108:65016 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     121.43.119.43:50798 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.43.119.43:50806 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
eval_model details status
online_api_1106_EV_0 [{'status': 'S', 'dataset': 'ERQA', 'accuracy': 37.5, 'rawDetails': {'Other': 21.43, 'Pointing': 32.35, 'accuracy': 37.5, 'Task Reasoning': 55.26, 'average_tokens': 1259.145, 'Action Reasoning': 37.5, 'State Estimation': 40.0, 'Spatial Reasoning': 30.95, 'Multi-view Reasoning': 35.14, 'Trajectory Reasoning': 40.91, 'average_prompt_tokens': 1227.3575, 'average_completion_tokens': 31.7875}}, {'status': 'S', 'dataset': 'Where2Place', 'accuracy': 59.56, 'rawDetails': {'avg': {'num': 100, 'score': 59.55612511671335, 'accuracy': 59.56}, 'seen': {'num': 70, 'score': 44.13287581699347, 'accuracy': 63.05}, 'unseen': {'num': 30, 'score': 15.423249299719888, 'accuracy': 51.41}, 'accuracy': 59.56, 'average_tokens': 714.31, 'average_prompt_tokens': 595.78, 'average_completion_tokens': 118.53}}, {'status': 'S', 'dataset': 'Blink', 'accuracy': 57.8, 'rawDetails': {'Counting': 65.0, 'accuracy': 57.8, 'Relative Depth': 87.1, 'average_tokens': 1331.0650289017342, 'Spatial Relation': 83.22, 'Multi-view Reasoning': 8.27, 'Visual Correspondence': 48.84, 'average_prompt_tokens': 1313.1604046242774, 'average_completion_tokens': 17.904624277456648}}, {'status': 'S', 'dataset': 'CVBench', 'accuracy': 85.63, 'rawDetails': {'accuracy': 85.63, 'accuracy_2d': 78.34, 'accuracy_3d': 92.92, 'average_tokens': 947.2300985595148, 'accuracy_2d_ade': 73.46, 'accuracy_2d_coco': 83.23, 'accuracy_3d_omni': 92.92, 'average_prompt_tokens': 936.2300985595148, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'EmbspatialBench', 'accuracy': 76.1, 'rawDetails': {'accuracy': 76.1, 'distance': 62.77, 'direction': 82.7, 'average_tokens': 786.1824175824175, 'average_prompt_tokens': 775.1824175824175, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'SAT', 'accuracy': 75.33, 'rawDetails': {'accuracy': 75.33, 'goal_aim': 91.18, 'perspective': 57.58, 'ego_movement': 100.0, 'obj_movement': 69.57, 'action_conseq': 64.86, 'average_tokens': 10010.733333333334, 'average_prompt_tokens': 9934.286666666669, 'average_completion_tokens': 76.44666666666667}}, {'status': 'S', 'dataset': 'VSI-Bench', 'accuracy': 36.68, 'rawDetails': {'avg': {'num': 392, 'correct': 143.80000000000004, 'accuracy': 36.68}, 'accuracy': 36.68, 'average_tokens': 6431.90306122449, 'route_planning': {'num': 49, 'correct': 21, 'accuracy': 42.86}, 'object_counting': {'num': 49, 'correct': 21.0, 'accuracy': 42.86}, 'object_abs_distance': {'num': 47, 'correct': 12.500000000000002, 'accuracy': 26.6}, 'object_rel_distance': {'num': 50, 'correct': 16, 'accuracy': 32.0}, 'obj_appearance_order': {'num': 49, 'correct': 9, 'accuracy': 18.37}, 'room_size_estimation': {'num': 50, 'correct': 14.4, 'accuracy': 28.8}, 'average_prompt_tokens': 6417.614795918367, 'object_size_estimation': {'num': 48, 'correct': 26.899999999999995, 'accuracy': 56.04}, 'average_completion_tokens': 14.28826530612245, 'object_rel_direction_easy': {'num': 10, 'correct': 4, 'accuracy': 40.0}, 'object_rel_direction_hard': {'num': 13, 'correct': 7, 'accuracy': 53.85}, 'object_rel_direction_medium': {'num': 27, 'correct': 12, 'accuracy': 44.44}}}, {'status': 'S', 'dataset': 'RoboSpatial-Home', 'accuracy': 59.2576, 'rawDetails': {'accuracy': 59.2576, 'results_v2': {'context': {'total': 122, 'accuracy': 49.5096, 'num_correct': 60.40169934640524}, 'compatibility': {'total': 105, 'accuracy': 54.2857, 'num_correct': 57}, 'configuration': {'total': 123, 'accuracy': 73.1707, 'num_correct': 90}}, 'results_ori': {'context': {'total': 122, 'accuracy': 0.0, 'num_correct': 0, 'illformed_responses': 0}, 'compatibility': {'total': 105, 'accuracy': 54.2857, 'num_correct': 57, 'illformed_responses': 0}, 'configuration': {'total': 123, 'accuracy': 73.1707, 'num_correct': 90, 'illformed_responses': 0}}, 'accuracy_ori': 42.0, 'average_tokens': 3731.548571428571, 'average_prompt_tokens': 3657.3914285714286, 'average_completion_tokens': 74.15714285714286}}, {'status': 'S', 'dataset': 'All-Angles Bench', 'accuracy': 47.89, 'rawDetails': {'accuracy': 47.89, 'counting': 41.83, 'manipulation': 40.76, 'average_tokens': 25727.89212007505, 'relative_distance': 54.05, 'relative_direction': 27.84, 'average_prompt_tokens': 25716.89212007505, 'camera_pose_estimation': 46.02, 'attribute_identification': 72.06, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'EgoPlan-Bench2', 'accuracy': 32.63, 'rawDetails': {'Work': 26.98, 'Hobbies': 30.85, 'accuracy': 32.63, 'Daily life': 38.72, 'Recreation': 33.33, 'average_tokens': 26033.7441332324, 'average_prompt_tokens': 26022.7441332324, 'average_completion_tokens': 11.0}}, {'status': 'S', 'dataset': 'EmbodiedVerse-Open-Sampled', 'accuracy': 40.01, 'rawDetails': {'Dynamic': 31.5, 'Counting': 31.0, 'Planning': 24.24, 'accuracy': 40.01, 'Navigation': 31.25, 'Perception': 39.96, 'Prediction': 29.8, 'Trajectory': 33.51, 'Relative shape': 42.68, 'average_tokens': 11150.71596474045, 'Size estimation': 33.33, 'Depth estimation': 51.4, 'Visual Grounding': 50.5, 'Future prediction': 17.54, 'Relative distance': 59.0, 'Spatial Reasoning': 46.18, 'Goal Decomposition': 22.0, 'Relative direction': 64.5, 'Multi-view matching': 34.5, 'average_prompt_tokens': 11126.962291870715, 'average_completion_tokens': 23.753672869735553, 'State & Activity Understanding': 33.33}}] S
INFO:     172.31.125.164:53538 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     147.185.132.84:63482 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.200:57862 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.127:59730 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.208:63844 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     91.196.152.119:36865 - "GET / HTTP/1.1" 404 Not Found
INFO:     91.196.152.20:43709 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     205.210.31.67:62576 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.9:59424 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.244:57860 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     91.196.152.220:43459 - "GET / HTTP/1.1" 404 Not Found
INFO:     91.231.89.130:43455 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     198.235.24.205:61234 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.226:62668 - "GET / HTTP/1.1" 404 Not Found
INFO:     147.185.132.88:58148 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     123.160.223.78:15284 - "GET / HTTP/1.1" 404 Not Found
INFO:     123.160.223.79:20381 - "GET / HTTP/1.1" 404 Not Found
INFO:     172.245.241.123:44614 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.51:64100 - "GET / HTTP/1.1" 404 Not Found
INFO:     47.97.2.138:57382 - "GET / HTTP/1.0" 404 Not Found
INFO:     47.97.2.138:59740 - "GET /nmaplowercheck1763048600 HTTP/1.1" 404 Not Found
INFO:     47.97.2.138:59754 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     47.97.2.138:59752 - "GET / HTTP/1.0" 404 Not Found
INFO:     47.97.2.138:59758 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     47.97.2.138:59764 - "GET /HNAP1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     47.97.2.138:60444 - "GET / HTTP/1.0" 404 Not Found
INFO:     47.97.2.138:60450 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     178.22.24.133:55414 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.149:57772 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.200:64044 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.151:58346 - "GET / HTTP/1.1" 404 Not Found
INFO:     147.185.132.201:57418 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.12:64030 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.119:64618 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.199:65276 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
INFO:     121.43.118.194:39522 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.43.118.194:39528 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.246:60914 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.193:59082 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     113.141.85.139:58594 - "GET / HTTP/1.1" 404 Not Found
INFO:     113.141.93.186:45430 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.95:63544 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     149.50.96.133:35780 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     147.185.132.129:60698 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     91.231.89.242:49329 - "GET / HTTP/1.1" 404 Not Found
INFO:     91.196.152.219:59803 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     198.235.24.92:61998 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     89.42.231.77:47416 - "GET /../../../../../../etc/passwd HTTP/1.1" 404 Not Found
INFO:     205.210.31.185:65040 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.22:63072 - "GET / HTTP/1.1" 404 Not Found
INFO:     47.92.65.140:42544 - "GET / HTTP/1.0" 404 Not Found
INFO:     47.92.65.140:42550 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     47.92.65.140:42554 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     149.50.96.133:51948 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     120.52.10.250:27659 - "HEAD / HTTP/1.1" 404 Not Found
INFO:     120.52.10.250:27665 - "GET / HTTP/1.1" 404 Not Found
INFO:     89.42.231.77:38856 - "GET /../../../../../../etc/passwd HTTP/1.1" 404 Not Found
INFO:     185.247.137.52:39663 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.229:59396 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.200:59674 - "GET / HTTP/1.1" 404 Not Found
nohup: ignoring input
INFO:     Started server process [1340607]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
get a new request
taskinfo eval_url='http://172.24.226.215:8000/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='Qwen2-7B-Instruct-11201-origin' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=1 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-A800'
{'user_id': 1526, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen2-7B-Instruct-11201-origin', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://172.24.226.215:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 1, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-A800'}} <class 'dict'>
{'id': 28510, 'evaluationId': 1338}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1338, 'batch_id': 28510, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1338, 'batch_id': 28510, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.17.239:39496 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-7B-Instruct-11201-origin [] R
INFO:     172.31.125.164:58678 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     172.31.125.164:58946 - "POST /evaluation_progress HTTP/1.1" 200 OK
Qwen2-7B-Instruct-11201-origin 28510 ebb4115d-d079-4418-96f2-de6ba8c1195a
submit stop batch 28510
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.17.239:52146 - "POST /stop_evaluation HTTP/1.1" 200 OK
batchresumption 28510 Qwen2-7B-Instruct-11201-origin Qwen2-7B-Instruct http://172.24.226.215:8000/v1/chat/completions Qwen/Qwen2-7B-Instruct EMPTY 1 1 1 -1  FlagRelease bj 1526
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.17.239:50352 - "POST /resume_evaluation HTTP/1.1" 200 OK
Qwen2-7B-Instruct-11201-origin 28510 ebb4115d-d079-4418-96f2-de6ba8c1195a
submit stop batch 28510
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.17.239:41476 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     208.87.243.131:35210 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     185.247.137.50:53887 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.74:61406 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.40.47.87:41248 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.40.47.87:41436 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     121.40.47.87:41428 - "GET /nmaplowercheck1763755365 HTTP/1.1" 404 Not Found
INFO:     121.40.47.87:41432 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.40.47.87:41458 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     121.40.47.87:41462 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.40.47.87:42166 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.40.47.87:42170 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     123.160.223.79:64803 - "GET / HTTP/1.1" 404 Not Found
INFO:     125.122.33.97:46704 - "GET / HTTP/1.1" 404 Not Found
INFO:     112.124.10.86:39890 - "GET / HTTP/1.1" 404 Not Found
INFO:     112.124.10.86:39892 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     205.210.31.55:64154 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.81:59986 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.165:63958 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.199.163.206:54782 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.199.163.206:54800 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     121.43.54.30:55166 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.43.54.30:55176 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     147.185.132.78:58954 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     147.185.132.231:60582 - "GET / HTTP/1.1" 404 Not Found
INFO:     185.247.137.4:41549 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     111.203.197.194:38416 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     111.203.197.194:55722 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     111.203.197.194:57963 - "POST /evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.117:58370 - "GET / HTTP/1.1" 404 Not Found
INFO:     39.108.88.65:60312 - "GET / HTTP/1.0" 404 Not Found
INFO:     39.108.88.65:60318 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     39.108.88.65:60320 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.199.163.202:50732 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.202:51394 - "GET /nmaplowercheck1764017707 HTTP/1.1" 404 Not Found
INFO:     121.199.163.202:51400 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     121.199.163.202:51396 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.202:51404 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     121.199.163.202:51410 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     121.199.163.202:51880 - "GET / HTTP/1.0" 404 Not Found
INFO:     121.199.163.202:51888 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.40.43.26:42458 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.40.43.26:42462 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     147.185.132.78:61092 - "GET / HTTP/1.1" 404 Not Found
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     120.92.55.16:4358 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     120.92.17.239:43394 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 109, in compare_urls
    taskqueue=json.load(f)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

INFO:     120.92.55.16:33262 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8000/v1/chat/completion' model='/workspace/CODE/models/Qwen2-7B' eval_model='qwen2-7b-flagos-1124' base_model_name='Qwen/Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=1 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-flagos-1124', 'online_model_name': '/workspace/CODE/models/Qwen2-7B', 'base_model_name': 'Qwen/Qwen2-7B', 'online_url': 'http://10.6.208.39:8000/v1/chat/completion', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 1, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28511, 'evaluationId': 1340}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1340, 'batch_id': 28511, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1340, 'batch_id': 28511, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.17.239:32942 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8000/v1/chat/completion' model='/workspace/CODE/models/Qwen2-7B' eval_model='qwen2-7b-flagos-1125' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=1 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-flagos-1125', 'online_model_name': '/workspace/CODE/models/Qwen2-7B', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.6.208.39:8000/v1/chat/completion', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 1, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28512, 'evaluationId': 1341}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1341, 'batch_id': 28512, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1341, 'batch_id': 28512, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.17.239:50068 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8000/v1/chat/completions' model='/workspace/CODE/models/Qwen2-7B' eval_model='qwen2-7b-flagos-1125_0' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=1 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-flagos-1125_0', 'online_model_name': '/workspace/CODE/models/Qwen2-7B', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.6.208.39:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 1, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28513, 'evaluationId': 1342}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1342, 'batch_id': 28513, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1342, 'batch_id': 28513, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.17.239:47874 - "POST /evaluation HTTP/1.1" 200 OK
qwen2-7b-flagos-1124 28511 f58587ef-b7bc-4fae-96e8-dcaaf3dcb49a
submit stop batch 28511
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     120.92.17.239:51578 - "POST /stop_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.233:61232 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     91.231.89.131:44213 - "GET / HTTP/1.1" 404 Not Found
INFO:     91.196.152.210:46437 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     147.185.132.141:59266 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.80:63458 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     121.40.47.190:37872 - "GET / HTTP/1.1" 404 Not Found
INFO:     121.40.47.190:37882 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.95:57506 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     91.196.152.190:34947 - "GET / HTTP/1.1" 404 Not Found
INFO:     91.231.89.7:58219 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     107.172.58.36:36414 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     123.160.223.75:38744 - "GET / HTTP/1.1" 404 Not Found
INFO:     123.160.223.72:37601 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.77:60856 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:29052 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.1.15.160:8000/v1/chat/completions' model='/workspace/models/qwen2_7b' eval_model='qwen2-7b-hygon-flagos-1127' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-hygon-flagos-1127', 'online_model_name': '/workspace/models/qwen2_7b', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.1.15.160:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28514, 'evaluationId': 1343}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1343, 'batch_id': 28514, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1343, 'batch_id': 28514, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.55.16:12303 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1127 [] R
INFO:     120.92.55.16:64290 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1127 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:56495 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1127 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:65480 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1127 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:21858 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     185.247.137.182:35599 - "GET / HTTP/1.1" 404 Not Found
INFO:     198.235.24.215:63280 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.1.15.160:8000/v1/chat/completions' model='/workspace/models/qwen2_7b' eval_model='qwen2-7b-hygon-flagos-1127' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-hygon-flagos-1127', 'online_model_name': '/workspace/models/qwen2_7b', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.1.15.160:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28515, 'evaluationId': 1343}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1343, 'batch_id': 28515, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1343, 'batch_id': 28515, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.55.16:46362 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1127 [{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     120.92.55.16:48023 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:48269 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.1.15.160:8000/v1/chat/completions' model='/workspace/models/qwen2_7b/' eval_model='qwen2-7b-hygon-flagos-1128' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-hygon-flagos-1128', 'online_model_name': '/workspace/models/qwen2_7b/', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.1.15.160:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28516, 'evaluationId': 1344}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1344, 'batch_id': 28516, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1344, 'batch_id': 28516, 'datasize': 14920}
mysql connect
insert success
INFO:     120.92.55.16:3298 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-hygon-flagos-1128 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:10281 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:50600 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:61546 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     198.235.24.159:64826 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.50:65332 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     120.55.95.177:39054 - "GET / HTTP/1.0" 404 Not Found
INFO:     120.55.95.177:39208 - "GET /nmaplowercheck1764384863 HTTP/1.1" 404 Not Found
INFO:     120.55.95.177:39210 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     120.55.95.177:39212 - "GET / HTTP/1.0" 404 Not Found
INFO:     120.55.95.177:39262 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     120.55.95.177:39266 - "GET /HNAP1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     120.55.95.177:39806 - "GET / HTTP/1.0" 404 Not Found
INFO:     120.55.95.177:39810 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     205.210.31.237:57498 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:59043 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     198.235.24.155:59262 - "GET / HTTP/1.1" 404 Not Found
INFO:     147.185.132.168:61888 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     125.122.15.250:47028 - "GET / HTTP/1.1" 404 Not Found
INFO:     111.7.96.178:21522 - "GET / HTTP/1.1" 404 Not Found
INFO:     147.185.132.174:58182 - "GET / HTTP/1.1" 404 Not Found
INFO:     210.16.164.124:59328 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:62726 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     147.185.132.73:63534 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     87.236.176.234:33865 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-flagos-1125_0 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 9.64765100671141, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 11.605317068059511, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     120.92.55.16:59331 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     205.210.31.185:58280 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
WARNING:  Unsupported upgrade request.
WARNING:  No supported WebSocket library detected. Please use "pip install 'uvicorn[standard]'", or install 'websockets' or 'wsproto' manually.
WARNING:  Invalid HTTP request received.
INFO:     198.235.24.234:63714 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.65:61514 - "GET / HTTP/1.1" 404 Not Found
INFO:     205.210.31.104:61126 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-flagos-1124 [] C
INFO:     172.31.125.164:45026 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8000/v1/chat/completions' model='/workspace/CODE/models/Qwen2-7B' eval_model='qwen2-7b-flagos-1125_0' base_model_name='Qwen2-7B' tokenizer='Qwen/Qwen2-7B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=1 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-flagos-1125_0', 'online_model_name': '/workspace/CODE/models/Qwen2-7B', 'base_model_name': 'Qwen2-7B', 'online_url': 'http://10.6.208.39:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 1, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28517, 'evaluationId': 1342}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1342, 'batch_id': 28517, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1342, 'batch_id': 28517, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.198:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:9010/v1/chat/completions' model='Hunyuan-A13B-Instruct-nvidia-flagos' eval_model='Hunyuan-A13B-Instruct-nvidia-flagos-tree1203' base_model_name='Hunyuan-A13B-Instruct' tokenizer='tencent/Hunyuan-A13B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=16000,temperature=0.7' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'tencent/Hunyuan-A13B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Hunyuan-A13B-Instruct-nvidia-flagos-tree1203', 'online_model_name': 'Hunyuan-A13B-Instruct-nvidia-flagos', 'base_model_name': 'Hunyuan-A13B-Instruct', 'online_url': 'http://10.6.208.39:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=16000,temperature=0.7', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28518, 'evaluationId': 1345}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1345, 'batch_id': 28518, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1345, 'batch_id': 28518, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.208:2048 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.163.207:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.169.207:2048 - "GET /api/v0/models HTTP/1.1" 404 Not Found
INFO:     100.67.161.204:2048 - "GET /v1/models HTTP/1.1" 404 Not Found
INFO:     100.67.161.203:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.163.198:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.209:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.202:2048 - "GET /favicon.ico HTTP/1.1" 404 Not Found
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-tree1203 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.64.134.193:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:9010/v1/chat/completions' model='Hunyuan-A13B-Instruct-nvidia-flagos' eval_model='Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp' base_model_name='Hunyuan-A13B-Instruct' tokenizer='tencent/Hunyuan-A13B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=16000,temperature=0.7' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'tencent/Hunyuan-A13B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp', 'online_model_name': 'Hunyuan-A13B-Instruct-nvidia-flagos', 'base_model_name': 'Hunyuan-A13B-Instruct', 'online_url': 'http://10.6.208.39:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=16000,temperature=0.7', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28519, 'evaluationId': 1346}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1346, 'batch_id': 28519, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1346, 'batch_id': 28519, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.207:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.67.173.200:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-tree1203 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.67.169.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:9010/v1/chat/completions' model='Hunyuan-A13B-Instruct-nvidia-flagos1' eval_model='Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp' base_model_name='Hunyuan-A13B-Instruct' tokenizer='tencent/Hunyuan-A13B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=16000,temperature=0.7' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'tencent/Hunyuan-A13B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp', 'online_model_name': 'Hunyuan-A13B-Instruct-nvidia-flagos1', 'base_model_name': 'Hunyuan-A13B-Instruct', 'online_url': 'http://10.6.208.39:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=16000,temperature=0.7', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28520, 'evaluationId': 1347}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1347, 'batch_id': 28520, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1347, 'batch_id': 28520, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.78.193:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [] R
INFO:     100.67.149.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.167.201:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.67.165.201:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.169.197:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.169.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.67.163.211:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.167.193:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.151.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.151.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:9010/v1/chat/completions' model='Hunyuan-A13B-Instruct-nvidia-flagos' eval_model='Hunyuan-A13B-Instruct-nvidia-flagos-tree1203' base_model_name='Hunyuan-A13B-Instruct' tokenizer='tencent/Hunyuan-A13B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=16000,temperature=0.7' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'tencent/Hunyuan-A13B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Hunyuan-A13B-Instruct-nvidia-flagos-tree1203', 'online_model_name': 'Hunyuan-A13B-Instruct-nvidia-flagos', 'base_model_name': 'Hunyuan-A13B-Instruct', 'online_url': 'http://10.6.208.39:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=16000,temperature=0.7', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28521, 'evaluationId': 1345}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1345, 'batch_id': 28521, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1345, 'batch_id': 28521, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.212:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.161.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.67.171.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
Hunyuan-A13B-Instruct-nvidia-flagos-tree1203 28521 4ef09959-504f-4723-9a71-662fe5ba9e7b
submit stop batch 28521
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.205:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.207:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.169.210:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.67.161.207:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.64.72.195:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.211:2048 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.171.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.149.209:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.64.78.210:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
request_id: docker system df -v query error: list index out of range
INFO:     100.67.163.202:2048 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.173.206:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.149.199:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.165.209:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.196:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.203:2048 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.161.201:2048 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.0748005319149, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 55.42328042328042, 'rawDetails': {}}] S
INFO:     100.67.165.209:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.67.175.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.130:9010/v1/chat/completions' model='DeepSeek-V3.2-Exp-ascend-origin' eval_model='DeepSeek-V3.2-Exp-ascend-origin-1205' base_model_name='DeepSeek-V3.2-Exp' tokenizer='deepseek-ai/DeepSeek-V3.2-Exp' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95' thinking=False retry_time=-1 chip='Ascend-910C'
{'user_id': 466, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'deepseek-ai/DeepSeek-V3.2-Exp'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'DeepSeek-V3.2-Exp-ascend-origin-1205', 'online_model_name': 'DeepSeek-V3.2-Exp-ascend-origin', 'base_model_name': 'DeepSeek-V3.2-Exp', 'online_url': 'http://10.1.15.130:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_p=0.95', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Ascend-910C'}} <class 'dict'>
{'id': 28522, 'evaluationId': 1348}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1348, 'batch_id': 28522, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1348, 'batch_id': 28522, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.165.210:2048 - "POST /evaluation HTTP/1.1" 200 OK
DeepSeek-V3.2-Exp-ascend-origin-1205 28522 a418cb84-278d-4553-961f-2bc5b473c9eb
submit stop batch 28522
[{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.197:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
batchresumption 28522 DeepSeek-V3.2-Exp-ascend-origin-1205 DeepSeek-V3.2-Exp-ascend-origin http://10.1.15.130:9010/v1/chat/completions deepseek-ai/DeepSeek-V3.2-Exp EMPTY 1 8 10 -1 temperature=0.6,top_p=0.95 FlagRelease bj 466
[{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.173.201:2048 - "POST /resume_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.209:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.173.198:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.198:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.171.193:2048 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.169.196:2048 - "GET /robots.txt HTTP/1.1" 404 Not Found
INFO:     100.67.169.199:2048 - "GET /sitemap.xml HTTP/1.1" 404 Not Found
INFO:     100.67.169.202:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.198:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.163.198:2049 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.163.206:2048 - "GET /robots.txt HTTP/1.1" 404 Not Found
INFO:     100.67.151.211:2048 - "GET /sitemap.xml HTTP/1.1" 404 Not Found
INFO:     100.67.149.202:2048 - "GET /sse HTTP/1.1" 404 Not Found
INFO:     100.67.173.201:2049 - "GET /mcp HTTP/1.1" 404 Not Found
INFO:     100.67.173.206:2049 - "GET /mcp-sse HTTP/1.1" 404 Not Found
INFO:     100.67.167.193:2049 - "GET /get_server_info HTTP/1.1" 404 Not Found
INFO:     100.67.169.200:2048 - "POST /token HTTP/1.1" 404 Not Found
INFO:     100.67.163.199:2048 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.165.194:2048 - "GET /nmaplowercheck1764974255 HTTP/1.1" 404 Not Found
INFO:     100.67.151.194:2048 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.165.211:2048 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.163.194:2048 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     100.67.163.211:2049 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.198:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.167.194:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.212:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.195:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.163.205:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.165.209:2050 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.149.194:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.163.199:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.212:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.202:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.195:2049 - "GET / HTTP/1.1" 404 Not Found
DeepSeek-V3.2-Exp-ascend-origin-1205 28522 a418cb84-278d-4553-961f-2bc5b473c9eb
submit stop batch 28522
[{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.169.204:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.67.149.193:2048 - "GET /?orgId=1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.200:2048 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.167.209:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.151.202:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.161.204:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.199:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.212:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.204:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.173.198:2051 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.149.201:2048 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-flagos-1209' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='do_sample=true, max_gen_toks=20000, temperature=0.7,top_k=20,top_p=0.8, repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-flagos-1209', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'do_sample=true, max_gen_toks=20000, temperature=0.7,top_k=20,top_p=0.8, repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28523, 'evaluationId': 1349}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28523, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28523, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.167.195:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-flagos-1209 [] R
INFO:     100.64.78.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-flagos-1209' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='do_sample=true,max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-flagos-1209', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'do_sample=true,max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28524, 'evaluationId': 1349}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28524, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28524, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.161.199:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-flagos-1209' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-flagos-1209', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28525, 'evaluationId': 1349}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28525, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1349, 'batch_id': 28525, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.200:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-NVIDIA-flagos-1209_00' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-NVIDIA-flagos-1209_00', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28526, 'evaluationId': 1350}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1350, 'batch_id': 28526, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1350, 'batch_id': 28526, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.171.201:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_00 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 38.48902925531915, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 42.32804232804233, 'rawDetails': {}}] S
INFO:     100.64.167.211:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-NVIDIA-flagos-1209_01' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-NVIDIA-flagos-1209_01', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28527, 'evaluationId': 1352}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1352, 'batch_id': 28527, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1352, 'batch_id': 28527, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.163.207:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_01 [] R
INFO:     100.64.169.195:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.198:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.207:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-flagos-1209_01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 38.48902925531915, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 42.32804232804233, 'rawDetails': {}}] S
INFO:     100.67.149.212:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct' eval_model='qwen2-7b-instruct-NVIDIA-Origin-1209' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-NVIDIA-Origin-1209', 'online_model_name': 'Qwen2-7B-Instruct', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28528, 'evaluationId': 1353}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1353, 'batch_id': 28528, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1353, 'batch_id': 28528, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.173.207:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [] R
INFO:     100.67.165.207:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [] R
INFO:     100.64.167.204:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.171.203:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.200:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.196:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-7b-instruct-NVIDIA-Origin-1209 28528 a06beb3b-30eb-488d-9fed-b507027b486e
submit stop batch 28528
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.161.210:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] C
INFO:     100.64.74.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct-Origin' eval_model='qwen2-7b-instruct-NVIDIA-Origin-1209' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-NVIDIA-Origin-1209', 'online_model_name': 'Qwen2-7B-Instruct-Origin', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28529, 'evaluationId': 1353}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1353, 'batch_id': 28529, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1353, 'batch_id': 28529, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.151.204:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [] R
INFO:     100.64.167.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209 [] R
INFO:     100.64.78.211:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-7b-instruct-NVIDIA-Origin-1209 28528 a06beb3b-30eb-488d-9fed-b507027b486e
submit stop batch 28528
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 14.848993288590604, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 27.343920559881695, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.167.204:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
qwen2-7b-instruct-NVIDIA-Origin-1209 28529 c7c366b6-33f4-413c-b290-97f129fb42f8
submit stop batch 28529
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.210:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen2-7B-Instruct-Origin' eval_model='qwen2-7b-instruct-NVIDIA-Origin-1209-02' base_model_name='Qwen2-7B-Instruct' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=64 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen2-7b-instruct-NVIDIA-Origin-1209-02', 'online_model_name': 'Qwen2-7B-Instruct-Origin', 'base_model_name': 'Qwen2-7B-Instruct', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=20000,temperature=0.7,top_k=20,top_p=0.8,repetition_penalty=1.05', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28530, 'evaluationId': 1354}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1354, 'batch_id': 28530, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1354, 'batch_id': 28530, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.149.197:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [] R
INFO:     100.64.169.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [] R
INFO:     100.67.161.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [] R
INFO:     100.64.169.198:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.211:2048 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.200:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.211:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.210:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-7b-instruct-NVIDIA-Origin-1209-02 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 3.3333333333333335, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 15.18456375838926, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 26.651209056039747, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 38.522273936170215, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 40.87301587301587, 'rawDetails': {}}] S
INFO:     100.64.134.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.195:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.206:2048 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.199:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.151.194:2049 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://10.1.15.130:9010/v1/chat/completions' model='Qwen3-Next-80B-A3B-Instruct-ascend-flagos' eval_model='Qwen3-Next-80B-A3B-Instruct-ascend-flagos-1210' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.7,top_p=0.8,top_k=20' thinking=False retry_time=-1 chip='Ascend-910C'
{'user_id': 466, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct-ascend-flagos-1210', 'online_model_name': 'Qwen3-Next-80B-A3B-Instruct-ascend-flagos', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://10.1.15.130:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.7,top_p=0.8,top_k=20', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Ascend-910C'}} <class 'dict'>
{'id': 28532, 'evaluationId': 1356}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1356, 'batch_id': 28532, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1356, 'batch_id': 28532, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.211:2048 - "POST /evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.67.173.198:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
Qwen3-Next-80B-A3B-Instruct-ascend-flagos-1210 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.169.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.64.74.197:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '', 'err_code': 0}
INFO:     100.67.171.193:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.67:9010/v1/chat/completions' model='Qwen3-Next-80B-A3B-Instruct-metax-flagos' eval_model='Qwen3-Next-80B-A3B-Instruct-metax-flagos-1210' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=64 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.7,top_p=0.8,top_k=20' thinking=False retry_time=-1 chip='Metax-C550'
{'user_id': 466, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct-metax-flagos-1210', 'online_model_name': 'Qwen3-Next-80B-A3B-Instruct-metax-flagos', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://10.1.15.67:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 64, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.7,top_p=0.8,top_k=20', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Metax-C550'}} <class 'dict'>
{'id': 28533, 'evaluationId': 1357}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1357, 'batch_id': 28533, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1357, 'batch_id': 28533, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.197:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen3-Next-80B-A3B-Instruct-metax-flagos-1210 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.161.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.211:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.203:2048 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.169.205:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.169.209:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
eval_model details status
Qwen3-Next-80B-A3B-Instruct-ascend-flagos-1210 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'F', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.67.161.194:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen3-Next-80B-A3B-Instruct-metax-flagos-1210 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 67.78523489932886, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 78.05973094434658, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 81.44946808510637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 61.904761904761905, 'rawDetails': {}}] S
INFO:     100.67.163.204:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.175.197:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.194:2050 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 70.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.28859060402685, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 43.99746122152186, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.32413563829788, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 58.20105820105819, 'rawDetails': {}}] S
INFO:     100.64.165.198:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Hunyuan-A13B-Instruct-nvidia-flagos1-gemscpp [{'status': 'S', 'dataset': 'AIME', 'accuracy': 66.66666666666666, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 43.875838926174495, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 45.61085163027264, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 75.0748005319149, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 55.42328042328042, 'rawDetails': {}}] S
INFO:     100.67.171.199:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.237:8000/v1/chat/completions' model='/workspace/flagscale_serve/qwen3_0_6B_mcore_to_hf_ckpt' eval_model='qwen3-0.6B-origin' base_model_name='Qwen3-0.6B' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-0.6B-origin', 'online_model_name': '/workspace/flagscale_serve/qwen3_0_6B_mcore_to_hf_ckpt', 'base_model_name': 'Qwen3-0.6B', 'online_url': 'http://10.1.15.237:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28534, 'evaluationId': 1358}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1358, 'batch_id': 28534, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1358, 'batch_id': 28534, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.211:2049 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.175.202:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.195:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.201:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://172.21.16.14:8000/v1/chat/completions' model='Kimi-K2-Thinking-nvidia-origin' eval_model='Kimi-K2-Thinking-nvidia-origin' base_model_name='Kimi-K2-Thinkingg' tokenizer='' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='H20-SXM'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': ''}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Kimi-K2-Thinking-nvidia-origin', 'online_model_name': 'Kimi-K2-Thinking-nvidia-origin', 'base_model_name': 'Kimi-K2-Thinkingg', 'online_url': 'http://172.21.16.14:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'H20-SXM'}} <class 'dict'>
{'id': 28535, 'evaluationId': 1360}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1360, 'batch_id': 28535, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1360, 'batch_id': 28535, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.76.195:2048 - "POST /evaluation HTTP/1.1" 200 OK
Kimi-K2-Thinking-nvidia-origin 28535 c0f726fa-8d2f-4763-b877-230ab016d065
submit stop batch 28535
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.198:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
nohup: ignoring input
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 10, in <module>
    from utils import *
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 399
    {"status": "S", "dataset": "AIME", "accuracy": 86.67, "rawDetails": {}}
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
nohup: ignoring input
INFO:     Started server process [3771195]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
get a new request
taskinfo eval_url='http://172.21.16.6:8000/v1/chat/completions' model='Kimi-K2-Thinking-nvidia-flagos' eval_model='Kimi-K2-Thinking-nvidia-flagos' base_model_name='Kimi-K2-Thinkingg' tokenizer='' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='H20-SXM'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': ''}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Kimi-K2-Thinking-nvidia-flagos', 'online_model_name': 'Kimi-K2-Thinking-nvidia-flagos', 'base_model_name': 'Kimi-K2-Thinkingg', 'online_url': 'http://172.21.16.6:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new', 'lm_eval-math_500'], 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'H20-SXM'}} <class 'dict'>
{'id': 28536, 'evaluationId': 1361}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1361, 'batch_id': 28536, 'datasize': 15420}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1361, 'batch_id': 28536, 'datasize': 15420}
mysql connect
insert success
INFO:     100.64.167.193:2048 - "POST /evaluation HTTP/1.1" 200 OK
Kimi-K2-Thinking-nvidia-flagos 28536 c869e2de-6c64-4615-b127-020fe9ee951f
submit stop batch 28536
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.204:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Kimi-K2-Thinking-nvidia-origin [{'status': 'S', 'dataset': 'LiveBench', 'accuracy': 75.19, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 75.34, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MUSR', 'accuracy': 68.39, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 83.17, 'rawDetails': {}}, {'status': 'S', 'dataset': 'AIME', 'accuracy': 86.67, 'rawDetails': {}}, {'status': 'S', 'dataset': 'math_500', 'accuracy': 92.8, 'rawDetails': {}}] S
INFO:     100.67.151.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Kimi-K2-Thinking-nvidia-flagos [{'status': 'S', 'dataset': 'LiveBench', 'accuracy': 74.58, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 76.85, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MUSR', 'accuracy': 68.65, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 83.21, 'rawDetails': {}}, {'status': 'S', 'dataset': 'AIME', 'accuracy': 90, 'rawDetails': {}}, {'status': 'S', 'dataset': 'math_500', 'accuracy': 93.6, 'rawDetails': {}}] S
INFO:     100.64.165.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.209:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.210:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.208:2048 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.165.207:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.167.207:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.193:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.200:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.163.200:2050 - "GET /nmaplowercheck1765660313 HTTP/1.1" 404 Not Found
INFO:     100.67.163.200:2049 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.167.210:2049 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.167.199:2049 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     100.67.171.199:2049 - "GET /HNAP1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.204:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.163.204:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.169.199:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.151.200:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.200:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.209:2048 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.165.210:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.199:2050 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.149.208:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.149.198:2049 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.169.205:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.169.198:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
request_id:  query error: list index out of range
INFO:     100.67.161.196:2049 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
eval_model details status
Kimi-K2-Thinking-nvidia-origin [{'status': 'S', 'dataset': 'LiveBench', 'accuracy': 75.19, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 75.34, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MUSR', 'accuracy': 68.39, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 83.17, 'rawDetails': {}}, {'status': 'S', 'dataset': 'AIME', 'accuracy': 86.67, 'rawDetails': {}}, {'status': 'S', 'dataset': 'math_500', 'accuracy': 92.8, 'rawDetails': {}}] S
INFO:     100.67.151.199:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Kimi-K2-Thinking-nvidia-flagos [{'status': 'S', 'dataset': 'LiveBench', 'accuracy': 74.58, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 76.85, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MUSR', 'accuracy': 68.65, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 83.21, 'rawDetails': {}}, {'status': 'S', 'dataset': 'AIME', 'accuracy': 90, 'rawDetails': {}}, {'status': 'S', 'dataset': 'math_500', 'accuracy': 93.6, 'rawDetails': {}}] S
INFO:     100.67.151.200:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.210:2052 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.167.208:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.205:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.193:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.200:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.207:2050 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.151.206:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.161.195:2052 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.151.194:2050 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.194:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.203:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.165.196:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28537,"evaluationId":1362}
{'id': 28537, 'evaluationId': 1362}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1362, 'batch_id': 28537, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.169.199:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217 [] R
INFO:     100.67.175.202:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.167.210:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1217 28537 1701d0c3-6656-4b64-ae11-f11eb6530106
submit stop batch 28537
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.161.199:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_toks=32768' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='max_toks=32768' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28538,"evaluationId":1363}
{'id': 28538, 'evaluationId': 1363}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1363, 'batch_id': 28538, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.167.200:2048 - "POST /evaluation HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1217-01 28538 9ff99b57-4bc2-4bcd-8023-88b21ac1f2a7
submit stop batch 28538
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.194:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-02' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-02' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-02', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-02', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28539,"evaluationId":1364}
{'id': 28539, 'evaluationId': 1364}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1364, 'batch_id': 28539, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.165.207:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-02 [] R
INFO:     100.64.76.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-02 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.149.207:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1217-02 28539 de3da88f-ec7e-4fe5-99cc-86655543efc1
submit stop batch 28539
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.197:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-03' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-03' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-03', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-03', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28540,"evaluationId":1365}
{'id': 28540, 'evaluationId': 1365}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1365, 'batch_id': 28540, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.72.210:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-03 [] R
INFO:     100.67.165.195:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-03 [] R
INFO:     100.64.72.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-04' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1217-04' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=32000 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-04', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1217-04', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 32000, 'retry_time': 3600}
submit_evaluation response {"id":28541,"evaluationId":1366}
{'id': 28541, 'evaluationId': 1366}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1366, 'batch_id': 28541, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.167.202:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.92:9010/v1/chat/completions' model='Qwen3-4B-hygon-flagos' eval_model='Qwen3-4B-hygon-flagos-concur16' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='hygon_BW-1000'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-hygon-flagos-concur16', 'online_model_name': 'Qwen3-4B-hygon-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.1.15.92:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new', 'lm_eval-math_500'], 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'hygon_BW-1000'}} <class 'dict'>
{'id': 28542, 'evaluationId': 1367}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1367, 'batch_id': 28542, 'datasize': 15420}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1367, 'batch_id': 28542, 'datasize': 15420}
mysql connect
insert success
INFO:     100.64.161.204:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.92:9010/v1/chat/completions' model='Qwen3-4B-hygon-flagos' eval_model='Qwen3-4B-hygon-flagos-concur16' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='hygon_BW-1000'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-hygon-flagos-concur16', 'online_model_name': 'Qwen3-4B-hygon-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.1.15.92:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new', 'lm_eval-math_500'], 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'hygon_BW-1000'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.134.200:2049 - "POST /evaluation HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1217-04 28541 65a7e995-06c6-4314-947a-5ab4136a6be4
submit stop batch 28541
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.72.204:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-4B-hygon-flagos-concur16 28542 f209dbf5-ad20-4090-a67c-39879746babb
submit stop batch 28542
[{'status': 'P', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'math_500', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.198:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-4B-hygon-flagos-concur16 28542 f209dbf5-ad20-4090-a67c-39879746babb
submit stop batch 28542
[{'status': 'P', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'math_500', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.165.202:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.203:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.208:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.175.196:2048 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.167.193:2052 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.196:2051 - "GET /nice%20ports%2C/Trinity.txt.bak HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.204:2050 - "GET /devicedesc.xml HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.197:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.197:2050 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.206:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.210:2049 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.151.206:2051 - "HEAD /evaldiffs HTTP/1.1" 405 Method Not Allowed
INFO:     100.67.175.212:2049 - "HEAD /evaldiffs HTTP/1.1" 405 Method Not Allowed
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.1.15.67:9010/v1/chat/completions' model='Qwen3-4B-metax-flagos' eval_model='Qwen3-4B-metax-flagos-concur4' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='metax_C550'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-metax-flagos-concur4', 'online_model_name': 'Qwen3-4B-metax-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.1.15.67:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new', 'lm_eval-math_500'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'metax_C550'}} <class 'dict'>
{'id': 28543, 'evaluationId': 1368}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1368, 'batch_id': 28543, 'datasize': 15420}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1368, 'batch_id': 28543, 'datasize': 15420}
mysql connect
insert success
INFO:     100.67.149.212:2050 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-4B-metax-flagos-concur4 28543 517357cb-61dd-4f92-b865-210fcab6908b
submit stop batch 28543
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.208:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-04 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] C
INFO:     100.67.151.193:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1217-04 28541 65a7e995-06c6-4314-947a-5ab4136a6be4
submit stop batch 28541
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.134.197:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1217-04 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] C
INFO:     100.64.76.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.113:9010/v1/chat/completions' model='Qwen3-4B-ascend-flagos' eval_model='Qwen3-4B-ascend-flagos-concur16' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='ascend_910C'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-ascend-flagos-concur16', 'online_model_name': 'Qwen3-4B-ascend-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.1.15.113:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new', 'lm_eval-math_500'], 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'ascend_910C'}} <class 'dict'>
{'id': 28544, 'evaluationId': 1369}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1369, 'batch_id': 28544, 'datasize': 15420}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1369, 'batch_id': 28544, 'datasize': 15420}
mysql connect
insert success
INFO:     100.64.165.203:2048 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     172.31.125.164:42760 - "POST /evaluation_progress HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [286769]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 5050): address already in use
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
nohup: ignoring input
INFO:     Started server process [286937]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
INFO:     100.67.169.209:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.205:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.203:2053 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.210:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.197:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.173.211:2048 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.198:2053 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.201:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.193:2054 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.163.210:2051 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.209:2052 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.175.196:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.165.200:2049 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.161.206:2049 - "GET /nice%20ports%2C/Trinity.txt.bak HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.203:2049 - "GET /devicedesc.xml HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.161.193:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.161.200:2051 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.169.193:2048 - "GET /nmaplowercheck1766291957 HTTP/1.1" 404 Not Found
INFO:     100.67.175.196:2050 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.149.212:2051 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.167.209:2051 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     100.67.149.196:2052 - "GET /HNAP1 HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.207:2053 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.169.193:2049 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.202:2054 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.167.195:2052 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://10.1.15.85:9010/v1/chat/completions' model='Qwen3-4B-cambricon-flagos' eval_model='Qwen3-4B-cambricon-flagos-lowgems-2' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='cambricon_MLU590'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-cambricon-flagos-lowgems-2', 'online_model_name': 'Qwen3-4B-cambricon-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.1.15.85:9010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'cambricon_MLU590'}} <class 'dict'>
{'id': 28545, 'evaluationId': 1370}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1370, 'batch_id': 28545, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1370, 'batch_id': 28545, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.167.199:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-4B-cambricon-flagos-lowgems-2 28545 66623dae-1dc9-461a-8f97-d5c922853b66
submit stop batch 28545
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.208:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.67.173.209:2048 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://111.203.197.197:39012/v1/chat/completions' model='Qwen3-4B-nv-origin' eval_model='Qwen3-4B-nv-origin-concur256' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=256 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-nv-origin-concur256', 'online_model_name': 'Qwen3-4B-nv-origin', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://111.203.197.197:39012/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 256, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28546, 'evaluationId': 1371}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1371, 'batch_id': 28546, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1371, 'batch_id': 28546, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.169.196:2048 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-4B-nv-origin-concur256 28546 5ad39786-fc05-4a6f-ad28-ad3faabf109f
submit stop batch 28546
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.195:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.67.169.193:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.169.193:2050 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.173.211:2049 - "GET /evaluation HTTP/1.1" 405 Method Not Allowed
get a new request
taskinfo eval_url='http://111.203.197.197:39012/v1/chat/completions' model='Qwen3-4B-nv-origin' eval_model='Qwen3-4B-nv-origin-concur256' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=256 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-nv-origin-concur256', 'online_model_name': 'Qwen3-4B-nv-origin', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://111.203.197.197:39012/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 256, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28547, 'evaluationId': 1371}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1371, 'batch_id': 28547, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1371, 'batch_id': 28547, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.151.210:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://111.203.197.197:39010/v1/chat/completions' model='Qwen3-4B-nv-flagos' eval_model='Qwen3-4B-nv-flagos-concur64' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=64 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-nv-flagos-concur64', 'online_model_name': 'Qwen3-4B-nv-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://111.203.197.197:39010/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 64, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28548, 'evaluationId': 1372}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1372, 'batch_id': 28548, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1372, 'batch_id': 28548, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.175.198:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.31.28.152:6701/v1/chat/completions' model='Qwen3-4B-iluvatar-flagos' eval_model='Qwen3-4B-iluvatar-flagos' base_model_name='Qwen3-4B' tokenizer='Qwen/Qwen3-4B' api_key='EMPTY' batch_size=1 num_concurrent=64 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_k=20,top_p=0.95,min_p=0' thinking=False retry_time=-1 chip='iluvatar-BI150'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-4B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-4B-iluvatar-flagos', 'online_model_name': 'Qwen3-4B-iluvatar-flagos', 'base_model_name': 'Qwen3-4B', 'online_url': 'http://10.31.28.152:6701/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 64, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'temperature=0.6,top_k=20,top_p=0.95,min_p=0', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'iluvatar-BI150'}} <class 'dict'>
{'id': 28549, 'evaluationId': 1373}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1373, 'batch_id': 28549, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1373, 'batch_id': 28549, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.200:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-4B-nv-origin-concur256 28547 9b97ecc6-89a9-4c50-a7f3-06e684f0f4d1
submit stop batch 28547
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.72.204:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-4B-nv-flagos-concur64 28548 12faefaa-2a4c-4055-ac63-6119f2a6681e
submit stop batch 28548
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.211:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-4B-iluvatar-flagos 28549 477cd598-86ec-4c24-86d3-ff35a03d3810
submit stop batch 28549
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.196:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28550,"evaluationId":1374}
{'id': 28550, 'evaluationId': 1374}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1374, 'batch_id': 28550, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.165.196:2051 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.173.207:2052 - "POST /evaldiffs HTTP/1.1" 405 Method Not Allowed
INFO:     100.67.175.199:2049 - "GET /evaldiffs HTTP/1.1" 422 Unprocessable Entity
INFO:     100.67.173.210:2050 - "GET /evaldiffs?request_id=1374 HTTP/1.1" 422 Unprocessable Entity
INFO:     100.67.173.195:2048 - "GET /evaldiffs?request_id=13741 HTTP/1.1" 422 Unprocessable Entity
INFO:     100.67.165.207:2054 - "GET /evaldiffs?request_id=1374 HTTP/1.1" 422 Unprocessable Entity
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.167.198:2052 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28551,"evaluationId":1375}
{'id': 28551, 'evaluationId': 1375}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1375, 'batch_id': 28551, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.163.202:2051 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.173.210:2051 - "GET /evaldiffs?request_id=1375 HTTP/1.1" 422 Unprocessable Entity
INFO:     100.67.169.212:2051 - "GET /evaldiffs HTTP/1.1" 422 Unprocessable Entity
request_id: 1375 query error: list index out of range
INFO:     100.67.149.196:2053 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
INFO:     100.67.171.208:2050 - "GET /evaldiffs?request_id=1375 HTTP/1.1" 422 Unprocessable Entity
request_id: 1375 query error: list index out of range
INFO:     100.67.163.210:2052 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
INFO:     100.67.151.204:2050 - "POST /evaldiffs HTTP/1.1" 405 Method Not Allowed
request_id: 1375 query error: list index out of range
INFO:     100.67.171.193:2052 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
INFO:     100.67.175.204:2050 - "GET /evaldiffs?request_id=1375 HTTP/1.1" 422 Unprocessable Entity
request_id: 1375 query error: list index out of range
INFO:     100.67.151.202:2050 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.171.206:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28552,"evaluationId":1376}
{'id': 28552, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28552, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.167.202:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.163.209:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.175.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.167.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.173.202:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.175.195:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.173.201:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.175.209:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.151.193:2053 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.149.195:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.171.194:2049 - "GET /stop_evaluation HTTP/1.1" 405 Method Not Allowed
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] R
INFO:     100.67.149.208:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28552 a674454a-6ea2-4ff2-b3e1-ec87a3674dd4
submit stop batch 28552
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.199:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.151.199:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28552 a674454a-6ea2-4ff2-b3e1-ec87a3674dd4
submit stop batch 28552
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.163.212:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.175.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28553,"evaluationId":1376}
{'id': 28553, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28553, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.173.200:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.161.202:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.161.198:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.165.199:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.171.208:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28553 242d0098-dadf-4755-96db-d4bc5d8671b5
submit stop batch 28553
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.169.202:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.165.200:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.151.195:2052 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.173.206:2051 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.161.211:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.167.194:2049 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.151.195:2053 - "GET /nmaplowercheck1766411963 HTTP/1.1" 404 Not Found
INFO:     100.67.173.194:2049 - "HEAD / HTTP/1.1" 404 Not Found
INFO:     100.67.151.194:2051 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     100.67.161.200:2052 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.211:2053 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.201:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.169.201:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.209:2055 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.208:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.167.201:2050 - "GET / HTTP/1.1" 404 Not Found
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1223-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1223-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=32000 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1223-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1223-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 32000, 'retry_time': 3600}
submit_evaluation response {"id":28554,"evaluationId":1377}
{'id': 28554, 'evaluationId': 1377}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1377, 'batch_id': 28554, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.171.197:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-01 [] R
INFO:     100.64.76.198:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-01 [] R
INFO:     100.64.169.211:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-01 [] R
INFO:     100.64.169.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-01 [] R
INFO:     100.64.165.203:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-01 [] R
INFO:     100.67.165.207:2055 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1223-01 28554 4aa9c2aa-bee1-4fcb-9da2-e4e93a4e2e8c
submit stop batch 28554
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.72.210:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.165.193:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.175.209:2056 - "GET /evaldiffs HTTP/1.1" 200 OK
request_id: a674454a-6ea2-4ff2-b3e1-ec87a3674dd3 query error: list index out of range
INFO:     100.67.149.201:2050 - "GET /evaldiffs HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 137, in get_diffs
    eval_model,_,details, status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.173.195:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.167.202:2049 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28552 a674454a-6ea2-4ff2-b3e1-ec87a3674dd4
submit stop batch 28552
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.151.206:2055 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.151.201:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.151.193:2054 - "POST /evaluation_diffs HTTP/1.1" 405 Method Not Allowed
INFO:     100.67.167.195:2053 - "POST /evaluation_diffs HTTP/1.1" 405 Method Not Allowed
INFO:     100.67.169.194:2049 - "POST /evaluation_diffs HTTP/1.1" 405 Method Not Allowed
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1223-02' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1223-02' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=32000 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1223-02', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1223-02', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 32000, 'retry_time': 3600}
submit_evaluation response {"id":28555,"evaluationId":1378}
{'id': 28555, 'evaluationId': 1378}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1378, 'batch_id': 28555, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.209:2052 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.161.198:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.165.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.169.201:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [] R
INFO:     100.67.167.196:2055 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28556,"evaluationId":1376}
{'id': 28556, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28556, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.167.195:2054 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.171.196:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.173.201:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.169.195:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28556 850c6b5f-7f4d-4698-9878-4f89d97dca7e
submit stop batch 28556
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.199:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [] R
INFO:     100.67.167.203:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28557,"evaluationId":1376}
{'id': 28557, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28557, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.210:2052 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.167.201:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.149.197:2052 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28556 850c6b5f-7f4d-4698-9878-4f89d97dca7e
submit stop batch 28556
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.161.197:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.175.211:2054 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.169.207:2053 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28556 850c6b5f-7f4d-4698-9878-4f89d97dca7e
submit stop batch 28556
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.169.210:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28556 850c6b5f-7f4d-4698-9878-4f89d97dca7e
submit stop batch 28556
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.169.193:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.173.196:2052 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28557 5d823842-aa30-4710-a7c0-8d13c3fc034d
submit stop batch 28557
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.206:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28558,"evaluationId":1376}
{'id': 28558, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28558, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.175.202:2056 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28558 68275377-805e-4779-9a17-ab0dc4bb30e0
submit stop batch 28558
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.161.211:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://120.92.17.239:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://120.92.17.239:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28559,"evaluationId":1376}
{'id': 28559, 'evaluationId': 1376}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1376, 'batch_id': 28559, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.149.196:2054 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28559 b7035c47-7139-4cc7-8be6-3549ad89916e
submit stop batch 28559
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.207:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28559 b7035c47-7139-4cc7-8be6-3549ad89916e
submit stop batch 28559
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.173.201:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28553 242d0098-dadf-4755-96db-d4bc5d8671b5
submit stop batch 28553
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.161.209:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test2 28552 a674454a-6ea2-4ff2-b3e1-ec87a3674dd4
submit stop batch 28552
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.167.203:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test2 [] C
INFO:     100.67.173.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [] R
INFO:     100.64.169.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.139:8000' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28560,"evaluationId":1379}
{'id': 28560, 'evaluationId': 1379}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1379, 'batch_id': 28560, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.151.208:2054 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-1 [] R
INFO:     100.67.163.210:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-1 28560 567fb04a-3a21-4f59-a295-2bae2240b3c7
submit stop batch 28560
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.175.208:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-1' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28561,"evaluationId":1379}
{'id': 28561, 'evaluationId': 1379}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1379, 'batch_id': 28561, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.167.197:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-1 [] R
INFO:     100.67.163.211:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-1 28561 77980f63-4ca1-42d9-a67a-598e832b0e36
submit stop batch 28561
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.201:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-1 [] C
INFO:     100.67.151.209:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-1 28561 77980f63-4ca1-42d9-a67a-598e832b0e36
submit stop batch 28561
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.171.197:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-1 28561 77980f63-4ca1-42d9-a67a-598e832b0e36
submit stop batch 28561
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.175.207:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-2' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 12345, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28562,"evaluationId":1380}
{'id': 28562, 'evaluationId': 1380}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1380, 'batch_id': 28562, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.149.206:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-2 [] R
INFO:     100.67.171.209:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [] R
INFO:     100.64.74.210:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-2 28562 d20f9a0e-3097-463e-86c8-1bf65afc7437
submit stop batch 28562
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.212:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-3' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-3' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28563,"evaluationId":1381}
{'id': 28563, 'evaluationId': 1381}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1381, 'batch_id': 28563, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.171.210:2048 - "POST /evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-2 28562 d20f9a0e-3097-463e-86c8-1bf65afc7437
submit stop batch 28562
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.161.209:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-3 28563 0f9d7599-e8db-4d82-ba09-9a9cc52e8425
submit stop batch 28563
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.209:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='{"temperature":0.6,"top_p":0.95, max_gen_toks: 16000}' thinking=False retry_time=3600 chip='Nvidia-H100'
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 80, in mmfetch_url
    key,value = param.split("=")[0], param.split("=")[1]
IndexError: list index out of range

tasks {'err_code': 2, 'err_msg': 'list index out of range'}
INFO:     100.67.151.210:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='{"temperature":0.6,"top_p":0.95, "max_gen_toks": 16000}' thinking=False retry_time=3600 chip='Nvidia-H100'
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 80, in mmfetch_url
    key,value = param.split("=")[0], param.split("=")[1]
IndexError: list index out of range

tasks {'err_code': 2, 'err_msg': 'list index out of range'}
INFO:     100.67.175.202:2057 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.139:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.139:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28564,"evaluationId":1382}
{'id': 28564, 'evaluationId': 1382}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1382, 'batch_id': 28564, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.149.199:2052 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-4 [] R
INFO:     100.67.175.193:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-4 [] R
INFO:     100.67.161.199:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.62.44:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.62.44:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-4' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.62.44:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.62.44:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.173.202:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.62.44:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-5' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.62.44:8000/v1/chat/completions' model='Qwen2-VL-7B-Instruct' eval_model='Qwen2-VL-7B-Instruct-test-5' base_model_name='Qwen2-VL-7B-Instruct' tokenizer='Qwen2-VL-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-5', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.62.44:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen2-VL-7B-Instruct-test-5', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.62.44:8000/v1/chat/completions', 'online_model_name': 'Qwen2-VL-7B-Instruct', 'base_model_name': 'Qwen2-VL-7B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28565,"evaluationId":1383}
{'id': 28565, 'evaluationId': 1383}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1383, 'batch_id': 28565, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.197:2053 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-5 [] R
INFO:     100.67.167.203:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.40.148:8000/v1/chat/completions' model='Qwen3-0.6B-CZ' eval_model='qwen3-0.6B-train-origin' base_model_name='qwen3-0.6B-train' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-0.6B-train-origin', 'online_model_name': 'Qwen3-0.6B-CZ', 'base_model_name': 'qwen3-0.6B-train', 'online_url': 'http://172.24.40.148:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28566, 'evaluationId': 1384}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1384, 'batch_id': 28566, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1384, 'batch_id': 28566, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.198:2048 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [] R
INFO:     100.67.167.198:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
Qwen2-VL-7B-Instruct-test-5 [] R
INFO:     100.67.161.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-4 28564 6da75b70-8612-499a-bb0e-1c1bf25d88dd
submit stop batch 28564
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.196:2056 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test 28550 db321512-e882-4215-a3d6-d2d016059cc6
submit stop batch 28550
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.207:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test1 28551 49cc29d7-a545-4be4-8fe5-e1f27c872851
submit stop batch 28551
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.204:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen2-VL-7B-Instruct-test-4 28564 6da75b70-8612-499a-bb0e-1c1bf25d88dd
submit stop batch 28564
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.134.198:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.64.78.194:2048 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/a800/llama3' eval_model='llama3-70B-train-origin' base_model_name='Llama3-70B-train' tokenizer='Qwen/Qwen2-7B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen2-7B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-origin', 'online_model_name': '/workspace/hardware_ckpt/a800/llama3', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28567, 'evaluationId': 1385}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1385, 'batch_id': 28567, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1385, 'batch_id': 28567, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.165.209:2055 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/a800/llama3' eval_model='llama3-70B-train-origin-0' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-origin-0', 'online_model_name': '/workspace/hardware_ckpt/a800/llama3', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28568, 'evaluationId': 1386}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1386, 'batch_id': 28568, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1386, 'batch_id': 28568, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.205:2048 - "POST /evaluation HTTP/1.1" 200 OK
llama3-70B-train-origin 28567 bcb85dac-4d1f-40de-9567-e6d62bbd40ab
submit stop batch 28567
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.206:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.167.207:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.165.203:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
llama3-70B-train-origin-0 28568 8343121c-b00b-4794-bda5-e9e17acc4a4f
submit stop batch 28568
[{'status': 'F', 'dataset': 'arc_challenge', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'arc_easy', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'boolq', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'ceval-valid', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'commonsense_qa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GSM', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'minerva_math_algebra', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'openbookqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'piqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'truthfulqa_mc1', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'winogrande', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.196:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/tsingmicro/tsingmocro_to_hf_llama3_ckpt' eval_model='llama3-70B-train-tsingmicro' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-tsingmicro', 'online_model_name': '/workspace/hardware_ckpt/tsingmicro/tsingmocro_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28569, 'evaluationId': 1387}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1387, 'batch_id': 28569, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1387, 'batch_id': 28569, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.197:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/tsingmicro/tsingmocro_to_hf_llama3_ckpt' eval_model='llama3-70B-train-tsingmicro-0' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='tsingmicro-TX81'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-tsingmicro-0', 'online_model_name': '/workspace/hardware_ckpt/tsingmicro/tsingmocro_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'tsingmicro-TX81'}} <class 'dict'>
{'id': 28570, 'evaluationId': 1388}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1388, 'batch_id': 28570, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1388, 'batch_id': 28570, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.210:2049 - "POST /evaluation HTTP/1.1" 200 OK
llama3-70B-train-tsingmicro 28569 c301455c-7533-48e1-a27e-e1a2c8b48c05
submit stop batch 28569
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.210:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.233:8000/v1/chat/completions' model='/workspace/hardware_ckpt/huawei/huawei_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-ascend' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='asecnd-910C'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-ascend', 'online_model_name': '/workspace/hardware_ckpt/huawei/huawei_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.233:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'asecnd-910C'}} <class 'dict'>
{'id': 28571, 'evaluationId': 1389}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1389, 'batch_id': 28571, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1389, 'batch_id': 28571, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.208:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.141:8000/v1/chat/completions' model='/workspace/hardware_ckpt/tianshu/tianshu_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-tianshu' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='iluvatar-BI150'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-tianshu', 'online_model_name': '/workspace/hardware_ckpt/tianshu/tianshu_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.141:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'iluvatar-BI150'}} <class 'dict'>
{'id': 28572, 'evaluationId': 1390}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1390, 'batch_id': 28572, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1390, 'batch_id': 28572, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.203:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.218:8000/v1/chat/completions' model='/workspace/hardware_ckpt/hygon/hygon_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-haiguang' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='haiguang-BW1000'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-haiguang', 'online_model_name': '/workspace/hardware_ckpt/hygon/hygon_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.218:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'haiguang-BW1000'}} <class 'dict'>
{'id': 28573, 'evaluationId': 1391}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1391, 'batch_id': 28573, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1391, 'batch_id': 28573, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.211:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/mthreads/mthreads_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-moer' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='mthreads-S5000'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-moer', 'online_model_name': '/workspace/hardware_ckpt/mthreads/mthreads_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'mthreads-S5000'}} <class 'dict'>
{'id': 28574, 'evaluationId': 1392}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1392, 'batch_id': 28574, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1392, 'batch_id': 28574, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.72.207:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/muxi/muxi_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-metax' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='metax-C550'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-metax', 'online_model_name': '/workspace/hardware_ckpt/muxi/muxi_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'metax-C550'}} <class 'dict'>
{'id': 28575, 'evaluationId': 1393}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1393, 'batch_id': 28575, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1393, 'batch_id': 28575, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.198:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/kunlunxin/kunlunxin_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-kunlunxin' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='kunlunxin-P800'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-kunlunxin', 'online_model_name': '/workspace/hardware_ckpt/kunlunxin/kunlunxin_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'kunlunxin-P800'}} <class 'dict'>
{'id': 28576, 'evaluationId': 1394}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1394, 'batch_id': 28576, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1394, 'batch_id': 28576, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.169.199:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/hygon/hygon_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-hygon' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='hygon-BW1000'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-hygon', 'online_model_name': '/workspace/hardware_ckpt/hygon/hygon_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'hygon-BW1000'}} <class 'dict'>
{'id': 28577, 'evaluationId': 1395}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1395, 'batch_id': 28577, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1395, 'batch_id': 28577, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.206:2052 - "POST /evaluation HTTP/1.1" 200 OK
llama3-70B-train-tsingmicro-0 28570 bda1ce05-aab6-494e-bbf4-3d780b5c86fe
submit stop batch 28570
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.208:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
llama3-70B-train-ascend 28571 1a58fc11-bcdb-47a6-b38d-bd867afebf5d
submit stop batch 28571
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.195:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
llama3-70B-train-tianshu 28572 6214f57a-0ec7-4e23-a90f-4a5776aed427
submit stop batch 28572
[{'status': 'F', 'dataset': 'arc_challenge', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'arc_easy', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'boolq', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'ceval-valid', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'commonsense_qa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GSM', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'minerva_math_algebra', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'openbookqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'piqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'truthfulqa_mc1', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'winogrande', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.207:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
llama3-70B-train-haiguang 28573 53d80a5d-d932-46ab-94b6-75c903a9533a
submit stop batch 28573
[{'status': 'F', 'dataset': 'arc_challenge', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'arc_easy', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'boolq', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'ceval-valid', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'commonsense_qa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GSM', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'minerva_math_algebra', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'openbookqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'piqa', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'truthfulqa_mc1', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'winogrande', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.163.211:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
llama3-70B-train-moer 28574 efdb9060-2811-4744-a84e-a5687686ec63
submit stop batch 28574
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.194:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.202:2052 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://10.1.15.124:8000/v1/chat/completions' model='/workspace/hardware_ckpt/pingtouge/pingtouge_mcore_to_hf_llama3_ckpt' eval_model='llama3-70B-train-pingtouge' base_model_name='Llama3-70B-train' tokenizer='LLM-Research/Meta-Llama-3-70B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='PPU-ZW810E'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'LLM-Research/Meta-Llama-3-70B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'llama3-70B-train-pingtouge', 'online_model_name': '/workspace/hardware_ckpt/pingtouge/pingtouge_mcore_to_hf_llama3_ckpt', 'base_model_name': 'Llama3-70B-train', 'online_url': 'http://10.1.15.124:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'PPU-ZW810E'}} <class 'dict'>
{'id': 28578, 'evaluationId': 1396}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1396, 'batch_id': 28578, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1396, 'batch_id': 28578, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.72.202:2048 - "POST /evaluation HTTP/1.1" 200 OK
llama3-70B-train-pingtouge 28578 75fd7723-51fb-4ec7-ad27-ed3dbbe5a646
submit stop batch 28578
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.201:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.209:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://172.24.40.148:8000/v1/chat/completions' model='Aquila-3B-Homo-Exp02-1000B' eval_model='Aquila-3B-origin' base_model_name='Aquila-3B' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Aquila-3B-origin', 'online_model_name': 'Aquila-3B-Homo-Exp02-1000B', 'base_model_name': 'Aquila-3B', 'online_url': 'http://172.24.40.148:8000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28579, 'evaluationId': 1397}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1397, 'batch_id': 28579, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1397, 'batch_id': 28579, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.78.204:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.40.148:8001/v1/chat/completions' model='Aquila-3B-Hetero-Exp02-1000B' eval_model='Aquila-3B-iluvatar_1T' base_model_name='Aquila-3B' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Aquila-3B-iluvatar_1T', 'online_model_name': 'Aquila-3B-Hetero-Exp02-1000B', 'base_model_name': 'Aquila-3B', 'online_url': 'http://172.24.40.148:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28580, 'evaluationId': 1398}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1398, 'batch_id': 28580, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1398, 'batch_id': 28580, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.207:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.40.148:8002/v1/chat/completions' model='Aquila-1.8B-A800_1T' eval_model='Aquila-1.8B-train-origin' base_model_name='Aquila-1.8B' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Aquila-1.8B-train-origin', 'online_model_name': 'Aquila-1.8B-A800_1T', 'base_model_name': 'Aquila-1.8B', 'online_url': 'http://172.24.40.148:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28581, 'evaluationId': 1399}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1399, 'batch_id': 28581, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1399, 'batch_id': 28581, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.212:2053 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.40.148:8003/v1/chat/completions' model='Aquila-1.8B-hetero_1T' eval_model='Aquila-1.8B-hetero' base_model_name='Aquila-1.8B' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Aquila-1.8B-hetero', 'online_model_name': 'Aquila-1.8B-hetero_1T', 'base_model_name': 'Aquila-1.8B', 'online_url': 'http://172.24.40.148:8003/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28582, 'evaluationId': 1400}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1400, 'batch_id': 28582, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1400, 'batch_id': 28582, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.203:2048 - "POST /evaluation HTTP/1.1" 200 OK
Aquila-3B-origin 28579 539733a3-6ef6-498d-b7a6-243b08db0f08
submit stop batch 28579
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.169.206:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Aquila-3B-iluvatar_1T 28580 4e890221-dc16-4ac7-ba0e-b9d88f57661b
submit stop batch 28580
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.161.204:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
Aquila-1.8B-train-origin 28581 d47b81cd-16fe-480f-bd29-d0a50b44fe05
submit stop batch 28581
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.195:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
Aquila-1.8B-hetero 28582 eff7b57a-2bea-4ac8-898c-df3507a28451
submit stop batch 28582
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.169.198:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
Aquila-3B-origin 28579 539733a3-6ef6-498d-b7a6-243b08db0f08
submit stop batch 28579
[{'status': 'S', 'dataset': 'arc_challenge', 'accuracy': 0.4369, 'rawDetails': {}}, {'status': 'S', 'dataset': 'arc_easy', 'accuracy': 0.7424, 'rawDetails': {}}, {'status': 'S', 'dataset': 'boolq', 'accuracy': 0.667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'ceval-valid', 'accuracy': 0.4042, 'rawDetails': {}}, {'status': 'S', 'dataset': 'CMMLU', 'accuracy': 0.4325, 'rawDetails': {}}, {'status': 'S', 'dataset': 'commonsense_qa', 'accuracy': 0.4472, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GSM', 'accuracy': 0.0523, 'rawDetails': {}}, {'status': 'S', 'dataset': 'minerva_math_algebra', 'accuracy': 0.0329, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 0.4346, 'rawDetails': {}}, {'status': 'S', 'dataset': 'openbookqa', 'accuracy': 0.396, 'rawDetails': {}}, {'status': 'S', 'dataset': 'piqa', 'accuracy': 0.7601, 'rawDetails': {}}, {'status': 'S', 'dataset': 'truthfulqa_mc1', 'accuracy': 0.2705, 'rawDetails': {}}, {'status': 'S', 'dataset': 'winogrande', 'accuracy': 0.6251, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.163.204:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
Aquila-1.8B-train-origin 28581 d47b81cd-16fe-480f-bd29-d0a50b44fe05
submit stop batch 28581
[{'status': 'S', 'dataset': 'arc_challenge', 'accuracy': 0.4147, 'rawDetails': {}}, {'status': 'S', 'dataset': 'arc_easy', 'accuracy': 0.7403, 'rawDetails': {}}, {'status': 'S', 'dataset': 'boolq', 'accuracy': 0.645, 'rawDetails': {}}, {'status': 'S', 'dataset': 'ceval-valid', 'accuracy': 0.2363, 'rawDetails': {}}, {'status': 'S', 'dataset': 'CMMLU', 'accuracy': 0.2667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'commonsense_qa', 'accuracy': 0.2465, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GSM', 'accuracy': 0.1463, 'rawDetails': {}}, {'status': 'S', 'dataset': 'minerva_math_algebra', 'accuracy': 0.0505, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 0.2928, 'rawDetails': {}}, {'status': 'S', 'dataset': 'openbookqa', 'accuracy': 0.408, 'rawDetails': {}}, {'status': 'S', 'dataset': 'piqa', 'accuracy': 0.7612, 'rawDetails': {}}, {'status': 'S', 'dataset': 'truthfulqa_mc1', 'accuracy': 0.2546, 'rawDetails': {}}, {'status': 'S', 'dataset': 'winogrande', 'accuracy': 0.6109, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.76.211:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': 'Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': 'Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28583,"evaluationId":1401}
{'id': 28583, 'evaluationId': 1401}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1401, 'batch_id': 28583, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.161.194:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test1 28583 80910faf-3fa0-4c3a-aee9-bf63884bc11b
submit stop batch 28583
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.173.198:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28584,"evaluationId":1401}
{'id': 28584, 'evaluationId': 1401}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1401, 'batch_id': 28584, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.173.207:2053 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test2' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:8000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test2' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:8000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28585,"evaluationId":1402}
{'id': 28585, 'evaluationId': 1402}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1402, 'batch_id': 28585, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.173.197:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test2 28585 70b50cbf-1ad1-4398-afeb-2bfb44cf4e1d
submit stop batch 28585
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.161.210:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test1 28584 949358e2-3810-4542-939f-603f9ded0594
submit stop batch 28584
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.173.201:2054 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test1 28583 80910faf-3fa0-4c3a-aee9-bf63884bc11b
submit stop batch 28583
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.149.207:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test3' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test3' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28586,"evaluationId":1403}
{'id': 28586, 'evaluationId': 1403}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1403, 'batch_id': 28586, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.163.207:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test4' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test4' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28587,"evaluationId":1404}
{'id': 28587, 'evaluationId': 1404}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1404, 'batch_id': 28587, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.167.195:2055 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 48.44, 'rawDetails': {'商业': {'num': 126, 'correct': 43, 'accuracy': 34.13}, '科学': {'num': 42, 'correct': 19, 'accuracy': 45.24}, 'overall': {'num': 256, 'correct': 124, 'accuracy': 48.44}, 'accuracy': 48.44, 'reject_info': {'reject_rate': 71.56, 'reject_number': 644, 'total_question': 900}, 'average_tokens': 444.96875, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, 'average_prompt_tokens': 365.66796875, 'average_completion_tokens': 79.30078125}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 60.6, 'rawDetails': {'accuracy': 60.6, 'reject_info': {'reject_rate': 62.78, 'reject_number': 565, 'total_question': 900}, 'subject_score': {'Math': 46.67, 'Music': 40.0, 'Manage': 53.33, 'Public': 66.67, 'Physics': 73.33, 'Pharmacy': 66.67, 'Marketing': 70.0, 'Materials': 60.0, 'Sociology': 70.0, 'Literature': 80.0, 'Mechanical': 40.0, 'Psychology': 76.67}, 'average_tokens': 633.6805970149254, 'difficulty_score': {'Easy': 67.86, 'Hard': 56.14, 'Medium': 57.23}, 'average_prompt_tokens': 631.2537313432836, 'average_completion_tokens': 2.426865671641791}}, {'status': 'S', 'dataset': 'MMMU_Pro_standard', 'accuracy': 43.84, 'rawDetails': {'accuracy': 43.84, 'reject_info': {'reject_rate': 0.06, 'reject_number': 1, 'total_question': 1730}, 'subject_score': {'Art': 56.6, 'Math': 30.0, 'Music': 28.33, 'Design': 65.0, 'Manage': 36.0, 'Biology': 42.37, 'Finance': 33.33, 'History': 62.5, 'Physics': 40.0, 'Pharmacy': 50.88, 'Chemistry': 46.67, 'Economics': 50.85, 'Geography': 49.02, 'Marketing': 40.68, 'Materials': 31.67, 'Sociology': 50.0, 'Accounting': 27.59, 'Art_Theory': 69.09, 'Literature': 69.23, 'Psychology': 48.33, 'Agriculture': 25.0, 'Electronics': 58.33, 'Public_Health': 41.38, 'Computer_Science': 51.67, 'Energy_and_Power': 24.14, 'Clinical_Medicine': 47.46, 'Basic_Medical_Science': 32.69, 'Mechanical_Engineering': 42.37, 'Architecture_and_Engineering': 35.0, 'Diagnostics_and_Laboratory_Medicine': 35.0}, 'average_tokens': 831.3597455176402, 'difficulty_score': {'Easy': 55.87, 'Hard': 34.25, 'Medium': 40.7}, 'average_prompt_tokens': 828.6737998843262, 'average_completion_tokens': 2.6859456333140543}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.165.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1223-02 28555 6752eacc-024c-4f9e-9349-7333ffd7c9bc
submit stop batch 28555
[{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 48.44, 'rawDetails': {'商业': {'num': 126, 'correct': 43, 'accuracy': 34.13}, '科学': {'num': 42, 'correct': 19, 'accuracy': 45.24}, 'overall': {'num': 256, 'correct': 124, 'accuracy': 48.44}, 'accuracy': 48.44, 'reject_info': {'reject_rate': 71.56, 'reject_number': 644, 'total_question': 900}, 'average_tokens': 444.96875, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, 'average_prompt_tokens': 365.66796875, 'average_completion_tokens': 79.30078125}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 60.6, 'rawDetails': {'accuracy': 60.6, 'reject_info': {'reject_rate': 62.78, 'reject_number': 565, 'total_question': 900}, 'subject_score': {'Math': 46.67, 'Music': 40.0, 'Manage': 53.33, 'Public': 66.67, 'Physics': 73.33, 'Pharmacy': 66.67, 'Marketing': 70.0, 'Materials': 60.0, 'Sociology': 70.0, 'Literature': 80.0, 'Mechanical': 40.0, 'Psychology': 76.67}, 'average_tokens': 633.6805970149254, 'difficulty_score': {'Easy': 67.86, 'Hard': 56.14, 'Medium': 57.23}, 'average_prompt_tokens': 631.2537313432836, 'average_completion_tokens': 2.426865671641791}}, {'status': 'S', 'dataset': 'MMMU_Pro_standard', 'accuracy': 43.84, 'rawDetails': {'accuracy': 43.84, 'reject_info': {'reject_rate': 0.06, 'reject_number': 1, 'total_question': 1730}, 'subject_score': {'Art': 56.6, 'Math': 30.0, 'Music': 28.33, 'Design': 65.0, 'Manage': 36.0, 'Biology': 42.37, 'Finance': 33.33, 'History': 62.5, 'Physics': 40.0, 'Pharmacy': 50.88, 'Chemistry': 46.67, 'Economics': 50.85, 'Geography': 49.02, 'Marketing': 40.68, 'Materials': 31.67, 'Sociology': 50.0, 'Accounting': 27.59, 'Art_Theory': 69.09, 'Literature': 69.23, 'Psychology': 48.33, 'Agriculture': 25.0, 'Electronics': 58.33, 'Public_Health': 41.38, 'Computer_Science': 51.67, 'Energy_and_Power': 24.14, 'Clinical_Medicine': 47.46, 'Basic_Medical_Science': 32.69, 'Mechanical_Engineering': 42.37, 'Architecture_and_Engineering': 35.0, 'Diagnostics_and_Laboratory_Medicine': 35.0}, 'average_tokens': 831.3597455176402, 'difficulty_score': {'Easy': 55.87, 'Hard': 34.25, 'Medium': 40.7}, 'average_prompt_tokens': 828.6737998843262, 'average_completion_tokens': 2.6859456333140543}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.203:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1223-02 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 48.44, 'rawDetails': {'商业': {'num': 126, 'correct': 43, 'accuracy': 34.13}, '科学': {'num': 42, 'correct': 19, 'accuracy': 45.24}, 'overall': {'num': 256, 'correct': 124, 'accuracy': 48.44}, 'accuracy': 48.44, 'reject_info': {'reject_rate': 71.56, 'reject_number': 644, 'total_question': 900}, 'average_tokens': 444.96875, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, 'average_prompt_tokens': 365.66796875, 'average_completion_tokens': 79.30078125}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 60.6, 'rawDetails': {'accuracy': 60.6, 'reject_info': {'reject_rate': 62.78, 'reject_number': 565, 'total_question': 900}, 'subject_score': {'Math': 46.67, 'Music': 40.0, 'Manage': 53.33, 'Public': 66.67, 'Physics': 73.33, 'Pharmacy': 66.67, 'Marketing': 70.0, 'Materials': 60.0, 'Sociology': 70.0, 'Literature': 80.0, 'Mechanical': 40.0, 'Psychology': 76.67}, 'average_tokens': 633.6805970149254, 'difficulty_score': {'Easy': 67.86, 'Hard': 56.14, 'Medium': 57.23}, 'average_prompt_tokens': 631.2537313432836, 'average_completion_tokens': 2.426865671641791}}, {'status': 'S', 'dataset': 'MMMU_Pro_standard', 'accuracy': 43.84, 'rawDetails': {'accuracy': 43.84, 'reject_info': {'reject_rate': 0.06, 'reject_number': 1, 'total_question': 1730}, 'subject_score': {'Art': 56.6, 'Math': 30.0, 'Music': 28.33, 'Design': 65.0, 'Manage': 36.0, 'Biology': 42.37, 'Finance': 33.33, 'History': 62.5, 'Physics': 40.0, 'Pharmacy': 50.88, 'Chemistry': 46.67, 'Economics': 50.85, 'Geography': 49.02, 'Marketing': 40.68, 'Materials': 31.67, 'Sociology': 50.0, 'Accounting': 27.59, 'Art_Theory': 69.09, 'Literature': 69.23, 'Psychology': 48.33, 'Agriculture': 25.0, 'Electronics': 58.33, 'Public_Health': 41.38, 'Computer_Science': 51.67, 'Energy_and_Power': 24.14, 'Clinical_Medicine': 47.46, 'Basic_Medical_Science': 32.69, 'Mechanical_Engineering': 42.37, 'Architecture_and_Engineering': 35.0, 'Diagnostics_and_Laboratory_Medicine': 35.0}, 'average_tokens': 831.3597455176402, 'difficulty_score': {'Easy': 55.87, 'Hard': 34.25, 'Medium': 40.7}, 'average_prompt_tokens': 828.6737998843262, 'average_completion_tokens': 2.6859456333140543}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] C
INFO:     100.64.134.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1223-02 28555 6752eacc-024c-4f9e-9349-7333ffd7c9bc
submit stop batch 28555
[{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 48.44, 'rawDetails': {'商业': {'num': 126, 'correct': 43, 'accuracy': 34.13}, '科学': {'num': 42, 'correct': 19, 'accuracy': 45.24}, 'overall': {'num': 256, 'correct': 124, 'accuracy': 48.44}, 'accuracy': 48.44, 'reject_info': {'reject_rate': 71.56, 'reject_number': 644, 'total_question': 900}, 'average_tokens': 444.96875, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, 'average_prompt_tokens': 365.66796875, 'average_completion_tokens': 79.30078125}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 60.6, 'rawDetails': {'accuracy': 60.6, 'reject_info': {'reject_rate': 62.78, 'reject_number': 565, 'total_question': 900}, 'subject_score': {'Math': 46.67, 'Music': 40.0, 'Manage': 53.33, 'Public': 66.67, 'Physics': 73.33, 'Pharmacy': 66.67, 'Marketing': 70.0, 'Materials': 60.0, 'Sociology': 70.0, 'Literature': 80.0, 'Mechanical': 40.0, 'Psychology': 76.67}, 'average_tokens': 633.6805970149254, 'difficulty_score': {'Easy': 67.86, 'Hard': 56.14, 'Medium': 57.23}, 'average_prompt_tokens': 631.2537313432836, 'average_completion_tokens': 2.426865671641791}}, {'status': 'S', 'dataset': 'MMMU_Pro_standard', 'accuracy': 43.84, 'rawDetails': {'accuracy': 43.84, 'reject_info': {'reject_rate': 0.06, 'reject_number': 1, 'total_question': 1730}, 'subject_score': {'Art': 56.6, 'Math': 30.0, 'Music': 28.33, 'Design': 65.0, 'Manage': 36.0, 'Biology': 42.37, 'Finance': 33.33, 'History': 62.5, 'Physics': 40.0, 'Pharmacy': 50.88, 'Chemistry': 46.67, 'Economics': 50.85, 'Geography': 49.02, 'Marketing': 40.68, 'Materials': 31.67, 'Sociology': 50.0, 'Accounting': 27.59, 'Art_Theory': 69.09, 'Literature': 69.23, 'Psychology': 48.33, 'Agriculture': 25.0, 'Electronics': 58.33, 'Public_Health': 41.38, 'Computer_Science': 51.67, 'Energy_and_Power': 24.14, 'Clinical_Medicine': 47.46, 'Basic_Medical_Science': 32.69, 'Mechanical_Engineering': 42.37, 'Architecture_and_Engineering': 35.0, 'Diagnostics_and_Laboratory_Medicine': 35.0}, 'average_tokens': 831.3597455176402, 'difficulty_score': {'Easy': 55.87, 'Hard': 34.25, 'Medium': 40.7}, 'average_prompt_tokens': 828.6737998843262, 'average_completion_tokens': 2.6859456333140543}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.149.204:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test4 28587 c955857d-6bbc-407a-9aca-caacd07a9ae0
submit stop batch 28587
[{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 45.66, 'rawDetails': {'商业': {'num': 126, 'correct': 37, 'accuracy': 29.37}, '科学': {'num': 204, 'correct': 81, 'accuracy': 39.71}, 'overall': {'num': 898, 'correct': 410, 'accuracy': 45.66}, 'accuracy': 45.66, 'reject_info': {'reject_rate': 0.22, 'reject_number': 2, 'total_question': 900}, 'average_tokens': 291.4543429844098, '健康与医学': {'num': 153, 'correct': 84, 'accuracy': 54.9}, '技术与工程': {'num': 242, 'correct': 98, 'accuracy': 40.5}, '艺术与设计': {'num': 88, 'correct': 59, 'accuracy': 67.05}, '人文社会科学': {'num': 85, 'correct': 51, 'accuracy': 60.0}, 'average_prompt_tokens': 288.0356347438753, 'average_completion_tokens': 3.4187082405345213}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.161.195:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test6' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test6' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test6', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test6', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28588,"evaluationId":1405}
{'id': 28588, 'evaluationId': 1405}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1405, 'batch_id': 28588, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.195:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test6 28588 914cb72c-c57f-4b42-bbfe-589f574d7274
submit stop batch 28588
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.175.203:2054 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test6 28588 914cb72c-c57f-4b42-bbfe-589f574d7274
submit stop batch 28588
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.165.210:2054 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test7' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test7' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test7', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test7', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28589,"evaluationId":1406}
{'id': 28589, 'evaluationId': 1406}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1406, 'batch_id': 28589, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.161.212:2052 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test7 28589 cb0b56cb-b002-4779-9c66-6935226480bb
submit stop batch 28589
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.171.199:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B/' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B/' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen3-8B-1224', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_model_name': '/nfs/Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen3-8B-1224', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_model_name': '/nfs/Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28590,"evaluationId":1407}
{'id': 28590, 'evaluationId': 1407}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1407, 'batch_id': 28590, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.167.201:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:8004/v1/chat/completions' model='Qwen3-8B/' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:8004/v1/chat/completions' model='Qwen3-8B/' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen3-8B-1224', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_model_name': 'Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen3-8B-1224', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_model_name': 'Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.149.199:2053 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8B-1224', 'online_model_name': '/nfs/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.74.204:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8B-1224', 'online_model_name': '/nfs/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.134.198:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B' eval_model='qwen3-8B-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8B-1224', 'online_model_name': '/nfs/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.67.167.212:2054 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B' eval_model='qwen3-8b-cambricon-flagos-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-cambricon-flagos-1224', 'online_model_name': '/nfs/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28591, 'evaluationId': 1408}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28591, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28591, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.207:2050 - "POST /evaluation HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1224 28591 bd067d07-3635-4f50-80f8-63e683e9562d
submit stop batch 28591
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.198:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
request_id: * query error: list index out of range
INFO:     100.64.167.200:2049 - "POST /stop_evaluation HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 220, in stopbatch
    eval_model,batch_id,details,_ = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='Qwen3-8B' eval_model='qwen3-8b-cambricon-flagos-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-cambricon-flagos-1224', 'online_model_name': 'Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28592, 'evaluationId': 1408}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28592, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28592, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.208:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.161.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1224 28592 ad1e5f7a-9c05-4da3-a43c-2485ad997dd9
submit stop batch 28592
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.202:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B/' eval_model='qwen3-8b-cambricon-flagos-1224' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-cambricon-flagos-1224', 'online_model_name': '/nfs/Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28593, 'evaluationId': 1408}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28593, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1408, 'batch_id': 28593, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.134.205:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.167.195:2056 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.163.210:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.134.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.134.195:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.151.197:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.151.194:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.161.201:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.169.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.74.210:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.72.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.149.210:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.167.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.169.195:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.175.194:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.167.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.72.203:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.74.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.167.207:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.169.197:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.165.203:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.165.194:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.167.200:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.74.211:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.72.199:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.161.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.76.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.169.199:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.67.175.200:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.72.211:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.78.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.165.210:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1224 [] R
INFO:     100.64.167.193:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.151.212:2048 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.205:2051 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.208:2051 - "GET / HTTP/1.1" 404 Not Found
qwen3-8b-cambricon-flagos-1224 28593 1aaa2acb-0f64-4d12-aa6e-ab048a6427a7
submit stop batch 28593
[{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.204:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.4:8004/v1/chat/completions' model='/nfs/Qwen3-8B/' eval_model='qwen3-8b-cambricon-flagos-1225' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-cambricon-flagos-1225', 'online_model_name': '/nfs/Qwen3-8B/', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.4:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28594, 'evaluationId': 1409}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1409, 'batch_id': 28594, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1409, 'batch_id': 28594, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.134.200:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [] R
INFO:     100.64.78.193:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [] R
INFO:     100.64.169.210:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.200:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.205:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.173.210:2052 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://10.1.15.95:8004/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-hygon-flagos-1225-01' base_model_name='qwen3_8b' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=3000' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-hygon-flagos-1225-01', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'qwen3_8b', 'online_url': 'http://10.1.15.95:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=3000', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28595, 'evaluationId': 1410}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1410, 'batch_id': 28595, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1410, 'batch_id': 28595, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.161.208:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1225-01 [] R
INFO:     100.67.151.205:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.149.197:2053 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.204:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.167.202:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8b-hygon-flagos-1225-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.199:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.165.196:2052 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
get a new request
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1226-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen2.5-vl' eval_model='qwen2-5-vl-cambricon-flagos-1226-01' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=32000 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=32000' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1226-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-cambricon-flagos-1226-01', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_model_name': '/root/model/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 32000, 'retry_time': 3600}
submit_evaluation response {"id":28596,"evaluationId":1411}
{'id': 28596, 'evaluationId': 1411}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1411, 'batch_id': 28596, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.169.199:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [] R
INFO:     100.64.161.208:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1225-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.171.201:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-8b-hygon-flagos-1225-01 28595 d827ec29-d3d0-4581-8a08-e3f9e9dc6c78
submit stop batch 28595
[{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.161.204:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.173.210:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.72.212:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.163.202:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.72.195:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.169.202:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.171.212:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.74.212:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.74.208:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.134.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:30000/v1/chat/completions' model='/workspace/liuyanqing/qwen3_0_6B_mcore_to_hf_ckpt' eval_model='qwen3-0.6B-train-mcore' base_model_name='qwen3-0.6B-train' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-0.6B-train-mcore', 'online_model_name': '/workspace/liuyanqing/qwen3_0_6B_mcore_to_hf_ckpt', 'base_model_name': 'qwen3-0.6B-train', 'online_url': 'http://10.1.15.124:30000/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28597, 'evaluationId': 1413}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1413, 'batch_id': 28597, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1413, 'batch_id': 28597, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.151.200:2054 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.169.198:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8001/v1/chat/completions' model='/workspace/models/qwen3_30A3B/' eval_model='qwen3-30b-a3b-hygon-flagos-1226' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-flagos-1226', 'online_model_name': '/workspace/models/qwen3_30A3B/', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.1.15.160:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28598, 'evaluationId': 1414}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1414, 'batch_id': 28598, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1414, 'batch_id': 28598, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.201:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-flagos-1226 [] R
INFO:     100.64.78.210:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8001/v1/chat/completions' model='Qwen3-30B-A3B-Gems' eval_model='qwen3-30b-a3b-NVIDIA-Gems-1228' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=30000,temperature=0.6,top_k=20,top_p=0.95' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-NVIDIA-Gems-1228', 'online_model_name': 'Qwen3-30B-A3B-Gems', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.6.208.39:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=30000,temperature=0.6,top_k=20,top_p=0.95', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28599, 'evaluationId': 1415}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1415, 'batch_id': 28599, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1415, 'batch_id': 28599, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.163.210:2056 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-NVIDIA-Gems-1228 [] R
INFO:     100.67.161.212:2055 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.6.208.39:8002/v1/chat/completions' model='Qwen3-30B-A3B-Origin' eval_model='qwen3-30b-a3b-NVIDIA-Origin-1228' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=30000,temperature=0.6,top_k=20,top_p=0.95' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-NVIDIA-Origin-1228', 'online_model_name': 'Qwen3-30B-A3B-Origin', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.6.208.39:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=30000,temperature=0.6,top_k=20,top_p=0.95', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28600, 'evaluationId': 1416}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1416, 'batch_id': 28600, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1416, 'batch_id': 28600, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.161.208:2052 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-NVIDIA-Origin-1228 [] R
INFO:     100.67.175.194:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8002/v1/chat/completions' model='Qwen3-30B-A3B' eval_model='qwen3-30b-a3b-hygon-origin-1226' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-origin-1226', 'online_model_name': 'Qwen3-30B-A3B', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.1.15.160:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28601, 'evaluationId': 1417}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1417, 'batch_id': 28601, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1417, 'batch_id': 28601, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.151.210:2052 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.95:8004/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-hygon-flagos-1226-001' base_model_name='qwen3_8b' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=3000' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-hygon-flagos-1226-001', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'qwen3_8b', 'online_url': 'http://10.1.15.95:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'mtemperature=0.6,top_k=20,top_p=0.95,max_gen_toks=3000', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28602, 'evaluationId': 1418}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1418, 'batch_id': 28602, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1418, 'batch_id': 28602, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.198:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1226-001 [] R
INFO:     100.64.76.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.167.209:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test7' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.24.178.138:5000/v1/chat/completions' model='/share/project/guowei/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test7' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test7', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test7', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.138:5000/v1/chat/completions', 'online_model_name': '/share/project/guowei/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response 
<!doctype html>
<html lang="en">
<head>
  <title>Server Error (500)</title>
</head>
<body>
  <h1>Server Error (500)</h1><p></p>
</body>
</html>

Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/requests/models.py", line 971, in json
    return complexjson.loads(self.text, **kwargs)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 2 column 1 (char 1)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 84, in mmfetch_url
    response = submit_mm_evaluation(taskinfo.eval_model, taskinfo.eval_url, taskinfo.api_key, taskinfo.model, taskinfo.batch_size, taskinfo.num_concurrent, taskinfo.num_retry, taskinfo.max_gen_toks, taskinfo.thinking, taskinfo.retry_time, mode, region, special_event, taskinfo.chip, taskinfo.base_model_name, user_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/submit.py", line 319, in submit_mm_evaluation
    response_data = response.json()
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/requests/models.py", line 975, in json
    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)
requests.exceptions.JSONDecodeError: Expecting value: line 2 column 1 (char 1)

tasks {'err_code': 2, 'err_msg': 'Expecting value: line 2 column 1 (char 1)'}
INFO:     100.67.169.210:2054 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.169.199:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.201:2052 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.203:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.167.200:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.198:2054 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.204:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.151.200:2055 - "GET /../../../../../../etc/passwd HTTP/1.1" 404 Not Found
INFO:     100.67.171.197:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.194:2050 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.173.195:2051 - "OPTIONS / HTTP/1.0" 404 Not Found
INFO:     100.67.165.205:2050 - "OPTIONS / HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.165.200:2054 - "GET /nice%20ports%2C/Trinity.txt.bak HTTP/1.0" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.198:2054 - "GET /devicedesc.xml HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.197:2054 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.193:2052 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 50.28, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 203, 'correct': 93, 'accuracy': 45.81}, 'overall': {'num': 899, 'correct': 452, 'accuracy': 50.28}, 'accuracy': 50.28, 'reject_info': {'reject_rate': 0.11, 'reject_number': 1, 'total_question': 900}, 'average_tokens': 388.4627363737486, '健康与医学': {'num': 153, 'correct': 88, 'accuracy': 57.52}, '技术与工程': {'num': 244, 'correct': 112, 'accuracy': 45.9}, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, '人文社会科学': {'num': 85, 'correct': 58, 'accuracy': 68.24}, 'average_prompt_tokens': 338.66407119021136, 'average_completion_tokens': 49.79866518353727}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 61.22, 'rawDetails': {'accuracy': 61.22, 'reject_info': {'reject_rate': 78.22, 'reject_number': 704, 'total_question': 900}, 'subject_score': {'Art': 73.33, 'Basic': 63.33, 'Biology': 56.25, 'Accounting': 50.0, 'Agriculture': 60.0, 'Architecture': 50.0}, 'average_tokens': 1131.8520408163265, 'difficulty_score': {'Easy': 72.46, 'Hard': 43.59, 'Medium': 60.23}, 'average_prompt_tokens': 1129.5, 'average_completion_tokens': 2.3520408163265305}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.134.194:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.167.201:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.72.204:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1226-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 23.657718120805367, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 23.630381924827848, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 64.0625, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 53.17460317460318, 'rawDetails': {}}] S
INFO:     100.64.78.198:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 50.28, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 203, 'correct': 93, 'accuracy': 45.81}, 'overall': {'num': 899, 'correct': 452, 'accuracy': 50.28}, 'accuracy': 50.28, 'reject_info': {'reject_rate': 0.11, 'reject_number': 1, 'total_question': 900}, 'average_tokens': 388.4627363737486, '健康与医学': {'num': 153, 'correct': 88, 'accuracy': 57.52}, '技术与工程': {'num': 244, 'correct': 112, 'accuracy': 45.9}, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, '人文社会科学': {'num': 85, 'correct': 58, 'accuracy': 68.24}, 'average_prompt_tokens': 338.66407119021136, 'average_completion_tokens': 49.79866518353727}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 61.22, 'rawDetails': {'accuracy': 61.22, 'reject_info': {'reject_rate': 78.22, 'reject_number': 704, 'total_question': 900}, 'subject_score': {'Art': 73.33, 'Basic': 63.33, 'Biology': 56.25, 'Accounting': 50.0, 'Agriculture': 60.0, 'Architecture': 50.0}, 'average_tokens': 1131.8520408163265, 'difficulty_score': {'Easy': 72.46, 'Hard': 43.59, 'Medium': 60.23}, 'average_prompt_tokens': 1129.5, 'average_completion_tokens': 2.3520408163265305}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.74.204:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-NVIDIA-Origin-1228 [{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.134.200:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-origin-1226 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 55.62080536912751, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 54.63885824381948, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 51.579122340425535, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 63.75661375661375, 'rawDetails': {}}] S
INFO:     100.67.163.206:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-flagos-1226 [{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.165.196:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8001/v1/chat/completions' model='Qwen3-30B-A3B' eval_model='qwen3-30b-a3b-hygon-gems-1228' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1228', 'online_model_name': 'Qwen3-30B-A3B', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.1.15.160:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28606, 'evaluationId': 1420}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1420, 'batch_id': 28606, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1420, 'batch_id': 28606, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.197:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1228 [] R
INFO:     100.64.134.211:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1228 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 55.62080536912751, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 54.63885824381948, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.238:8020/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-cambricon-flagos-1229' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-cambricon-flagos-1229', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.238:8020/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28607, 'evaluationId': 1421}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1421, 'batch_id': 28607, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1421, 'batch_id': 28607, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.210:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1228 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 55.62080536912751, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 54.63885824381948, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 51.579122340425535, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 63.75661375661375, 'rawDetails': {}}] S
INFO:     100.64.72.193:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8001/v1/chat/completions' model='Qwen3-30B-A3B' eval_model='qwen3-30b-a3b-hygon-gems-1228' base_model_name='Qwen3-30B-A3B-gems' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1228', 'online_model_name': 'Qwen3-30B-A3B', 'base_model_name': 'Qwen3-30B-A3B-gems', 'online_url': 'http://10.1.15.160:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28608, 'evaluationId': 1420}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1420, 'batch_id': 28608, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1420, 'batch_id': 28608, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.134.195:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1228 [] R
INFO:     100.64.169.198:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1228 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 86.66666666666667, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8001/v1/chat/completions' model='Qwen3-30B-A3B-Gems' eval_model='qwen3-30b-a3b-hygon-gems-1229' base_model_name='Qwen3-30B-A3B-gems' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1229', 'online_model_name': 'Qwen3-30B-A3B-Gems', 'base_model_name': 'Qwen3-30B-A3B-gems', 'online_url': 'http://10.1.15.160:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28609, 'evaluationId': 1422}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1422, 'batch_id': 28609, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1422, 'batch_id': 28609, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.167.206:2054 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229 [] R
INFO:     100.64.74.208:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229 [] R
INFO:     100.64.134.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-30b-a3b-hygon-gems-1229 [] R
INFO:     100.67.161.196:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-30b-a3b-hygon-gems-1229 28609 e8c8075d-5e11-4c6e-8e24-8b7e1bfb51c2
submit stop batch 28609
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.200:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8001/v1/chat/completions' model='Qwen3-30B-A3B-Gems' eval_model='qwen3-30b-a3b-hygon-gems-1229' base_model_name='Qwen3-30B-A3B-gems' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='max_gen_toks=30000,temperature=6,top_k=20,top_p=0.95' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1229', 'online_model_name': 'Qwen3-30B-A3B-Gems', 'base_model_name': 'Qwen3-30B-A3B-gems', 'online_url': 'http://10.1.15.160:8001/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'max_gen_toks=30000,temperature=6,top_k=20,top_p=0.95', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28610, 'evaluationId': 1422}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1422, 'batch_id': 28610, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1422, 'batch_id': 28610, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.193:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229 [] R
INFO:     100.64.167.205:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.149.203:2051 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-30b-a3b-hygon-gems-1229 [{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.151.193:2056 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8002/v1/chat/completions' model='Qwen3-30B-A3B-Gems-01' eval_model='qwen3-30b-a3b-hygon-gems-1229' base_model_name='Qwen3-30B-A3B-gems' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1229', 'online_model_name': 'Qwen3-30B-A3B-Gems-01', 'base_model_name': 'Qwen3-30B-A3B-gems', 'online_url': 'http://10.1.15.160:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.76.197:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8002/v1/chat/completions' model='Qwen3-30B-A3B-Gems-01' eval_model='qwen3-30b-a3b-hygon-gems-1229' base_model_name='Qwen3-30B-A3B-gems' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1229', 'online_model_name': 'Qwen3-30B-A3B-Gems-01', 'base_model_name': 'Qwen3-30B-A3B-gems', 'online_url': 'http://10.1.15.160:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.72.198:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.160:8002/v1/chat/completions' model='Qwen3-30B-A3B-Gems-01' eval_model='qwen3-30b-a3b-hygon-gems-1229-1337' base_model_name='Qwen3-30B-A3B' tokenizer='Qwen/Qwen3-30B-A3B' api_key='EMPTY' batch_size=64 num_concurrent=32 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-30B-A3B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-30b-a3b-hygon-gems-1229-1337', 'online_model_name': 'Qwen3-30B-A3B-Gems-01', 'base_model_name': 'Qwen3-30B-A3B', 'online_url': 'http://10.1.15.160:8002/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 64, 'num_concurrent': 32, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28611, 'evaluationId': 1423}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1423, 'batch_id': 28611, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1423, 'batch_id': 28611, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.212:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [] R
INFO:     100.67.165.206:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.211:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 50.28, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 203, 'correct': 93, 'accuracy': 45.81}, 'overall': {'num': 899, 'correct': 452, 'accuracy': 50.28}, 'accuracy': 50.28, 'reject_info': {'reject_rate': 0.11, 'reject_number': 1, 'total_question': 900}, 'average_tokens': 388.4627363737486, '健康与医学': {'num': 153, 'correct': 88, 'accuracy': 57.52}, '技术与工程': {'num': 244, 'correct': 112, 'accuracy': 45.9}, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, '人文社会科学': {'num': 85, 'correct': 58, 'accuracy': 68.24}, 'average_prompt_tokens': 338.66407119021136, 'average_completion_tokens': 49.79866518353727}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 61.22, 'rawDetails': {'accuracy': 61.22, 'reject_info': {'reject_rate': 78.22, 'reject_number': 704, 'total_question': 900}, 'subject_score': {'Art': 73.33, 'Basic': 63.33, 'Biology': 56.25, 'Accounting': 50.0, 'Agriculture': 60.0, 'Architecture': 50.0}, 'average_tokens': 1131.8520408163265, 'difficulty_score': {'Easy': 72.46, 'Hard': 43.59, 'Medium': 60.23}, 'average_prompt_tokens': 1129.5, 'average_completion_tokens': 2.3520408163265305}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.165.201:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1226-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 0.0, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 23.657718120805367, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 23.630381924827848, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 64.0625, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 53.17460317460318, 'rawDetails': {}}] S
INFO:     100.64.165.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.72.195:2050 - "POST /evaluation_progress HTTP/1.1" 422 Unprocessable Entity
get a new request
taskinfo eval_url='http://10.1.15.95:8004/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-hygon-flagos-1229-01' base_model_name='qwen3_8b' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='mtemperature=0.6,top_k=20,top_p=0.95' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-hygon-flagos-1229-01', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'qwen3_8b', 'online_url': 'http://10.1.15.95:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': 'mtemperature=0.6,top_k=20,top_p=0.95', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28612, 'evaluationId': 1424}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1424, 'batch_id': 28612, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1424, 'batch_id': 28612, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.200:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [] R
INFO:     100.64.134.201:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.175.197:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.200:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.149.204:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.207:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.195:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.195:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.163.211:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-cambricon-flagos-1226-01 [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 50.28, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 203, 'correct': 93, 'accuracy': 45.81}, 'overall': {'num': 899, 'correct': 452, 'accuracy': 50.28}, 'accuracy': 50.28, 'reject_info': {'reject_rate': 0.11, 'reject_number': 1, 'total_question': 900}, 'average_tokens': 388.4627363737486, '健康与医学': {'num': 153, 'correct': 88, 'accuracy': 57.52}, '技术与工程': {'num': 244, 'correct': 112, 'accuracy': 45.9}, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, '人文社会科学': {'num': 85, 'correct': 58, 'accuracy': 68.24}, 'average_prompt_tokens': 338.66407119021136, 'average_completion_tokens': 49.79866518353727}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 61.22, 'rawDetails': {'accuracy': 61.22, 'reject_info': {'reject_rate': 78.22, 'reject_number': 704, 'total_question': 900}, 'subject_score': {'Art': 73.33, 'Basic': 63.33, 'Biology': 56.25, 'Accounting': 50.0, 'Agriculture': 60.0, 'Architecture': 50.0}, 'average_tokens': 1131.8520408163265, 'difficulty_score': {'Easy': 72.46, 'Hard': 43.59, 'Medium': 60.23}, 'average_prompt_tokens': 1129.5, 'average_completion_tokens': 2.3520408163265305}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.169.195:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.212:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': 's/it]\rRequesting API:  23%|██▎       | 7/30 [10:52<35:58, 93.84s/it]\rRequesting API:  27%|██▋       | 8/30 [12:29<34:49, 95.00s/it]\rRequesting API:  30%|███       | 9/30 [14:34<36:29, 104.26s/it]\rRequesting API:  33%|███▎      | 10/30 [17:54<44:36, 133.85s/it]\rRequesting API:  37%|███▋      | 11/30 [18:45<34:21, 108.48s/it]\rRequesting API:  40%|████      | 12/30 [21:13<36:08, 120.48s/it]\rRequesting API:  43%|████▎     | 13/30 [22:55<32:33, 114.93s/it]\rRequesting API:  47%|████▋     | 14/30 [24:17<28:01, 105.12s/it]\rRequesting API:  50%|█████     | 15/30 [24:20<18:31, 74.11s/it] \rRequesting API:  53%|█████▎    | 16/30 [25:39<17:40, 75.79s/it]\rRequesting API:  57%|█████▋    | 17/30 [26:50<16:04, 74.18s/it]\rRequesting API:  60%|██████    | 18/30 [32:52<32:08, 160.69s/it]\rRequesting API:  63%|██████▎   | 19/30 [40:44<46:36, 254.24s/it]\rRequesting API:  67%|██████▋   | 20/30 [43:06<36:45, 220.58s/it]\rRequesting API:  70%|███████   | 21/30 [43:47<24:59, 166.57s/it]\rRequesting API:  73%|███████▎  | 22/30 [45:40<20:04, 150.61s/it]\rRequesting API:  77%|███████▋  | 23/30 [49:59<21:22, 183.20s/it]\rRequesting API:  80%|████████  | 24/30 [58:11<27:34, 275.74s/it]\rRequesting API:  83%|████████▎ | 25/30 [58:56<17:11, 206.39s/it]\rRequesting API:  87%|████████▋ | 26/30 [59:56<10:50, 162.72s/it]\rRequesting API:  90%|█████████ | 27/30 [1:16:24<20:30, 410.29s/it]\rRequesting API:  93%|█████████▎| 28/30 [1:22:56<13:29, 404.62s/it]', 'page': {'current': 4, 'total': 4}, 'err_code': 0}
INFO:     100.67.149.203:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.167.208:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.67.151.209:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.203:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 1, 'finishedDataset': 1, 'runningDataset': '', 'runningProgress': '   | 8/1192 [04:16<11:35:41, 35.25s/it]\rRequesting API:   1%|          | 9/1192 [04:27<9:10:37, 27.93s/it] \rRequesting API:   1%|          | 10/1192 [04:30<6:33:43, 19.99s/it]\rRequesting API:   1%|          | 11/1192 [05:03<7:56:22, 24.20s/it]\rRequesting API:   1%|          | 12/1192 [05:15<6:40:49, 20.38s/it]\rRequesting API:   1%|          | 13/1192 [06:11<10:11:20, 31.11s/it]\rRequesting API:   1%|          | 14/1192 [06:13<7:19:18, 22.38s/it] \rRequesting API:   1%|▏         | 15/1192 [10:16<29:06:14, 89.02s/it]\rRequesting API:   1%|▏         | 16/1192 [11:30<27:34:37, 84.42s/it]\rRequesting API:   1%|▏         | 17/1192 [12:08<22:59:52, 70.46s/it]\rRequesting API:   2%|▏         | 18/1192 [14:04<27:25:29, 84.10s/it]', 'page': {'current': 9, 'total': 9}, 'err_code': 0}
INFO:     100.64.74.195:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.173.196:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.169.199:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.169.206:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.203:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.196:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.134.212:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 57.38255033557047, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.194:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.198:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 1, 'finishedDataset': 1, 'runningDataset': '', 'runningProgress': '5<10:10:43, 34.31s/it]\rRequesting API:  10%|█         | 125/1192 [1:24:19<10:08:37, 34.22s/it]\rRequesting API:  11%|█         | 126/1192 [1:24:21<7:13:11, 24.38s/it] \rRequesting API:  11%|█         | 127/1192 [1:25:16<9:57:36, 33.67s/it]\rRequesting API:  11%|█         | 128/1192 [1:25:24<7:40:42, 25.98s/it]\rRequesting API:  11%|█         | 129/1192 [1:26:15<9:50:31, 33.33s/it]\rRequesting API:  11%|█         | 130/1192 [1:26:21<7:26:35, 25.23s/it]\rRequesting API:  11%|█         | 131/1192 [1:26:30<6:02:41, 20.51s/it]\rRequesting API:  11%|█         | 132/1192 [1:27:20<8:38:37, 29.36s/it]\rRequesting API:  11%|█         | 133/1192 [1:27:56<9:11:25, 31.24s/it]\rRequesting API:  11%|█         | 134/1192 [1:28:19<8:28:48, 28.85s/it]\rRequesting API:  11%|█▏        | 135/1192 [1:28:34<7:13:04, 24.58s/it]\rRequesting API:  11%|█▏        | 136/1192 [1:29:10<8:13:33, 28.04s/it]\rRequesting API:  11%|█▏        | 137/1192 [1:29:25<7:04:05, 24.12s/it]\rRequesting API:  12%|█▏        | 138/1192 [1:30:34<10:57:58, 37.46s/it]\rRequesting API:  12%|█▏        | 139/1192 [1:30:51<9:09:12, 31.29s/it] \rRequesting API:  12%|█▏        | 140/1192 [1:31:29<9:45:09, 33.37s/it]\rRequesting API:  12%|█▏        | 141/1192 [1:32:20<11:17:44, 38.69s/it]\rRequesting API:  12%|█▏        | 142/1192 [1:32:31<8:52:25, 30.42s/it] \rRequesting API:  12%|█▏        | 143/1192 [1:32:38<6:50:36, 23.49s/it]\rRequesting API:  12%|█▏        | 144/1192 [1:33:23<8:41:58, 29.88s/it]\rRequesting API:  12%|█▏        | 145/1192 [1:34:16<10:42:48, 36.84s/it]\rRequesting API:  12%|█▏        | 146/1192 [1:34:51<10:29:24, 36.10s/it]\rRequesting API:  12%|█▏        | 147/1192 [1:35:42<11:49:40, 40.75s/it]\rRequesting API:  12%|█▏        | 148/1192 [1:37:01<15:05:26, 52.04s/it]\rRequesting API:  12%|█▎        | 149/1192 [1:37:08<11:10:56, 38.60s/it]\rRequesting API:  13%|█▎        | 150/1192 [1:38:05<12:46:36, 44.14s/it]\rRequesting API:  13%|█▎        | 151/1192 [1:38:42<12:10:16, 42.09s/it]\rRequesting API:  13%|█▎        | 152/1192 [1:40:15<16:33:02, 57.29s/it]\rRequesting API:  13%|█▎        | 153/1192 [1:40:42<13:56:59, 48.33s/it]\rRequesting API:  13%|█▎        | 154/1192 [1:41:55<16:00:01, 55.49s/it]\rRequesting API:  13%|█▎        | 155/1192 [1:42:12<12:43:59, 44.20s/it]\rRequesting API:  13%|█▎        | 156/1192 [1:43:27<15:20:34, 53.32s/it]\rRequesting API:  13%|█▎        | 157/1192 [1:44:10<14:26:57, 50.26s/it]\rRequesting API:  13%|█▎        | 158/1192 [1:44:27<11:32:44, 40.20s/it]\rRequesting API:  13%|█▎        | 159/1192 [1:45:24<12:57:59, 45.19s/it]', 'page': {'current': 10, 'total': 10}, 'err_code': 0}
INFO:     100.64.169.209:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.175.193:2053 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.161.209:2055 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.161.206:2051 - "GET /nmaplowercheck1767003621 HTTP/1.1" 404 Not Found
INFO:     100.67.165.199:2049 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.173.209:2049 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     100.67.161.209:2056 - "GET /evox/about HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.200:2055 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.149.203:2053 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.161.211:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 1, 'finishedDataset': 1, 'runningDataset': '', 'runningProgress': '5<10:10:43, 34.31s/it]\rRequesting API:  10%|█         | 125/1192 [1:24:19<10:08:37, 34.22s/it]\rRequesting API:  11%|█         | 126/1192 [1:24:21<7:13:11, 24.38s/it] \rRequesting API:  11%|█         | 127/1192 [1:25:16<9:57:36, 33.67s/it]\rRequesting API:  11%|█         | 128/1192 [1:25:24<7:40:42, 25.98s/it]\rRequesting API:  11%|█         | 129/1192 [1:26:15<9:50:31, 33.33s/it]\rRequesting API:  11%|█         | 130/1192 [1:26:21<7:26:35, 25.23s/it]\rRequesting API:  11%|█         | 131/1192 [1:26:30<6:02:41, 20.51s/it]\rRequesting API:  11%|█         | 132/1192 [1:27:20<8:38:37, 29.36s/it]\rRequesting API:  11%|█         | 133/1192 [1:27:56<9:11:25, 31.24s/it]\rRequesting API:  11%|█         | 134/1192 [1:28:19<8:28:48, 28.85s/it]\rRequesting API:  11%|█▏        | 135/1192 [1:28:34<7:13:04, 24.58s/it]\rRequesting API:  11%|█▏        | 136/1192 [1:29:10<8:13:33, 28.04s/it]\rRequesting API:  11%|█▏        | 137/1192 [1:29:25<7:04:05, 24.12s/it]\rRequesting API:  12%|█▏        | 138/1192 [1:30:34<10:57:58, 37.46s/it]\rRequesting API:  12%|█▏        | 139/1192 [1:30:51<9:09:12, 31.29s/it] \rRequesting API:  12%|█▏        | 140/1192 [1:31:29<9:45:09, 33.37s/it]\rRequesting API:  12%|█▏        | 141/1192 [1:32:20<11:17:44, 38.69s/it]\rRequesting API:  12%|█▏        | 142/1192 [1:32:31<8:52:25, 30.42s/it] \rRequesting API:  12%|█▏        | 143/1192 [1:32:38<6:50:36, 23.49s/it]\rRequesting API:  12%|█▏        | 144/1192 [1:33:23<8:41:58, 29.88s/it]\rRequesting API:  12%|█▏        | 145/1192 [1:34:16<10:42:48, 36.84s/it]\rRequesting API:  12%|█▏        | 146/1192 [1:34:51<10:29:24, 36.10s/it]\rRequesting API:  12%|█▏        | 147/1192 [1:35:42<11:49:40, 40.75s/it]\rRequesting API:  12%|█▏        | 148/1192 [1:37:01<15:05:26, 52.04s/it]\rRequesting API:  12%|█▎        | 149/1192 [1:37:08<11:10:56, 38.60s/it]\rRequesting API:  13%|█▎        | 150/1192 [1:38:05<12:46:36, 44.14s/it]\rRequesting API:  13%|█▎        | 151/1192 [1:38:42<12:10:16, 42.09s/it]\rRequesting API:  13%|█▎        | 152/1192 [1:40:15<16:33:02, 57.29s/it]\rRequesting API:  13%|█▎        | 153/1192 [1:40:42<13:56:59, 48.33s/it]\rRequesting API:  13%|█▎        | 154/1192 [1:41:55<16:00:01, 55.49s/it]\rRequesting API:  13%|█▎        | 155/1192 [1:42:12<12:43:59, 44.20s/it]\rRequesting API:  13%|█▎        | 156/1192 [1:43:27<15:20:34, 53.32s/it]\rRequesting API:  13%|█▎        | 157/1192 [1:44:10<14:26:57, 50.26s/it]\rRequesting API:  13%|█▎        | 158/1192 [1:44:27<11:32:44, 40.20s/it]\rRequesting API:  13%|█▎        | 159/1192 [1:45:24<12:57:59, 45.19s/it]\rRequesting API:  13%|█▎        | 160/1192 [1:48:26<24:45:47, 86.38s/it]\rRequesting API:  14%|█▎        | 161/1192 [1:48:31<17:42:56, 61.86s/it]\rRequesting API:  14%|█▎        | 162/1192 [1:48:33<12:36:14, 44.05s/it]\rRequesting API:  14%|█▎        | 163/1192 [1:49:40<14:31:10, 50.80s/it]\rRequesting API:  14%|█▍        | 164/1192 [1:51:27<19:21:51, 67.81s/it]\rRequesting API:  14%|█▍        | 165/1192 [1:52:27<18:39:11, 65.39s/it]\rRequesting API:  14%|█▍        | 166/1192 [1:52:28<13:09:33, 46.17s/it]\rRequesting API:  14%|█▍        | 167/1192 [1:52:39<10:04:05, 35.36s/it]\rRequesting API:  14%|█▍        | 168/1192 [1:52:56<8:30:02, 29.89s/it] \rRequesting API:  14%|█▍        | 169/1192 [1:52:57<6:04:02, 21.35s/it]\rRequesting API:  14%|█▍        | 170/1192 [1:53:38<7:41:22, 27.09s/it]\rRequesting API:  14%|█▍        | 171/1192 [1:55:57<17:16:11, 60.89s/it]\rRequesting API:  14%|█▍        | 172/1192 [1:56:00<12:18:05, 43.42s/it]\rRequesting API:  15%|█▍        | 173/1192 [1:57:16<15:00:51, 53.04s/it]\rRequesting API:  15%|█▍        | 174/1192 [1:58:20<15:59:51, 56.57s/it]\rRequesting API:  15%|█▍        | 175/1192 [1:59:07<15:11:02, 53.75s/it]\rRequesting API:  15%|█▍        | 176/1192 [1:59:45<13:49:28, 48.98s/it]\rRequesting API:  15%|█▍        | 177/1192 [2:01:04<16:18:31, 57.84s/it]\rRequesting API:  15%|█▍        | 178/1192 [2:01:36<14:09:34, 50.27s/it]\rRequesting API:  15%|█▌        | 179/1192 [2:02:11<12:47:24, 45.45s/it]\rRequesting API:  15%|█▌        | 180/1192 [2:02:20<9:46:03, 34.75s/it] \rRequesting API:  15%|█▌        | 181/1192 [2:02:27<7:23:16, 26.31s/it]\rRequesting API:  15%|█▌        | 182/1192 [2:04:12<14:01:19, 49.98s/it]\rRequesting API:  15%|█▌        | 183/1192 [2:05:25<15:56:52, 56.90s/it]\rRequesting API:  15%|█▌        | 184/1192 [2:06:00<14:05:21, 50.32s/it]\rRequesting API:  16%|█▌        | 185/1192 [2:06:05<10:12:59, 36.52s/it]\rRequesting API:  16%|█▌        | 186/1192 [2:06:15<7:59:07, 28.58s/it] \rRequesting API:  16%|█▌        | 187/1192 [2:08:27<16:38:58, 59.64s/it]\rRequesting API:  16%|█▌        | 188/1192 [2:09:30<16:53:47, 60.58s/it]\rRequesting API:  16%|█▌        | 189/1192 [2:10:17<15:47:45, 56.70s/it]\rRequesting API:  16%|█▌        | 190/1192 [2:10:20<11:18:46, 40.64s/it]\rRequesting API:  16%|█▌        | 191/1192 [2:13:34<24:05:06, 86.62s/it]\rRequesting API:  16%|█▌        | 192/1192 [2:16:11<29:53:30, 107.61s/it]\rRequesting API:  16%|█▌        | 193/1192 [2:16:25<22:07:00, 79.70s/it] \rRequesting API:  16%|█▋        | 194/1192 [2:16:47<17:15:29, 62.25s/it]\rRequesting API:  16%|█▋        | 195/1192 [2:17:58<17:59:37, 64.97s/it]\rRequesting API:  16%|█▋        | 196/1192 [2:18:31<15:19:16, 55.38s/it]\rRequesting API:  17%|█▋        | 197/1192 [2:20:36<21:04:39, 76.26s/it]\rRequesting API:  17%|█▋        | 198/1192 [2:21:05<17:04:37, 61.85s/it]\rRequesting API:  17%|█▋        | 199/1192 [2:21:27<13:46:09, 49.92s/it]\rRequesting API:  17%|█▋        | 200/1192 [2:21:51<11:37:10, 42.17s/it]\rRequesting API:  17%|█▋        | 201/1192 [2:22:59<13:46:15, 50.03s/it]\rRequesting API:  17%|█▋        | 202/1192 [2:23:11<10:38:30, 38.70s/it]\rRequesting API:  17%|█▋        | 203/1192 [2:23:23<8:25:21, 30.66s/it] \rRequesting API:  17%|█▋        | 204/1192 [2:25:19<15:25:08, 56.18s/it]\rRequesting API:  17%|█▋        | 205/1192 [2:25:27<11:24:41, 41.62s/it]\rRequesting API:  17%|█▋        | 206/1192 [2:25:36<8:45:00, 31.95s/it] \rRequesting API:  17%|█▋        | 207/1192 [2:26:06<8:34:21, 31.33s/it]\rRequesting API:  17%|█▋        | 208/1192 [2:26:39<8:42:34, 31.86s/it]\rRequesting API:  18%|█▊        | 209/1192 [2:29:56<22:16:04, 81.55s/it]\rRequesting API:  18%|█▊        | 210/1192 [2:31:08<21:25:04, 78.52s/it]\rRequesting API:  18%|█▊        | 211/1192 [2:31:53<18:39:15, 68.46s/it]\rRequesting API:  18%|█▊        | 212/1192 [2:32:35<16:28:08, 60.50s/it]\rRequesting API:  18%|█▊        | 213/1192 [2:34:39<21:39:40, 79.65s/it]\rRequesting API:  18%|█▊        | 214/1192 [2:34:42<15:20:43, 56.49s/it]\rRequesting API:  18%|█▊        | 215/1192 [2:36:04<17:26:55, 64.29s/it]\rRequesting API:  18%|█▊        | 216/1192 [2:36:30<14:16:41, 52.67s/it]\rRequesting API:  18%|█▊        | 217/1192 [2:37:12<13:23:26, 49.44s/it]\rRequesting API:  18%|█▊        | 218/1192 [2:37:23<10:19:36, 38.17s/it]\rRequesting API:  18%|█▊        | 219/1192 [2:37:57<9:55:26, 36.72s/it] \rRequesting API:  18%|█▊        | 220/1192 [2:39:57<16:39:08, 61.67s/it]\rRequesting API:  19%|█▊        | 221/1192 [2:41:52<20:57:03, 77.68s/it]\rRequesting API:  19%|█▊        | 222/1192 [2:42:26<17:24:46, 64.62s/it]\rRequesting API:  19%|█▊        | 223/1192 [2:42:37<13:04:24, 48.57s/it]\rRequesting API:  19%|█▉        | 224/1192 [2:43:39<14:11:03, 52.75s/it]', 'page': {'current': 10, 'total': 10}, 'err_code': 0}
INFO:     100.67.151.212:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 57.38255033557047, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.208:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 57.38255033557047, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.193:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.167.199:2054 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.198:2052 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.200:2054 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.194:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': '      | 86/910 [2:09:00<32:29:16, 141.94s/it]\rRequesting API:  10%|▉         | 87/910 [2:21:07<72:35:22, 317.52s/it]\rRequesting API:  10%|▉         | 88/910 [2:29:34<85:30:08, 374.46s/it]\rRequesting API:  10%|▉         | 89/910 [2:34:30<79:58:51, 350.71s/it]\rRequesting API:  10%|▉         | 90/910 [2:37:22<67:42:42, 297.27s/it]\rRequesting API:  10%|█         | 91/910 [2:37:22<47:21:47, 208.19s/it]\rRequesting API:  10%|█         | 92/910 [2:39:51<43:14:27, 190.30s/it]\rRequesting API:  10%|█         | 93/910 [2:40:14<31:48:51, 140.19s/it]\rRequesting API:  10%|█         | 94/910 [2:40:49<24:34:37, 108.43s/it]\rRequesting API:  10%|█         | 95/910 [2:42:21<23:28:50, 103.72s/it]\rRequesting API:  11%|█         | 96/910 [2:42:25<16:38:36, 73.61s/it] \rRequesting API:  11%|█         | 97/910 [2:43:26<15:48:08, 69.97s/it]\rRequesting API:  11%|█         | 98/910 [2:47:32<27:42:30, 122.85s/it]\rRequesting API:  11%|█         | 99/910 [2:54:18<46:47:38, 207.72s/it]\rRequesting API:  11%|█         | 100/910 [2:55:27<37:21:32, 166.04s/it]\rRequesting API:  11%|█         | 101/910 [2:57:25<34:04:03, 151.60s/it]', 'page': {'current': 15, 'total': 15}, 'err_code': 0}
INFO:     100.67.175.206:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.167.199:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.76.198:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.149.208:2053 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.64.134.193:2049 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
INFO:     100.64.165.196:2050 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
INFO:     100.64.167.211:2050 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28617,"evaluationId":1429}
{'id': 28617, 'evaluationId': 1429}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1429, 'batch_id': 28617, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.72.193:2049 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.167.194:2049 - "POST /evaldiffs HTTP/1.1" 405 Method Not Allowed
INFO:     100.64.134.198:2050 - "GET /evaldiffs?request_id=4c32ee2b-5d21-41c1-beea-3c4f6f8f2c20 HTTP/1.1" 422 Unprocessable Entity
INFO:     100.64.76.195:2049 - "POST /evaldiffs HTTP/1.1" 405 Method Not Allowed
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.134.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.161.199:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.175.194:2054 - "GET /evaluation_progress HTTP/1.1" 405 Method Not Allowed
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '158/900', 'err_code': 0}
INFO:     100.64.78.204:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '174/900', 'err_code': 0}
INFO:     100.64.169.195:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '174/900', 'err_code': 0}
INFO:     100.67.161.202:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.169.206:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '174/900', 'err_code': 0}
INFO:     100.64.161.211:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '245/900', 'err_code': 0}
INFO:     100.64.134.199:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
robobrain2_3b-nv-flagos 28617 4c32ee2b-5d21-41c1-beea-3c4f6f8f2c20
submit stop batch 28617
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.161.194:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=1 num_concurrent=16 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 1, 'num_concurrent': 16, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28619,"evaluationId":1429}
{'id': 28619, 'evaluationId': 1429}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1429, 'batch_id': 28619, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.74.196:2049 - "POST /evaluation HTTP/1.1" 200 OK
loginfos {'err_code': 1, 'message': 'get log failed with:\n<!doctype html>\n<html lang="en">\n<head>\n  <title>Server Error (500)</title>\n</head>\n<body>\n  <h1>Server Error (500)</h1><p></p>\n</body>\n</html>\n'}
INFO:     100.64.169.200:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] C
INFO:     100.64.78.197:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
request_id: - d1a04ab3-4113-4e46-9ea2-00d865b285be query error: list index out of range
INFO:     100.64.169.200:2049 - "POST /evaluation_progress HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 249, in process_evaluation
    eval_model,batch_id,details,status = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
INFO:     100.64.169.205:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.78.208:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.169.201:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.134.199:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.78.212:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] C
INFO:     100.67.163.207:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [] R
INFO:     100.64.78.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.72.197:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.64.134.210:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.67.173.198:2055 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.64.78.203:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.64.76.205:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.64.78.206:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.64.167.199:2049 - "POST /evaluation HTTP/1.1" 200 OK
request_id: - d1a04ab3-4113-4e46-9ea2-00d865b285be query error: list index out of range
INFO:     100.64.161.199:2050 - "POST /stop_evaluation HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/protocols/http/httptools_impl.py", line 419, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py", line 84, in __call__
    return await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/applications.py", line 123, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 186, in __call__
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 758, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 778, in app
    await route.handle(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 299, in handle
    await self.app(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 79, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 64, in wrapped_app
    raise exc
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    await app(scope, receive, sender)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/starlette/routing.py", line 74, in app
    response = await func(request)
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 278, in app
    raw_response = await run_endpoint_function(
  File "/home/wanghui/lixuejing/conda-lmeval/lib/python3.10/site-packages/fastapi/routing.py", line 191, in run_endpoint_function
    return await dependant.call(**values)
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 220, in stopbatch
    eval_model,batch_id,details,_ = query(request.request_id)
  File "/home/wanghui/lixuejing/evaldiffs_online/utils.py", line 118, in query
    return eval_names, batch_id, details, status
UnboundLocalError: local variable 'batch_id' referenced before assignment
eval_model details status
qwen3-30b-a3b-hygon-gems-1229-1337 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 57.38255033557047, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 54.81060800125853, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 53.20811170212766, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 63.095238095238095, 'rawDetails': {}}] S
INFO:     100.67.173.205:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
robobrain2_3b-nv-flagos 28619 d1a04ab3-4113-4e46-9ea2-00d865b285be
submit stop batch 28619
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.203:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28620,"evaluationId":1429}
{'id': 28620, 'evaluationId': 1429}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1429, 'batch_id': 28620, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.134.204:2048 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.76.202:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [] R
INFO:     100.67.165.195:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.161.194:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.167.194:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.161.205:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.134.208:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.64.169.194:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '164/900', 'err_code': 0}
INFO:     100.67.161.206:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '174/900', 'err_code': 0}
INFO:     100.64.78.203:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '365/900', 'err_code': 0}
INFO:     100.64.134.195:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '365/900', 'err_code': 0}
INFO:     100.64.161.210:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.165.202:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '365/900', 'err_code': 0}
INFO:     100.64.74.209:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '365/900', 'err_code': 0}
INFO:     100.64.72.210:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '365/900', 'err_code': 0}
INFO:     100.64.167.193:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '585/900', 'err_code': 0}
INFO:     100.64.165.209:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '585/900', 'err_code': 0}
INFO:     100.64.167.204:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '517/517', 'err_code': 0}
INFO:     100.64.78.200:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos [{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 44.82, 'rawDetails': {'商业': {'num': 123, 'correct': 34, 'accuracy': 27.64}, '科学': {'num': 188, 'correct': 68, 'accuracy': 36.17}, 'overall': {'num': 859, 'correct': 385, 'accuracy': 44.82}, 'accuracy': 44.82, 'reject_info': {'reject_rate': 4.56, 'reject_number': 41, 'total_question': 900}, 'average_tokens': 462.0919674039581, '健康与医学': {'num': 151, 'correct': 76, 'accuracy': 50.33}, '技术与工程': {'num': 232, 'correct': 108, 'accuracy': 46.55}, '艺术与设计': {'num': 85, 'correct': 56, 'accuracy': 65.88}, '人文社会科学': {'num': 80, 'correct': 43, 'accuracy': 53.75}, 'average_prompt_tokens': 338.9871944121071, 'average_completion_tokens': 123.104772991851}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 47.15, 'rawDetails': {'accuracy': 47.15, 'reject_info': {'reject_rate': 4.33, 'reject_number': 39, 'total_question': 900}, 'subject_score': {'Art': 63.64, 'Math': 28.57, 'Basic': 56.67, 'Music': 48.0, 'Design': 63.33, 'Energy': 36.67, 'Manage': 37.93, 'Public': 56.67, 'Biology': 42.86, 'Finance': 20.0, 'History': 71.43, 'Physics': 40.0, 'Clinical': 44.83, 'Computer': 42.86, 'Pharmacy': 55.17, 'Chemistry': 20.0, 'Economics': 42.86, 'Geography': 48.28, 'Marketing': 43.33, 'Materials': 39.29, 'Sociology': 73.33, 'Accounting': 40.0, 'Literature': 82.76, 'Mechanical': 37.93, 'Psychology': 57.69, 'Agriculture': 53.33, 'Diagnostics': 41.38, 'Electronics': 20.0, 'Architecture': 41.38}, 'average_tokens': 723.8385598141696, 'difficulty_score': {'Easy': 60.92, 'Hard': 35.71, 'Medium': 42.3}, 'average_prompt_tokens': 721.6120789779326, 'average_completion_tokens': 2.226480836236934}}, {'status': 'S', 'dataset': 'MMMU_Pro_standard', 'accuracy': 31.95, 'rawDetails': {'accuracy': 31.95, 'reject_info': {'reject_rate': 7.92, 'reject_number': 137, 'total_question': 1730}, 'subject_score': {'Art': 50.94, 'Math': 18.97, 'Music': 22.92, 'Design': 58.33, 'Manage': 34.69, 'Biology': 35.29, 'Finance': 13.79, 'History': 48.94, 'Physics': 20.69, 'Pharmacy': 33.33, 'Chemistry': 30.0, 'Economics': 19.3, 'Geography': 29.55, 'Marketing': 29.63, 'Materials': 21.05, 'Sociology': 51.85, 'Accounting': 30.36, 'Art_Theory': 53.33, 'Literature': 65.31, 'Psychology': 32.61, 'Agriculture': 25.0, 'Electronics': 47.46, 'Public_Health': 22.81, 'Computer_Science': 34.0, 'Energy_and_Power': 27.59, 'Clinical_Medicine': 12.28, 'Basic_Medical_Science': 30.0, 'Mechanical_Engineering': 25.42, 'Architecture_and_Engineering': 23.64, 'Diagnostics_and_Laboratory_Medicine': 21.43}, 'average_tokens': 786.1324544883867, 'difficulty_score': {'Easy': 43.9, 'Hard': 23.16, 'Medium': 28.25}, 'average_prompt_tokens': 784.1148775894538, 'average_completion_tokens': 2.0175768989328313}}, {'status': 'S', 'dataset': 'MMMU_Pro_vision', 'accuracy': 23.93, 'rawDetails': {'accuracy': 23.93, 'subject_score': {'Art': 39.62, 'Math': 13.33, 'Music': 25.0, 'Design': 23.33, 'Manage': 40.0, 'Biology': 23.73, 'Finance': 15.0, 'History': 32.14, 'Physics': 16.67, 'Pharmacy': 29.82, 'Chemistry': 16.67, 'Economics': 18.64, 'Geography': 23.08, 'Marketing': 8.47, 'Materials': 23.33, 'Sociology': 40.74, 'Accounting': 24.14, 'Art_Theory': 32.73, 'Literature': 65.38, 'Psychology': 20.0, 'Agriculture': 13.33, 'Electronics': 23.33, 'Public_Health': 6.9, 'Computer_Science': 28.33, 'Energy_and_Power': 17.24, 'Clinical_Medicine': 13.56, 'Basic_Medical_Science': 34.62, 'Mechanical_Engineering': 27.12, 'Architecture_and_Engineering': 11.67, 'Diagnostics_and_Laboratory_Medicine': 23.33}, 'average_tokens': 3895.498843930636, 'average_prompt_tokens': 3891.9028901734105, 'average_completion_tokens': 3.5959537572254336}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.173.210:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '517/517', 'err_code': 0}
INFO:     100.67.161.207:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '517/517', 'err_code': 0}
INFO:     100.67.169.206:2055 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.173.206:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': ':01:54,  9.26s/it]\rRequesting API:  45%|████▍     | 323/723 [2:20:44<58:27,  8.77s/it]  \rRequesting API:  45%|████▍     | 324/723 [2:20:52<56:13,  8.45s/it]\rRequesting API:  45%|████▍     | 325/723 [2:20:53<41:58,  6.33s/it]\rRequesting API:  45%|████▌     | 326/723 [2:21:02<46:54,  7.09s/it]\rRequesting API:  45%|████▌     | 327/723 [2:21:05<36:59,  5.60s/it]\rRequesting API:  45%|████▌     | 328/723 [2:21:24<1:04:13,  9.75s/it]\rRequesting API:  46%|████▌     | 329/723 [2:21:30<56:48,  8.65s/it]  \rRequesting API:  46%|████▌     | 330/723 [2:21:33<45:50,  7.00s/it]\rRequesting API:  46%|████▌     | 331/723 [2:21:34<34:24,  5.27s/it]\rRequesting API:  46%|████▌     | 332/723 [2:21:39<32:05,  4.93s/it]\rRequesting API:  46%|████▌     | 333/723 [2:21:44<34:04,  5.24s/it]\rRequesting API:  46%|████▌     | 334/723 [2:21:56<46:20,  7.15s/it]\rRequesting API:  46%|████▋     | 335/723 [2:22:01<42:18,  6.54s/it]\rRequesting API:  46%|████▋     | 336/723 [2:22:03<32:30,  5.04s/it]\rRequesting API:  47%|████▋     | 337/723 [2:22:06<28:16,  4.39s/it]\rRequesting API:  47%|████▋     | 338/723 [2:22:24<55:16,  8.62s/it]\rRequesting API:  47%|████▋     | 339/723 [2:22:26<41:42,  6.52s/it]\rRequesting API:  47%|████▋     | 340/723 [2:22:26<29:42,  4.65s/it]\rRequesting API:  47%|████▋     | 341/723 [2:22:42<51:15,  8.05s/it]\rRequesting API:  47%|████▋     | 342/723 [2:22:43<38:15,  6.02s/it]\rRequesting API:  47%|████▋     | 343/723 [2:22:46<31:55,  5.04s/it]\rRequesting API:  48%|████▊     | 344/723 [2:22:52<32:51,  5.20s/it]\rRequesting API:  48%|████▊     | 345/723 [2:22:55<28:37,  4.54s/it]\rRequesting API:  48%|████▊     | 346/723 [2:22:57<24:18,  3.87s/it]\rRequesting API:  48%|████▊     | 347/723 [2:22:58<18:52,  3.01s/it]\rRequesting API:  48%|████▊     | 348/723 [2:23:07<29:57,  4.79s/it]\rRequesting API:  48%|████▊     | 349/723 [2:23:23<50:11,  8.05s/it]\rRequesting API:  48%|████▊     | 350/723 [2:23:32<52:38,  8.47s/it]\rRequesting API:  49%|████▊     | 351/723 [2:23:32<37:08,  5.99s/it]\rRequesting API:  49%|████▊     | 352/723 [2:23:42<43:19,  7.01s/it]\rRequesting API:  49%|████▉     | 353/723 [2:23:44<35:05,  5.69s/it]\rRequesting API:  49%|████▉     | 354/723 [2:23:53<41:35,  6.76s/it]\rRequesting API:  49%|████▉     | 356/723 [2:24:05<38:52,  6.36s/it]\rRequesting API:  49%|████▉     | 357/723 [2:24:08<33:29,  5.49s/it]\rRequesting API:  50%|████▉     | 358/723 [2:24:13<33:03,  5.43s/it]\rRequesting API:  50%|████▉     | 359/723 [2:24:23<40:19,  6.65s/it]\rRequesting API:  50%|████▉     | 360/723 [2:24:27<35:12,  5.82s/it]\rRequesting API:  50%|████▉     | 361/723 [2:24:29<28:16,  4.69s/it]', 'page': {'current': 14, 'total': 14}, 'err_code': 0}
INFO:     100.67.167.203:2054 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '1730/1730', 'err_code': 0}
INFO:     100.64.76.205:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': ':01:54,  9.26s/it]\rRequesting API:  45%|████▍     | 323/723 [2:20:44<58:27,  8.77s/it]  \rRequesting API:  45%|████▍     | 324/723 [2:20:52<56:13,  8.45s/it]\rRequesting API:  45%|████▍     | 325/723 [2:20:53<41:58,  6.33s/it]\rRequesting API:  45%|████▌     | 326/723 [2:21:02<46:54,  7.09s/it]\rRequesting API:  45%|████▌     | 327/723 [2:21:05<36:59,  5.60s/it]\rRequesting API:  45%|████▌     | 328/723 [2:21:24<1:04:13,  9.75s/it]\rRequesting API:  46%|████▌     | 329/723 [2:21:30<56:48,  8.65s/it]  \rRequesting API:  46%|████▌     | 330/723 [2:21:33<45:50,  7.00s/it]\rRequesting API:  46%|████▌     | 331/723 [2:21:34<34:24,  5.27s/it]\rRequesting API:  46%|████▌     | 332/723 [2:21:39<32:05,  4.93s/it]\rRequesting API:  46%|████▌     | 333/723 [2:21:44<34:04,  5.24s/it]\rRequesting API:  46%|████▌     | 334/723 [2:21:56<46:20,  7.15s/it]\rRequesting API:  46%|████▋     | 335/723 [2:22:01<42:18,  6.54s/it]\rRequesting API:  46%|████▋     | 336/723 [2:22:03<32:30,  5.04s/it]\rRequesting API:  47%|████▋     | 337/723 [2:22:06<28:16,  4.39s/it]\rRequesting API:  47%|████▋     | 338/723 [2:22:24<55:16,  8.62s/it]\rRequesting API:  47%|████▋     | 339/723 [2:22:26<41:42,  6.52s/it]\rRequesting API:  47%|████▋     | 340/723 [2:22:26<29:42,  4.65s/it]\rRequesting API:  47%|████▋     | 341/723 [2:22:42<51:15,  8.05s/it]\rRequesting API:  47%|████▋     | 342/723 [2:22:43<38:15,  6.02s/it]\rRequesting API:  47%|████▋     | 343/723 [2:22:46<31:55,  5.04s/it]\rRequesting API:  48%|████▊     | 344/723 [2:22:52<32:51,  5.20s/it]\rRequesting API:  48%|████▊     | 345/723 [2:22:55<28:37,  4.54s/it]\rRequesting API:  48%|████▊     | 346/723 [2:22:57<24:18,  3.87s/it]\rRequesting API:  48%|████▊     | 347/723 [2:22:58<18:52,  3.01s/it]\rRequesting API:  48%|████▊     | 348/723 [2:23:07<29:57,  4.79s/it]\rRequesting API:  48%|████▊     | 349/723 [2:23:23<50:11,  8.05s/it]\rRequesting API:  48%|████▊     | 350/723 [2:23:32<52:38,  8.47s/it]\rRequesting API:  49%|████▊     | 351/723 [2:23:32<37:08,  5.99s/it]\rRequesting API:  49%|████▊     | 352/723 [2:23:42<43:19,  7.01s/it]\rRequesting API:  49%|████▉     | 353/723 [2:23:44<35:05,  5.69s/it]\rRequesting API:  49%|████▉     | 354/723 [2:23:53<41:35,  6.76s/it]\rRequesting API:  49%|████▉     | 356/723 [2:24:05<38:52,  6.36s/it]\rRequesting API:  49%|████▉     | 357/723 [2:24:08<33:29,  5.49s/it]\rRequesting API:  50%|████▉     | 358/723 [2:24:13<33:03,  5.43s/it]\rRequesting API:  50%|████▉     | 359/723 [2:24:23<40:19,  6.65s/it]\rRequesting API:  50%|████▉     | 360/723 [2:24:27<35:12,  5.82s/it]\rRequesting API:  50%|████▉     | 361/723 [2:24:29<28:16,  4.69s/it]\rRequesting API:  50%|█████     | 362/723 [2:24:47<51:59,  8.64s/it]\rRequesting API:  50%|█████     | 363/723 [2:24:55<50:57,  8.49s/it]\rRequesting API:  50%|█████     | 364/723 [2:24:59<41:57,  7.01s/it]\rRequesting API:  50%|█████     | 365/723 [2:25:01<33:35,  5.63s/it]\rRequesting API:  51%|█████     | 366/723 [2:25:06<32:52,  5.52s/it]\rRequesting API:  51%|█████     | 367/723 [2:25:22<50:22,  8.49s/it]\rRequesting API:  51%|█████     | 369/723 [2:25:49<1:03:50, 10.82s/it]\rRequesting API:  51%|█████▏    | 371/723 [2:25:50<39:46,  6.78s/it]  \rRequesting API:  51%|█████▏    | 372/723 [2:25:55<36:57,  6.32s/it]\rRequesting API:  52%|█████▏    | 373/723 [2:26:04<40:15,  6.90s/it]\rRequesting API:  52%|█████▏    | 374/723 [2:26:12<42:04,  7.23s/it]\rRequesting API:  52%|█████▏    | 375/723 [2:26:23<48:44,  8.40s/it]\rRequesting API:  52%|█████▏    | 376/723 [2:26:26<38:56,  6.73s/it]\rRequesting API:  52%|█████▏    | 377/723 [2:26:27<30:26,  5.28s/it]\rRequesting API:  52%|█████▏    | 378/723 [2:26:29<24:21,  4.24s/it]\rRequesting API:  52%|█████▏    | 379/723 [2:26:37<29:52,  5.21s/it]\rRequesting API:  53%|█████▎    | 380/723 [2:26:46<37:14,  6.51s/it]\rRequesting API:  53%|█████▎    | 381/723 [2:27:07<1:01:31, 10.79s/it]\rRequesting API:  53%|█████▎    | 382/723 [2:27:12<50:28,  8.88s/it]  \rRequesting API:  53%|█████▎    | 383/723 [2:27:15<40:36,  7.17s/it]\rRequesting API:  53%|█████▎    | 384/723 [2:27:16<30:11,  5.35s/it]\rRequesting API:  53%|█████▎    | 385/723 [2:27:30<45:00,  7.99s/it]\rRequesting API:  53%|█████▎    | 386/723 [2:27:34<38:49,  6.91s/it]\rRequesting API:  54%|█████▎    | 387/723 [2:27:38<33:30,  5.98s/it]\rRequesting API:  54%|█████▎    | 388/723 [2:27:55<52:12,  9.35s/it]\rRequesting API:  54%|█████▍    | 389/723 [2:28:06<54:42,  9.83s/it]\rRequesting API:  54%|█████▍    | 390/723 [2:28:11<45:50,  8.26s/it]\rRequesting API:  54%|█████▍    | 391/723 [2:28:32<1:06:50, 12.08s/it]\rRequesting API:  54%|█████▍    | 392/723 [2:28:33<48:17,  8.75s/it]  \rRequesting API:  54%|█████▍    | 393/723 [2:28:37<40:11,  7.31s/it]\rRequesting API:  54%|█████▍    | 394/723 [2:28:48<46:31,  8.48s/it]\rRequesting API:  55%|█████▍    | 395/723 [2:28:49<34:40,  6.34s/it]\rRequesting API:  55%|█████▍    | 396/723 [2:28:56<35:14,  6.47s/it]\rRequesting API:  55%|█████▍    | 397/723 [2:29:46<1:46:27, 19.59s/it]\rRequesting API:  55%|█████▌    | 398/723 [2:29:56<1:29:08, 16.46s/it]\rRequesting API:  55%|█████▌    | 399/723 [2:30:00<1:08:39, 12.72s/it]', 'page': {'current': 14, 'total': 14}, 'err_code': 0}
INFO:     100.64.161.205:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
qwen2-5-vl-cambricon-flagos-1226-01 28596 7ae0ccc5-c279-4be6-b483-d857b37afb03
submit stop batch 28596
[{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 50.28, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 203, 'correct': 93, 'accuracy': 45.81}, 'overall': {'num': 899, 'correct': 452, 'accuracy': 50.28}, 'accuracy': 50.28, 'reject_info': {'reject_rate': 0.11, 'reject_number': 1, 'total_question': 900}, 'average_tokens': 388.4627363737486, '健康与医学': {'num': 153, 'correct': 88, 'accuracy': 57.52}, '技术与工程': {'num': 244, 'correct': 112, 'accuracy': 45.9}, '艺术与设计': {'num': 88, 'correct': 62, 'accuracy': 70.45}, '人文社会科学': {'num': 85, 'correct': 58, 'accuracy': 68.24}, 'average_prompt_tokens': 338.66407119021136, 'average_completion_tokens': 49.79866518353727}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 61.22, 'rawDetails': {'accuracy': 61.22, 'reject_info': {'reject_rate': 78.22, 'reject_number': 704, 'total_question': 900}, 'subject_score': {'Art': 73.33, 'Basic': 63.33, 'Biology': 56.25, 'Accounting': 50.0, 'Agriculture': 60.0, 'Architecture': 50.0}, 'average_tokens': 1131.8520408163265, 'difficulty_score': {'Easy': 72.46, 'Hard': 43.59, 'Medium': 60.23}, 'average_prompt_tokens': 1129.5, 'average_completion_tokens': 2.3520408163265305}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'S', 'dataset': 'MathVision', 'accuracy': 35.31, 'rawDetails': {'accuracy': 35.31, 'reject_info': {'reject_rate': 76.71, 'reject_number': 2332, 'total_question': 3040}, 'average_tokens': 2907.0466101694915, 'average_prompt_tokens': 2042.9025423728813, 'average_completion_tokens': 864.1440677966102}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.197:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [3767985]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
nohup: ignoring input
INFO:     Started server process [3769121]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos-EmbodiedVerse' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos-EmbodiedVerse' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
EmbodiedVerse ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos-EmbodiedVerse', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos-EmbodiedVerse', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28621,"evaluationId":1430}
{'id': 28621, 'evaluationId': 1430}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1430, 'batch_id': 28621, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.169.209:2050 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.124:8006/v1/chat/completions' model='/workspace/liuyanqing/qwen3_0_6B_mcore_to_hf_ckpt' eval_model='qwen3-0.6B-train-mcore_0' base_model_name='qwen3-0.6B-train' tokenizer='Qwen/Qwen-1_8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen-1_8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-0.6B-train-mcore_0', 'online_model_name': '/workspace/liuyanqing/qwen3_0_6B_mcore_to_hf_ckpt', 'base_model_name': 'qwen3-0.6B-train', 'online_url': 'http://10.1.15.124:8006/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-truthfulqa', 'lm_eval-winogrande', 'lm_eval-commonsense_qa', 'lm_eval-piqa', 'lm_eval-openbookqa', 'lm_eval-boolq', 'lm_eval-arc_easy', 'lm_eval-arc_challenge', 'lm_eval-minerva_math_algebra', 'lm_eval-mmlu', 'lm_eval-gsm8k', 'lm_eval-ceval-valid', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28622, 'evaluationId': 1431}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1431, 'batch_id': 28622, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1431, 'batch_id': 28622, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.72.198:2049 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.74.212:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.161.211:2054 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.149.194:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.72.199:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.149.196:2055 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.161.201:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.175.199:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.167.196:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen3-8B' eval_model='qwen3-8B-cambricon-flagos-1230-01' base_model_name='qwen3_8b' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=8 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8B-cambricon-flagos-1230-01', 'online_model_name': '/root/model/Qwen3-8B', 'base_model_name': 'qwen3_8b', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 8, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28623, 'evaluationId': 1432}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1432, 'batch_id': 28623, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1432, 'batch_id': 28623, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.76.194:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [] R
INFO:     100.64.76.202:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [] R
INFO:     100.64.165.193:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.203:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [] R
INFO:     100.64.74.196:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 70.71143617021278, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 61.772486772486765, 'rawDetails': {}}] S
INFO:     100.64.72.196:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.205:2053 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.211:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': "on3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n/root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2025-12-31:09:10:26 INFO     [__main__:338] Including path: /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19\n2025-12-31:09:10:28 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:09:10:29 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:09:10:29 INFO     [__main__:422] Selected Tasks: ['aime']\n2025-12-31:09:10:29 INFO     [evaluator:180] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2025-12-31:09:10:29 INFO     [evaluator:218] Initializing openai-chat-completions model, with arguments: {'model': '/root/model/Qwen3-8B', 'base_url': 'http://10.1.15.46:8004/v1/chat/completions', 'num_concurrent': 8, 're_try': 10}\n2025-12-31:09:10:29 WARNING  [models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.\n2025-12-31:09:10:29 INFO     [models.api_models:116] Using max length 2048 - 1\n2025-12-31:09:10:29 INFO     [models.api_models:134] Using tokenizer None\n2025-12-31:09:10:29 INFO     [evaluator:238] Using cache at /share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db\n2025-12-31:09:10:30 INFO     [evaluator:281] aime: Using gen_kwargs: {'temperature': 0.6, 'max_gen_toks': 32000, 'top_p': 0.95, 'until': []}\n2025-12-31:09:10:30 WARNING  [evaluator:446] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n2025-12-31:09:10:30 INFO     [api.task:426] Building contexts for aime on rank 0...\n\r  0%|          | 0/30 [00:00<?, ?it/s]\r100%|██████████| 30/30 [00:00<00:00, 2627.63it/s]\n2025-12-31:09:10:30 INFO     [evaluator:542] Running generate_until requests\n2025-12-31:09:10:30 INFO     [api.model:261] Loading 'generate_until' responses from cache '/share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db' where possible...\n\rChecking cached requests:   0%|          | 0/30 [00:00<?, ?it/s]\rChecking cached requests: 100%|██████████| 30/30 [00:00<00:00, 339.50it/s]\n2025-12-31:09:10:30 INFO     [api.model:287] Cached requests: 24, Requests remaining: 6\n2025-12-31:09:10:30 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2025-12-31:09:10:30 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/6 [00:00<?, ?it/s]", 'page': {'current': 3, 'total': 3}, 'err_code': 0}
INFO:     100.64.134.197:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.171.198:2052 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.210:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.151.194:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '1/10668 [06:06<70:15:46, 23.82s/it]\rRequesting API:   0%|          | 52/10668 [06:28<68:40:05, 23.29s/it]\rRequesting API:   0%|          | 53/10668 [06:49<66:38:23, 22.60s/it]\rRequesting API:   1%|          | 54/10668 [06:53<50:23:12, 17.09s/it]\rRequesting API:   1%|          | 55/10668 [07:08<47:59:42, 16.28s/it]\rRequesting API:   1%|          | 56/10668 [07:14<39:41:57, 13.47s/it]\rRequesting API:   1%|          | 57/10668 [07:16<29:31:46, 10.02s/it]\rRequesting API:   1%|          | 58/10668 [07:18<22:28:57,  7.63s/it]\rRequesting API:   1%|          | 59/10668 [07:34<29:49:58, 10.12s/it]\rRequesting API:   1%|          | 60/10668 [07:41<26:50:53,  9.11s/it]\rRequesting API:   1%|          | 61/10668 [07:52<28:55:12,  9.82s/it]\rRequesting API:   1%|          | 62/10668 [08:08<33:52:56, 11.50s/it]\rRequesting API:   1%|          | 63/10668 [08:11<26:39:25,  9.05s/it]\rRequesting API:   1%|          | 64/10668 [08:22<28:05:37,  9.54s/it]\rRequesting API:   1%|          | 65/10668 [08:28<25:07:25,  8.53s/it]\rRequesting API:   1%|          | 66/10668 [08:49<36:00:48, 12.23s/it]\rRequesting API:   1%|          | 67/10668 [09:56<84:40:55, 28.76s/it]\rRequesting API:   1%|          | 68/10668 [10:02<64:39:12, 21.96s/it]\rRequesting API:   1%|          | 69/10668 [10:42<80:38:54, 27.39s/it]\rRequesting API:   1%|          | 70/10668 [11:17<87:22:34, 29.68s/it]\rRequesting API:   1%|          | 71/10668 [11:53<92:26:29, 31.40s/it]\rRequesting API:   1%|          | 72/10668 [12:15<84:23:15, 28.67s/it]\rRequesting API:   1%|          | 73/10668 [12:30<71:51:23, 24.42s/it]\rRequesting API:   1%|          | 74/10668 [12:55<72:47:51, 24.74s/it]', 'page': {'current': 28, 'total': 28}, 'err_code': 0}
INFO:     100.67.149.197:2055 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.169.197:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos-EmbodiedVerse [{'status': 'S', 'dataset': 'ERQA', 'accuracy': 36.59, 'rawDetails': {'Other': 20.0, 'Pointing': 34.38, 'accuracy': 36.59, 'reject_info': {'reject_rate': 28.25, 'reject_number': 113, 'total_question': 400}, 'Task Reasoning': 56.25, 'average_tokens': 1207.006968641115, 'Action Reasoning': 40.91, 'State Estimation': 38.3, 'Spatial Reasoning': 24.56, 'Trajectory Reasoning': 39.06, 'average_prompt_tokens': 1180.0627177700349, 'average_completion_tokens': 26.94425087108014}}, {'status': 'S', 'dataset': 'Where2Place', 'accuracy': 65.71, 'rawDetails': {'avg': {'num': 100, 'score': 65.71043884220356, 'accuracy': 65.71}, 'seen': {'num': 70, 'score': 46.51396825396826, 'accuracy': 66.45}, 'unseen': {'num': 30, 'score': 19.196470588235293, 'accuracy': 63.99}, 'accuracy': 65.71, 'average_tokens': 632.54, 'average_prompt_tokens': 589.78, 'average_completion_tokens': 42.76}}, {'status': 'S', 'dataset': 'Blink', 'accuracy': 77.78, 'rawDetails': {'Counting': 64.17, 'accuracy': 77.78, 'reject_info': {'reject_rate': 44.08, 'reject_number': 305, 'total_question': 692}, 'Relative Depth': 88.71, 'average_tokens': 380.7700258397933, 'Spatial Relation': 79.72, 'average_prompt_tokens': 374.1059431524547, 'average_completion_tokens': 6.664082687338501}}, {'status': 'S', 'dataset': 'CVBench', 'accuracy': 86.57, 'rawDetails': {'accuracy': 86.57, 'accuracy_2d': 80.97, 'accuracy_3d': 92.17, 'average_tokens': 932.2300985595148, 'accuracy_2d_ade': 76.46, 'accuracy_2d_coco': 85.47, 'accuracy_3d_omni': 92.17, 'average_prompt_tokens': 930.2300985595148, 'average_completion_tokens': 2.0}}, {'status': 'S', 'dataset': 'EmbspatialBench', 'accuracy': 75.41, 'rawDetails': {'accuracy': 75.41, 'distance': 61.19, 'direction': 82.46, 'average_tokens': 771.1824175824175, 'average_prompt_tokens': 769.1824175824175, 'average_completion_tokens': 2.0}}, {'status': 'S', 'dataset': 'SAT', 'accuracy': 73.08, 'rawDetails': {'accuracy': 73.08, 'goal_aim': 85.29, 'perspective': 57.58, 'reject_info': {'reject_rate': 30.67, 'reject_number': 46, 'total_question': 150}, 'action_conseq': 75.68, 'average_tokens': 540.2115384615385, 'average_prompt_tokens': 515.2019230769231, 'average_completion_tokens': 25.009615384615383}}, {'status': 'C', 'dataset': 'VSI-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'S', 'dataset': 'RoboSpatial-Home', 'accuracy': 63.9124, 'rawDetails': {'accuracy': 63.9124, 'results_v2': {'context': {'total': 122, 'accuracy': 45.6502, 'num_correct': 55.69326797385622}, 'compatibility': {'total': 105, 'accuracy': 73.3333, 'num_correct': 77}, 'configuration': {'total': 123, 'accuracy': 73.9837, 'num_correct': 91}}, 'results_ori': {'context': {'total': 122, 'accuracy': 0.0, 'num_correct': 0, 'illformed_responses': 0}, 'compatibility': {'total': 105, 'accuracy': 73.3333, 'num_correct': 77, 'illformed_responses': 0}, 'configuration': {'total': 123, 'accuracy': 73.9837, 'num_correct': 91, 'illformed_responses': 0}}, 'accuracy_ori': 48.0, 'average_tokens': 3679.048571428571, 'average_prompt_tokens': 3651.3914285714286, 'average_completion_tokens': 27.65714285714286}}, {'status': 'C', 'dataset': 'All-Angles Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'C', 'dataset': 'EgoPlan-Bench2', 'accuracy': '', 'rawDetails': {}}, {'status': 'S', 'dataset': 'EmbodiedVerse-Open-Sampled', 'accuracy': 58.99, 'rawDetails': {'Dynamic': 62.07, 'Counting': 41.46, 'Planning': 42.86, 'accuracy': 58.99, 'Navigation': 25.0, 'Perception': 47.44, 'Prediction': 40.0, 'Trajectory': 41.94, 'reject_info': {'reject_rate': 56.17, 'reject_number': 1147, 'total_question': 2042}, 'Relative shape': 68.29, 'average_tokens': 1436.8, 'Depth estimation': 81.97, 'Visual Grounding': 53.3, 'Future prediction': 25.0, 'Relative distance': 61.64, 'Spatial Reasoning': 68.66, 'Goal Decomposition': 66.67, 'Relative direction': 71.04, 'average_prompt_tokens': 1419.5385474860336, 'average_completion_tokens': 17.261452513966482, 'State & Activity Understanding': 34.38}}, {'status': 'S', 'dataset': 'ERQAPlus', 'accuracy': 14.77, 'rawDetails': {'Planning': 7.14, 'accuracy': 14.77, 'Perception': 12.67, 'Prediction': 20.41, 'reject_info': {'reject_rate': 25.5, 'reject_number': 204, 'total_question': 800}, 'average_tokens': 1258.3825503355704, 'Spatial Reasoning': 17.39, 'average_prompt_tokens': 1086.8389261744967, 'average_completion_tokens': 171.54362416107384}}] OOR
INFO:     100.64.72.210:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [73560]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.165.201:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': "on3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n/root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2025-12-31:09:10:26 INFO     [__main__:338] Including path: /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19\n2025-12-31:09:10:28 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:09:10:29 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:09:10:29 INFO     [__main__:422] Selected Tasks: ['aime']\n2025-12-31:09:10:29 INFO     [evaluator:180] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2025-12-31:09:10:29 INFO     [evaluator:218] Initializing openai-chat-completions model, with arguments: {'model': '/root/model/Qwen3-8B', 'base_url': 'http://10.1.15.46:8004/v1/chat/completions', 'num_concurrent': 8, 're_try': 10}\n2025-12-31:09:10:29 WARNING  [models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.\n2025-12-31:09:10:29 INFO     [models.api_models:116] Using max length 2048 - 1\n2025-12-31:09:10:29 INFO     [models.api_models:134] Using tokenizer None\n2025-12-31:09:10:29 INFO     [evaluator:238] Using cache at /share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db\n2025-12-31:09:10:30 INFO     [evaluator:281] aime: Using gen_kwargs: {'temperature': 0.6, 'max_gen_toks': 32000, 'top_p': 0.95, 'until': []}\n2025-12-31:09:10:30 WARNING  [evaluator:446] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n2025-12-31:09:10:30 INFO     [api.task:426] Building contexts for aime on rank 0...\n\r  0%|          | 0/30 [00:00<?, ?it/s]\r100%|██████████| 30/30 [00:00<00:00, 2627.63it/s]\n2025-12-31:09:10:30 INFO     [evaluator:542] Running generate_until requests\n2025-12-31:09:10:30 INFO     [api.model:261] Loading 'generate_until' responses from cache '/share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db' where possible...\n\rChecking cached requests:   0%|          | 0/30 [00:00<?, ?it/s]\rChecking cached requests: 100%|██████████| 30/30 [00:00<00:00, 339.50it/s]\n2025-12-31:09:10:30 INFO     [api.model:287] Cached requests: 24, Requests remaining: 6\n2025-12-31:09:10:30 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2025-12-31:09:10:30 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/6 [00:00<?, ?it/s]", 'page': {'current': 3, 'total': 3}, 'err_code': 0}
INFO:     100.67.169.196:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.64.134.207:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos-EmbodiedVerse2' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='robobrain2_3b-nv-flagos' eval_model='robobrain2_3b-nv-flagos-EmbodiedVerse2' base_model_name='Qwen/Qwen2.5-VL-3B-Instruct' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
EmbodiedVerse ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos-EmbodiedVerse2', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain2_3b-nv-flagos-EmbodiedVerse2', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': 'robobrain2_3b-nv-flagos', 'base_model_name': 'Qwen/Qwen2.5-VL-3B-Instruct', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['ERQA', 'ERQAPlus', 'Where2Place', 'Blink_ev', 'CVBench', 'EmbspatialBench', 'SAT', 'VSI-Bench', 'RoboSpatial-Home', 'All-Angles Bench', 'EgoPlan-Bench2', 'EmbodiedVerse-Open-Sampled'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28630,"evaluationId":1434}
{'id': 28630, 'evaluationId': 1434}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1434, 'batch_id': 28630, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.72.206:2048 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.76.193:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.64.72.198:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': '19/400', 'err_code': 0}
INFO:     100.64.161.194:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28631,"evaluationId":1435}
{'id': 28631, 'evaluationId': 1435}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1435, 'batch_id': 28631, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.173.199:2051 - "POST /evaluation HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '1867/3640', 'err_code': 0}
INFO:     100.64.165.202:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '1867/3640', 'err_code': 0}
INFO:     100.64.161.196:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 4, 'runningDataset': '', 'runningProgress': '1867/3640', 'err_code': 0}
INFO:     100.64.134.194:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28632, 'evaluationId': 1436}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28632, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28632, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.169.203:2053 - "POST /evaluation HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 5, 'runningDataset': '', 'runningProgress': '20/150', 'err_code': 0}
INFO:     100.64.78.206:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
robobrain2_3b-nv-flagos-EmbodiedVerse2 [{'status': 'S', 'dataset': 'ERQA', 'accuracy': 39.48, 'rawDetails': {'Other': 35.71, 'Pointing': 41.94, 'accuracy': 39.48, 'reject_info': {'reject_rate': 3.75, 'reject_number': 15, 'total_question': 400}, 'Task Reasoning': 50.0, 'average_tokens': 1275.1636363636364, 'Action Reasoning': 40.3, 'State Estimation': 40.74, 'Spatial Reasoning': 28.57, 'Multi-view Reasoning': 54.05, 'Trajectory Reasoning': 36.67, 'average_prompt_tokens': 1263.0493506493506, 'average_completion_tokens': 12.114285714285714}}, {'status': 'S', 'dataset': 'Where2Place', 'accuracy': 62.39, 'rawDetails': {'avg': {'num': 100, 'score': 62.391671335200755, 'accuracy': 62.39}, 'seen': {'num': 70, 'score': 44.91141923436041, 'accuracy': 64.16}, 'unseen': {'num': 30, 'score': 17.48025210084034, 'accuracy': 58.27}, 'accuracy': 62.39, 'average_tokens': 637.04, 'average_prompt_tokens': 595.78, 'average_completion_tokens': 41.26}}, {'status': 'S', 'dataset': 'Blink', 'accuracy': 55.92, 'rawDetails': {'Counting': 64.17, 'accuracy': 55.92, 'Relative Depth': 88.71, 'average_tokens': 1319.0549132947976, 'Spatial Relation': 79.72, 'Multi-view Reasoning': 3.01, 'Visual Correspondence': 47.67, 'average_prompt_tokens': 1313.1604046242774, 'average_completion_tokens': 5.894508670520231}}, {'status': 'S', 'dataset': 'CVBench', 'accuracy': 86.51, 'rawDetails': {'accuracy': 86.51, 'accuracy_2d': 80.69, 'accuracy_3d': 92.33, 'average_tokens': 938.2300985595148, 'accuracy_2d_ade': 75.67, 'accuracy_2d_coco': 85.71, 'accuracy_3d_omni': 92.33, 'average_prompt_tokens': 936.2300985595148, 'average_completion_tokens': 2.0}}, {'status': 'S', 'dataset': 'EmbspatialBench', 'accuracy': 75.14, 'rawDetails': {'accuracy': 75.14, 'distance': 60.45, 'direction': 82.42, 'average_tokens': 777.1824175824175, 'average_prompt_tokens': 775.1824175824175, 'average_completion_tokens': 2.0}}, {'status': 'R', 'dataset': 'SAT', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'VSI-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'RoboSpatial-Home', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'All-Angles Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'EgoPlan-Bench2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'EmbodiedVerse-Open-Sampled', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'ERQAPlus', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.67.161.200:2055 - "GET /evaldiffs HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin 28632 802d91ed-1799-41d3-8a71-9878c81e880e
submit stop batch 28632
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.161.198:2055 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
Qnext ['MMMU', 'CMMMU']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28633,"evaluationId":1436}
{'id': 28633, 'evaluationId': 1436}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28633, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.74.211:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin 28633 83d98651-6d50-4f3f-bb2f-0b2d05113bc2
submit stop batch 28633
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.212:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_0' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_0' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
Qnext ['MMMU', 'CMMMU']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-Next-80B-A3B-Instruct_origin_0', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-Next-80B-A3B-Instruct_origin_0', 'online_api_key': 'EMPTY', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28634,"evaluationId":1437}
{'id': 28634, 'evaluationId': 1437}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1437, 'batch_id': 28634, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.134.211:2051 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin_0 28634 388f9c66-b07a-48fb-b20f-f3147b40864f
submit stop batch 28634
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.204:2049 - "POST /stop_evaluation HTTP/1.1" 200 OK
nohup: ignoring input
Traceback (most recent call last):
  File "/home/wanghui/lixuejing/evaldiffs_online/online_web.py", line 9, in <module>
    from submit import *
  File "/home/wanghui/lixuejing/evaldiffs_online/submit.py", line 96
    Robo_MMDataSets=[
IndentationError: unexpected indent
nohup: ignoring input
INFO:     Started server process [109439]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28635, 'evaluationId': 1436}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28635, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28635, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.175.194:2057 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.169.209:2054 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-t1 28631 51f7ed51-5c77-4b93-beac-7addaa3a5110
submit stop batch 28631
[{'status': 'S', 'dataset': 'CMMMU', 'accuracy': 45.56, 'rawDetails': {'商业': {'num': 126, 'correct': 39, 'accuracy': 30.95}, '科学': {'num': 204, 'correct': 78, 'accuracy': 38.24}, 'overall': {'num': 900, 'correct': 410, 'accuracy': 45.56}, 'accuracy': 45.56, 'average_tokens': 292.6144444444444, '健康与医学': {'num': 153, 'correct': 85, 'accuracy': 55.56}, '技术与工程': {'num': 244, 'correct': 99, 'accuracy': 40.57}, '艺术与设计': {'num': 88, 'correct': 57, 'accuracy': 64.77}, '人文社会科学': {'num': 85, 'correct': 52, 'accuracy': 61.18}, 'average_prompt_tokens': 289.07444444444445, 'average_completion_tokens': 3.54}}, {'status': 'S', 'dataset': 'MMMU', 'accuracy': 57.0, 'rawDetails': {'accuracy': 57.0, 'subject_score': {'Art': 80.0, 'Math': 53.33, 'Basic': 66.67, 'Music': 43.33, 'Design': 76.67, 'Energy': 50.0, 'Manage': 40.0, 'Public': 63.33, 'Biology': 53.33, 'Finance': 36.67, 'History': 63.33, 'Physics': 63.33, 'Clinical': 63.33, 'Computer': 56.67, 'Pharmacy': 50.0, 'Chemistry': 40.0, 'Economics': 66.67, 'Geography': 53.33, 'Marketing': 66.67, 'Materials': 43.33, 'Sociology': 60.0, 'Accounting': 60.0, 'Literature': 86.67, 'Mechanical': 50.0, 'Psychology': 63.33, 'Agriculture': 60.0, 'Diagnostics': 36.67, 'Electronics': 40.0, 'Architecture': 43.33}, 'average_tokens': 1504.0388888888888, 'difficulty_score': {'Easy': 68.81, 'Hard': 42.54, 'Medium': 54.95}, 'average_prompt_tokens': 594.1533333333333, 'average_completion_tokens': 909.8855555555556}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.165.196:2054 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-t1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-t1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.171.200:2048 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-ts1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-ts1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-ts1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-ts1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28636,"evaluationId":1438}
{'id': 28636, 'evaluationId': 1438}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1438, 'batch_id': 28636, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.149.208:2054 - "POST /evaluation HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 8, 'runningDataset': '', 'runningProgress': '9/2132', 'err_code': 0}
INFO:     100.64.72.207:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin 28635 44f1ef00-0687-45e0-9456-93604cc998fd
submit stop batch 28635
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.208:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': ''}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28637, 'evaluationId': 1436}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28637, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28637, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.207:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMMU', 'CMMMU', 'MMBench_en', 'MathVision']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMBench_en', 'MathVision'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMBench_en', 'MathVision'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28638,"evaluationId":1439}
{'id': 28638, 'evaluationId': 1439}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1439, 'batch_id': 28638, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.165.209:2057 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.134.201:2050 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin 28637 0ead13bd-9eb5-46ef-b573-65d0084a2166
submit stop batch 28637
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.201:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28639, 'evaluationId': 1436}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28639, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1436, 'batch_id': 28639, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.167.195:2057 - "POST /evaluation HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 8, 'runningDataset': '', 'runningProgress': '277/2132', 'err_code': 0}
INFO:     100.64.161.211:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [120263]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
Qwen3-Next-80B-A3B-Instruct_origin 28639 26d8f890-70e8-4828-a270-e0347b0dddc0
submit stop batch 28639
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.169.211:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_1' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin_1', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 4, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28640, 'evaluationId': 1440}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1440, 'batch_id': 28640, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1440, 'batch_id': 28640, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.165.211:2049 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-1 28638 24463e95-755f-4c65-acab-531e7c3efb72
submit stop batch 28638
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.173.208:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 8, 'runningDataset': '', 'runningProgress': '390/2132', 'err_code': 0}
INFO:     100.64.78.208:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'F', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.67.169.212:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28641,"evaluationId":1401}
{'id': 28641, 'evaluationId': 1401}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1401, 'batch_id': 28641, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.175.212:2053 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-test1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-test1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.67.149.197:2056 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test1 28641 b6deae95-aea1-4e9a-859a-414e1c71a959
submit stop batch 28641
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.165.195:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-test1 28641 b6deae95-aea1-4e9a-859a-414e1c71a959
submit stop batch 28641
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.151.212:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-tes1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-tes1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-tes1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-tes1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28642,"evaluationId":1441}
{'id': 28642, 'evaluationId': 1441}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1441, 'batch_id': 28642, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.209:2055 - "POST /evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.210:2058 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.167.199:2055 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
Qwen3-VL-8B-Instruct-test1 28641 b6deae95-aea1-4e9a-859a-414e1c71a959
submit stop batch 28641
[] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.167.204:2054 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-tes1 28642 597ac171-ea97-4148-9c10-062badf2ded7
submit stop batch 28642
[{'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.163.209:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-tes1 28642 597ac171-ea97-4148-9c10-062badf2ded7
submit stop batch 28642
[{'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.149.193:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-tes1 28642 597ac171-ea97-4148-9c10-062badf2ded7
submit stop batch 28642
[{'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.165.211:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-tes1 28642 597ac171-ea97-4148-9c10-062badf2ded7
submit stop batch 28642
[{'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.163.212:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
Qwen3-VL-8B-Instruct-tes1 28642 597ac171-ea97-4148-9c10-062badf2ded7
submit stop batch 28642
[{'status': 'R', 'dataset': 'MMBench_en', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.173.207:2055 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-ce1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8000/v1/chat/completions' model='/share/project/fengli/model/Qwen3-VL-8B-Instruct' eval_model='Qwen3-VL-8B-Instruct-ce1' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='Qwen3-VL-8B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-ce1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'Qwen3-VL-8B-Instruct-ce1', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8000/v1/chat/completions', 'online_model_name': '/share/project/fengli/model/Qwen3-VL-8B-Instruct', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28643,"evaluationId":1442}
{'id': 28643, 'evaluationId': 1442}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1442, 'batch_id': 28643, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.203:2054 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.173.203:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_2' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin_2', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28644, 'evaluationId': 1443}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1443, 'batch_id': 28644, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1443, 'batch_id': 28644, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.197:2048 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin_1 28640 271c1b45-c9e8-4519-a541-8b7cd5d78126
submit stop batch 28640
[{'status': 'R', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.169.197:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.195:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.204:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.200:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.194:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.197:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': "on3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n/root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2025-12-31:12:14:26 INFO     [__main__:338] Including path: /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19\n2025-12-31:12:14:28 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:12:14:29 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:12:14:29 INFO     [__main__:422] Selected Tasks: ['aime']\n2025-12-31:12:14:29 INFO     [evaluator:180] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2025-12-31:12:14:29 INFO     [evaluator:218] Initializing openai-chat-completions model, with arguments: {'model': '/root/model/Qwen3-8B', 'base_url': 'http://10.1.15.46:8004/v1/chat/completions', 'num_concurrent': 8, 're_try': 10}\n2025-12-31:12:14:29 WARNING  [models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.\n2025-12-31:12:14:29 INFO     [models.api_models:116] Using max length 2048 - 1\n2025-12-31:12:14:29 INFO     [models.api_models:134] Using tokenizer None\n2025-12-31:12:14:29 INFO     [evaluator:238] Using cache at /share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db\n2025-12-31:12:14:30 INFO     [evaluator:281] aime: Using gen_kwargs: {'temperature': 0.6, 'max_gen_toks': 32000, 'top_p': 0.95, 'until': []}\n2025-12-31:12:14:30 WARNING  [evaluator:446] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n2025-12-31:12:14:30 INFO     [api.task:426] Building contexts for aime on rank 0...\n\r  0%|          | 0/30 [00:00<?, ?it/s]\r100%|██████████| 30/30 [00:00<00:00, 2742.93it/s]\n2025-12-31:12:14:30 INFO     [evaluator:542] Running generate_until requests\n2025-12-31:12:14:30 INFO     [api.model:261] Loading 'generate_until' responses from cache '/share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db' where possible...\n\rChecking cached requests:   0%|          | 0/30 [00:00<?, ?it/s]\rChecking cached requests: 100%|██████████| 30/30 [00:00<00:00, 371.77it/s]\n2025-12-31:12:14:30 INFO     [api.model:287] Cached requests: 24, Requests remaining: 6\n2025-12-31:12:14:30 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2025-12-31:12:14:30 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/6 [00:00<?, ?it/s]", 'page': {'current': 3, 'total': 3}, 'err_code': 0}
INFO:     100.64.167.205:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.197:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': ':04:31<46:21:29, 16.66s/it]\rRequesting API:   1%|▏         | 143/10157 [1:04:56<53:53:21, 19.37s/it]\rRequesting API:   1%|▏         | 144/10157 [1:05:14<52:42:12, 18.95s/it]\rRequesting API:   1%|▏         | 145/10157 [1:05:23<44:28:27, 15.99s/it]\rRequesting API:   1%|▏         | 146/10157 [1:05:34<39:53:12, 14.34s/it]\rRequesting API:   1%|▏         | 147/10157 [1:05:36<29:58:36, 10.78s/it]\rRequesting API:   1%|▏         | 148/10157 [1:05:40<24:29:28,  8.81s/it]\rRequesting API:   1%|▏         | 149/10157 [1:05:58<32:01:38, 11.52s/it]\rRequesting API:   1%|▏         | 150/10157 [1:06:25<44:54:43, 16.16s/it]\rRequesting API:   1%|▏         | 151/10157 [1:06:35<39:31:27, 14.22s/it]\rRequesting API:   1%|▏         | 152/10157 [1:06:37<29:28:19, 10.60s/it]\rRequesting API:   2%|▏         | 153/10157 [1:07:12<49:58:05, 17.98s/it]\rRequesting API:   2%|▏         | 154/10157 [1:07:14<35:58:01, 12.94s/it]\rRequesting API:   2%|▏         | 155/10157 [1:07:30<38:46:49, 13.96s/it]\rRequesting API:   2%|▏         | 156/10157 [1:08:12<62:09:29, 22.37s/it]\rRequesting API:   2%|▏         | 157/10157 [1:08:40<66:58:06, 24.11s/it]\rRequesting API:   2%|▏         | 158/10157 [1:09:05<67:47:39, 24.41s/it]\rRequesting API:   2%|▏         | 159/10157 [1:09:22<61:07:35, 22.01s/it]\rRequesting API:   2%|▏         | 160/10157 [1:10:29<98:44:45, 35.56s/it]\rRequesting API:   2%|▏         | 161/10157 [1:11:29<119:00:00, 42.86s/it]\rRequesting API:   2%|▏         | 162/10157 [1:12:48<149:31:02, 53.85s/it]\rRequesting API:   2%|▏         | 163/10157 [1:14:11<174:02:53, 62.69s/it]', 'page': {'current': 29, 'total': 29}, 'err_code': 0}
INFO:     100.64.161.206:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.205:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': "on3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n/root/online_third_party/env/venv.28623-lmeval/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2025-12-31:12:14:26 INFO     [__main__:338] Including path: /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19\n2025-12-31:12:14:28 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:12:14:29 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2025-12-31:12:14:29 INFO     [__main__:422] Selected Tasks: ['aime']\n2025-12-31:12:14:29 INFO     [evaluator:180] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2025-12-31:12:14:29 INFO     [evaluator:218] Initializing openai-chat-completions model, with arguments: {'model': '/root/model/Qwen3-8B', 'base_url': 'http://10.1.15.46:8004/v1/chat/completions', 'num_concurrent': 8, 're_try': 10}\n2025-12-31:12:14:29 WARNING  [models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.\n2025-12-31:12:14:29 INFO     [models.api_models:116] Using max length 2048 - 1\n2025-12-31:12:14:29 INFO     [models.api_models:134] Using tokenizer None\n2025-12-31:12:14:29 INFO     [evaluator:238] Using cache at /share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db\n2025-12-31:12:14:30 INFO     [evaluator:281] aime: Using gen_kwargs: {'temperature': 0.6, 'max_gen_toks': 32000, 'top_p': 0.95, 'until': []}\n2025-12-31:12:14:30 WARNING  [evaluator:446] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.\n2025-12-31:12:14:30 INFO     [api.task:426] Building contexts for aime on rank 0...\n\r  0%|          | 0/30 [00:00<?, ?it/s]\r100%|██████████| 30/30 [00:00<00:00, 2742.93it/s]\n2025-12-31:12:14:30 INFO     [evaluator:542] Running generate_until requests\n2025-12-31:12:14:30 INFO     [api.model:261] Loading 'generate_until' responses from cache '/share/project/flageval/eval_caches//root/model/Qwen3-8B/aime_rank0.db' where possible...\n\rChecking cached requests:   0%|          | 0/30 [00:00<?, ?it/s]\rChecking cached requests: 100%|██████████| 30/30 [00:00<00:00, 371.77it/s]\n2025-12-31:12:14:30 INFO     [api.model:287] Cached requests: 24, Requests remaining: 6\n2025-12-31:12:14:30 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2025-12-31:12:14:30 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/6 [00:00<?, ?it/s]", 'page': {'current': 3, 'total': 3}, 'err_code': 0}
INFO:     100.67.151.203:2053 - "POST /evaluation_progress HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8001/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/robobrain-v2_5-stage1-datav2' eval_model='robobrain-v2_5-stage1-datav2' base_model_name='robobrain-v2_5-stage1-datav2' tokenizer='robobrain-v2_5-stage1-datav2' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8001/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/robobrain-v2_5-stage1-datav2' eval_model='robobrain-v2_5-stage1-datav2' base_model_name='robobrain-v2_5-stage1-datav2' tokenizer='robobrain-v2_5-stage1-datav2' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain-v2_5-stage1-datav2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8001/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/robobrain-v2_5-stage1-datav2', 'base_model_name': 'robobrain-v2_5-stage1-datav2', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'robobrain-v2_5-stage1-datav2', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8001/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/robobrain-v2_5-stage1-datav2', 'base_model_name': 'robobrain-v2_5-stage1-datav2', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28646,"evaluationId":1445}
{'id': 28646, 'evaluationId': 1445}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1445, 'batch_id': 28646, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.173.207:2056 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8002/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_spatial_only' eval_model='train_qwen3_vl_8b_data_spatial_only' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_spatial_only' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8002/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_spatial_only' eval_model='train_qwen3_vl_8b_data_spatial_only' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_spatial_only' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_spatial_only', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8002/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_spatial_only', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_spatial_only', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8002/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_spatial_only', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28647,"evaluationId":1446}
{'id': 28647, 'evaluationId': 1446}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1446, 'batch_id': 28647, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.198:2051 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.73.150:8003/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_rb2_only' eval_model='train_qwen3_vl_8b_data_rb2_only' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_rb2_only' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.73.150:8003/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_rb2_only' eval_model='train_qwen3_vl_8b_data_rb2_only' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_rb2_only' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_rb2_only', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8003/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_rb2_only', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_rb2_only', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.73.150:8003/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_rb2_only', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28648,"evaluationId":1447}
{'id': 28648, 'evaluationId': 1447}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1447, 'batch_id': 28648, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.163.207:2053 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.244.118:8001/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v3' eval_model='train_qwen3_vl_8b_data_v3' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v3' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.244.118:8001/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v3' eval_model='train_qwen3_vl_8b_data_v3' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v3' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8001/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v3', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v3', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8001/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v3', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28649,"evaluationId":1448}
{'id': 28649, 'evaluationId': 1448}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1448, 'batch_id': 28649, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.161.211:2055 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.244.118:8000/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v2_lr_x5' eval_model='train_qwen3_vl_8b_data_v2_lr_x5' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v2_lr_x5' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.244.118:8000/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v2_lr_x5' eval_model='train_qwen3_vl_8b_data_v2_lr_x5' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v2_lr_x5' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v2_lr_x5', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8000/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v2_lr_x5', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v2_lr_x5', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8000/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v2_lr_x5', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28650,"evaluationId":1449}
{'id': 28650, 'evaluationId': 1449}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1449, 'batch_id': 28650, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.171.202:2053 - "POST /evaluation HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [203927]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
Qwen3-Next-80B-A3B-Instruct_origin_2 28644 169d5aaa-ab51-4ecf-ac34-768eafbacd42
submit stop batch 28644
[{'status': 'R', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.211:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_3' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin_3', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code500', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code500', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.167.197:2049 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8888/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_3' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin_3', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8888/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28651, 'evaluationId': 1450}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1450, 'batch_id': 28651, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1450, 'batch_id': 28651, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.134.203:2049 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin_2 28644 169d5aaa-ab51-4ecf-ac34-768eafbacd42
submit stop batch 28644
[{'status': 'R', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.165.195:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1225 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 70.71143617021278, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 61.772486772486765, 'rawDetails': {}}] S
INFO:     100.64.74.208:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1225 28594 a805ae60-d2e5-4ed4-b518-2cb4f583cee0
submit stop batch 28594
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 76.66666666666667, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.40604026845637, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 49.734056167972426, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MMLU', 'accuracy': 70.71143617021278, 'rawDetails': {}}, {'status': 'S', 'dataset': 'MuSR', 'accuracy': 61.772486772486765, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.209:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.204:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'g API:   2%|▏         | 251/10157 [1:57:06<108:34:07, 39.46s/it]\rRequesting API:   2%|▏         | 252/10157 [1:57:41<105:03:37, 38.18s/it]\rRequesting API:   2%|▏         | 253/10157 [1:58:30<114:21:37, 41.57s/it]\rRequesting API:   3%|▎         | 254/10157 [1:59:46<142:26:23, 51.78s/it]\rRequesting API:   3%|▎         | 255/10157 [2:00:38<142:14:59, 51.72s/it]\rRequesting API:   3%|▎         | 256/10157 [2:00:42<103:22:51, 37.59s/it]\rRequesting API:   3%|▎         | 257/10157 [2:00:52<80:40:32, 29.34s/it] \rRequesting API:   3%|▎         | 258/10157 [2:00:59<62:01:16, 22.56s/it]\rRequesting API:   3%|▎         | 259/10157 [2:01:19<60:01:53, 21.83s/it]\rRequesting API:   3%|▎         | 260/10157 [2:01:30<51:20:22, 18.67s/it]\rRequesting API:   3%|▎         | 261/10157 [2:01:47<49:18:29, 17.94s/it]\rRequesting API:   3%|▎         | 262/10157 [2:02:32<72:00:56, 26.20s/it]\rRequesting API:   3%|▎         | 263/10157 [2:02:42<58:17:16, 21.21s/it]\rRequesting API:   3%|▎         | 264/10157 [2:02:58<54:04:02, 19.67s/it]\rRequesting API:   3%|▎         | 265/10157 [2:03:14<51:35:10, 18.77s/it]\rRequesting API:   3%|▎         | 266/10157 [2:04:13<84:40:13, 30.82s/it]\rRequesting API:   3%|▎         | 267/10157 [2:04:32<74:15:00, 27.03s/it]\rRequesting API:   3%|▎         | 268/10157 [2:04:33<53:04:53, 19.32s/it]\rRequesting API:   3%|▎         | 269/10157 [2:04:39<42:00:52, 15.30s/it]\rRequesting API:   3%|▎         | 270/10157 [2:04:55<43:08:18, 15.71s/it]\rRequesting API:   3%|▎         | 271/10157 [2:05:34<61:55:58, 22.55s/it]\rRequesting API:   3%|▎         | 272/10157 [2:06:01<65:57:36, 24.02s/it]\rRequesting API:   3%|▎         | 273/10157 [2:06:10<53:19:25, 19.42s/it]\rRequesting API:   3%|▎         | 274/10157 [2:06:39<60:57:39, 22.21s/it]\rRequesting API:   3%|▎         | 275/10157 [2:07:27<82:08:34, 29.92s/it]\rRequesting API:   3%|▎         | 276/10157 [2:08:32<111:00:09, 40.44s/it]\rRequesting API:   3%|▎         | 277/10157 [2:08:34<79:21:29, 28.92s/it] \rRequesting API:   3%|▎         | 278/10157 [2:10:52<168:56:58, 61.57s/it]\rRequesting API:   3%|▎         | 279/10157 [2:11:38<156:06:37, 56.89s/it]\rRequesting API:   3%|▎         | 280/10157 [2:11:50<119:46:42, 43.66s/it]\rRequesting API:   3%|▎         | 281/10157 [2:11:55<87:38:57, 31.95s/it] \rRequesting API:   3%|▎         | 282/10157 [2:12:02<67:16:14, 24.52s/it]\rRequesting API:   3%|▎         | 283/10157 [2:12:17<59:37:00, 21.74s/it]\rRequesting API:   3%|▎         | 284/10157 [2:12:36<57:10:18, 20.85s/it]\rRequesting API:   3%|▎         | 285/10157 [2:13:08<66:04:12, 24.09s/it]\rRequesting API:   3%|▎         | 286/10157 [2:13:19<55:25:23, 20.21s/it]\rRequesting API:   3%|▎         | 287/10157 [2:13:33<50:10:12, 18.30s/it]\rRequesting API:   3%|▎         | 288/10157 [2:14:26<78:44:32, 28.72s/it]\rRequesting API:   3%|▎         | 289/10157 [2:17:12<191:56:27, 70.02s/it]\rRequesting API:   3%|▎         | 290/10157 [2:17:45<161:36:10, 58.96s/it]\rRequesting API:   3%|▎         | 291/10157 [2:18:50<165:56:09, 60.55s/it]\rRequesting API:   3%|▎         | 292/10157 [2:19:40<157:41:06, 57.54s/it]\rRequesting API:   3%|▎         | 293/10157 [2:20:34<154:15:54, 56.30s/it]\rRequesting API:   3%|▎         | 294/10157 [2:24:49<317:49:48, 116.01s/it]\rRequesting API:   3%|▎         | 295/10157 [2:24:52<224:44:52, 82.04s/it] \rRequesting API:   3%|▎         | 296/10157 [2:26:46<251:31:20, 91.82s/it]\rRequesting API:   3%|▎         | 297/10157 [2:26:54<181:57:39, 66.44s/it]\rRequesting API:   3%|▎         | 298/10157 [2:27:56<178:20:30, 65.12s/it]\rRequesting API:   3%|▎         | 299/10157 [2:28:01<129:17:35, 47.22s/it]\rRequesting API:   3%|▎         | 300/10157 [2:29:54<183:10:57, 66.90s/it]\rRequesting API:   3%|▎         | 301/10157 [2:30:22<151:25:36, 55.31s/it]\rRequesting API:   3%|▎         | 302/10157 [2:31:18<152:16:46, 55.63s/it]\rRequesting API:   3%|▎         | 303/10157 [2:31:59<139:33:58, 50.99s/it]\rRequesting API:   3%|▎         | 304/10157 [2:32:24<118:23:12, 43.26s/it]\rRequesting API:   3%|▎         | 305/10157 [2:32:58<111:10:26, 40.62s/it]\rRequesting API:   3%|▎         | 306/10157 [2:33:33<106:27:18, 38.90s/it]\rRequesting API:   3%|▎         | 307/10157 [2:33:37<78:00:10, 28.51s/it] \rRequesting API:   3%|▎         | 308/10157 [2:34:27<95:28:27, 34.90s/it]\rRequesting API:   3%|▎         | 309/10157 [2:34:51<86:35:10, 31.65s/it]\rRequesting API:   3%|▎         | 310/10157 [2:35:00<67:51:46, 24.81s/it]\rRequesting API:   3%|▎         | 311/10157 [2:35:06<52:21:06, 19.14s/it]\rRequesting API:   3%|▎         | 312/10157 [2:35:21<48:49:00, 17.85s/it]\rRequesting API:   3%|▎         | 314/10157 [2:35:22<26:45:35,  9.79s/it]\rRequesting API:   3%|▎         | 315/10157 [2:35:22<20:14:06,  7.40s/it]\rRequesting API:   3%|▎         | 316/10157 [2:35:35<24:21:58,  8.91s/it]\rRequesting API:   3%|▎         | 317/10157 [2:35:36<18:20:31,  6.71s/it]\rRequesting API:   3%|▎         | 318/10157 [2:35:57<29:02:42, 10.63s/it]\rRequesting API:   3%|▎         | 319/10157 [2:36:03<25:43:22,  9.41s/it]\rRequesting API:   3%|▎         | 320/10157 [2:36:15<27:48:23, 10.18s/it]\rRequesting API:   3%|▎         | 321/10157 [2:37:07<61:18:06, 22.44s/it]\rRequesting API:   3%|▎         | 322/10157 [2:37:19<52:29:47, 19.22s/it]\rRequesting API:   3%|▎         | 323/10157 [2:37:26<42:37:38, 15.60s/it]\rRequesting API:   3%|▎         | 324/10157 [2:37:46<46:06:06, 16.88s/it]\rRequesting API:   3%|▎         | 325/10157 [2:38:03<46:14:34, 16.93s/it]\rRequesting API:   3%|▎         | 326/10157 [2:38:22<48:08:16, 17.63s/it]', 'page': {'current': 30, 'total': 30}, 'err_code': 0}
INFO:     100.64.78.196:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.199:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8B-cambricon-flagos-1230-01 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.208:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-8B-cambricon-flagos-1230-01 28623 01dcdcf3-daf2-4284-b320-f231f5db6f2c
submit stop batch 28623
[{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.199:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://172.27.244.118:8004/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v4' eval_model='train_qwen3_vl_8b_data_v4' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v4' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
eval_url='http://172.27.244.118:8004/v1/chat/completions' model='/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v4' eval_model='train_qwen3_vl_8b_data_v4' base_model_name='Qwen3-VL-8B-Instruct' tokenizer='train_qwen3_vl_8b_data_v4' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=16000 gen_kwargs='temperature=0.6,top_p=0.95,max_gen_toks=16000' thinking=False retry_time=3600 chip='Nvidia-H100'
RoboTrain ['MMBench_en']
{'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8004/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v4', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 2512, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'train_qwen3_vl_8b_data_v4', 'online_api_key': 'EMPTY', 'online_url': 'http://172.27.244.118:8004/v1/chat/completions', 'online_model_name': '/share/project/tanhuajie/robobrain_v2_5/checkpoints/train_qwen3_vl_8b_data_v4', 'base_model_name': 'Qwen3-VL-8B-Instruct', 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'mmdataset': ['MMBench_en'], 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'max_tokens': 16000, 'retry_time': 3600}
submit_evaluation response {"id":28652,"evaluationId":1451}
{'id': 28652, 'evaluationId': 1451}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1451, 'batch_id': 28652, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.149.197:2057 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.67.171.200:2049 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://10.1.15.46:8004/v1/chat/completions' model='/root/model/Qwen3-8B' eval_model='qwen3-8B-cambricon-flagos-1231-001' base_model_name='qwen3_8b' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8B-cambricon-flagos-1231-001', 'online_model_name': '/root/model/Qwen3-8B', 'base_model_name': 'qwen3_8b', 'online_url': 'http://10.1.15.46:8004/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28653, 'evaluationId': 1452}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1452, 'batch_id': 28653, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1452, 'batch_id': 28653, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.72.198:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [] R
INFO:     100.64.72.210:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.72.203:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [] R
INFO:     100.67.175.198:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.163.197:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': False, 'totalDatasets': 0, 'finishedDataset': 0, 'runningDataset': '', 'runningProgress': 'S); draw(A--B--C--cycle); for(real i=0.62; i<2.7; i+=0.29){ draw(circle((i,0.145), 0.145)); } [/asy]\\\\n\\\\nPlease reason step by step, and put your final answer within \\\\\\\\boxed{}.\\\\n"}]\'),), gen_kwargs is {\'temperature\': 0.6, \'max_gen_toks\': 32000, \'top_p\': 0.95, \'until\': []}\n2025-12-31:17:34:08 INFO     [models.api_models:362] model_call timeout 3600\n2025-12-31:17:34:08 WARNING  [models.api_models:291] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.\n', 'page': {'current': 4, 'total': 4}, 'err_code': 0}
INFO:     100.64.167.206:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.209:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.208:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
get a new request
taskinfo eval_url='http://172.24.178.148:8887/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_origin_3' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_origin_3', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8887/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28654, 'evaluationId': 1450}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1450, 'batch_id': 28654, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1450, 'batch_id': 28654, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.72.210:2053 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_origin_3 28654 88ac2fc9-7406-48af-8803-f1b008e11348
submit stop batch 28654
[{'status': 'R', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.202:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.24.178.148:8887/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_fl' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_fl', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8887/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28655, 'evaluationId': 1453}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1453, 'batch_id': 28655, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1453, 'batch_id': 28655, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.169.205:2050 - "POST /evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.195:2052 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.175.198:2053 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.204:2053 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.74.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.165.203:2053 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.173.211:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.161.212:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
batchresumption 28612 qwen3-8b-hygon-flagos-1229-01 /root/Qwen3-8B http://10.1.15.95:8004/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 10 10 -1 mtemperature=0.6,top_k=20,top_p=0.95 FlagRelease bj 0
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.203:2049 - "POST /resume_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.193:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.74.196:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.211:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.175.210:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.207:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.134.209:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.202:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'requests:  69%|██████▉   | 8331/12032 [00:23<00:07, 492.14it/s]\rChecking cached requests:  70%|██████▉   | 8381/12032 [00:24<00:07, 485.13it/s]\rChecking cached requests:  70%|███████   | 8432/12032 [00:24<00:07, 491.16it/s]\rChecking cached requests:  70%|███████   | 8482/12032 [00:24<00:07, 490.37it/s]\rChecking cached requests:  71%|███████   | 8532/12032 [00:24<00:07, 490.98it/s]\rChecking cached requests:  71%|███████▏  | 8582/12032 [00:24<00:06, 492.94it/s]\rChecking cached requests:  72%|███████▏  | 8632/12032 [00:24<00:06, 492.88it/s]\rChecking cached requests:  72%|███████▏  | 8682/12032 [00:24<00:06, 488.96it/s]\rChecking cached requests:  73%|███████▎  | 8731/12032 [00:24<00:06, 488.77it/s]\rChecking cached requests:  73%|███████▎  | 8782/12032 [00:24<00:06, 493.46it/s]\rChecking cached requests:  73%|███████▎  | 8832/12032 [00:24<00:06, 494.91it/s]\rChecking cached requests:  74%|███████▍  | 8883/12032 [00:25<00:06, 497.52it/s]\rChecking cached requests:  74%|███████▍  | 8933/12032 [00:25<00:06, 496.94it/s]\rChecking cached requests:  75%|███████▍  | 8983/12032 [00:25<00:06, 492.59it/s]\rChecking cached requests:  75%|███████▌  | 9034/12032 [00:25<00:06, 496.44it/s]\rChecking cached requests:  75%|███████▌  | 9084/12032 [00:25<00:05, 493.73it/s]\rChecking cached requests:  76%|███████▌  | 9136/12032 [00:25<00:05, 499.22it/s]\rChecking cached requests:  76%|███████▋  | 9186/12032 [00:25<00:05, 497.08it/s]\rChecking cached requests:  77%|███████▋  | 9237/12032 [00:25<00:05, 498.43it/s]\rChecking cached requests:  77%|███████▋  | 9287/12032 [00:25<00:05, 494.25it/s]\rChecking cached requests:  78%|███████▊  | 9337/12032 [00:25<00:05, 491.14it/s]\rChecking cached requests:  78%|███████▊  | 9387/12032 [00:26<00:05, 490.72it/s]\rChecking cached requests:  78%|███████▊  | 9437/12032 [00:26<00:05, 490.02it/s]\rChecking cached requests:  79%|███████▉  | 9487/12032 [00:26<00:05, 488.44it/s]\rChecking cached requests:  79%|███████▉  | 9536/12032 [00:26<00:05, 486.29it/s]\rChecking cached requests:  80%|███████▉  | 9585/12032 [00:26<00:05, 485.18it/s]\rChecking cached requests:  80%|████████  | 9634/12032 [00:26<00:04, 481.59it/s]\rChecking cached requests:  80%|████████  | 9683/12032 [00:26<00:04, 480.57it/s]\rChecking cached requests:  81%|████████  | 9733/12032 [00:26<00:04, 485.28it/s]\rChecking cached requests:  81%|████████▏ | 9784/12032 [00:26<00:04, 490.26it/s]\rChecking cached requests:  82%|████████▏ | 9834/12032 [00:26<00:04, 492.71it/s]\rChecking cached requests:  82%|████████▏ | 9884/12032 [00:27<00:04, 488.62it/s]\rChecking cached requests:  83%|████████▎ | 9934/12032 [00:27<00:04, 490.23it/s]\rChecking cached requests:  83%|████████▎ | 9984/12032 [00:27<00:04, 491.84it/s]\rChecking cached requests:  83%|████████▎ | 10035/12032 [00:27<00:04, 494.87it/s]\rChecking cached requests:  84%|████████▍ | 10085/12032 [00:27<00:03, 496.10it/s]\rChecking cached requests:  84%|████████▍ | 10135/12032 [00:27<00:03, 495.43it/s]\rChecking cached requests:  85%|████████▍ | 10185/12032 [00:27<00:03, 487.91it/s]\rChecking cached requests:  85%|████████▌ | 10235/12032 [00:27<00:03, 491.41it/s]\rChecking cached requests:  85%|████████▌ | 10285/12032 [00:27<00:03, 489.51it/s]\rChecking cached requests:  86%|████████▌ | 10335/12032 [00:28<00:03, 492.60it/s]\rChecking cached requests:  86%|████████▋ | 10385/12032 [00:28<00:03, 491.72it/s]\rChecking cached requests:  87%|████████▋ | 10435/12032 [00:28<00:03, 491.66it/s]\rChecking cached requests:  87%|████████▋ | 10486/12032 [00:28<00:03, 494.61it/s]\rChecking cached requests:  88%|████████▊ | 10540/12032 [00:28<00:02, 505.83it/s]\rChecking cached requests:  88%|████████▊ | 10593/12032 [00:28<00:02, 510.17it/s]\rChecking cached requests:  88%|████████▊ | 10647/12032 [00:28<00:02, 517.53it/s]\rChecking cached requests:  89%|████████▉ | 10699/12032 [00:28<00:02, 514.45it/s]\rChecking cached requests:  89%|████████▉ | 10754/12032 [00:28<00:02, 523.57it/s]\rChecking cached requests:  90%|████████▉ | 10807/12032 [00:28<00:02, 523.09it/s]\rChecking cached requests:  90%|█████████ | 10861/12032 [00:29<00:02, 525.98it/s]\rChecking cached requests:  91%|█████████ | 10914/12032 [00:29<00:02, 527.11it/s]\rChecking cached requests:  91%|█████████ | 10968/12032 [00:29<00:02, 530.04it/s]\rChecking cached requests:  92%|█████████▏| 11022/12032 [00:29<00:01, 525.69it/s]\rChecking cached requests:  92%|█████████▏| 11075/12032 [00:29<00:01, 525.24it/s]\rChecking cached requests:  92%|█████████▏| 11128/12032 [00:29<00:01, 525.42it/s]\rChecking cached requests:  93%|█████████▎| 11181/12032 [00:29<00:01, 523.35it/s]\rChecking cached requests:  93%|█████████▎| 11234/12032 [00:29<00:01, 524.28it/s]\rChecking cached requests:  94%|█████████▍| 11287/12032 [00:29<00:01, 523.50it/s]\rChecking cached requests:  94%|█████████▍| 11340/12032 [00:29<00:01, 520.43it/s]\rChecking cached requests:  95%|█████████▍| 11395/12032 [00:30<00:01, 526.82it/s]\rChecking cached requests:  95%|█████████▌| 11449/12032 [00:30<00:01, 529.37it/s]\rChecking cached requests:  96%|█████████▌| 11502/12032 [00:30<00:01, 525.53it/s]\rChecking cached requests:  96%|█████████▌| 11556/12032 [00:30<00:00, 528.44it/s]\rChecking cached requests:  96%|█████████▋| 11610/12032 [00:30<00:00, 529.42it/s]\rChecking cached requests:  97%|█████████▋| 11663/12032 [00:30<00:00, 528.08it/s]\rChecking cached requests:  97%|█████████▋| 11716/12032 [00:30<00:00, 528.61it/s]\rChecking cached requests:  98%|█████████▊| 11769/12032 [00:30<00:00, 525.95it/s]\rChecking cached requests:  98%|█████████▊| 11822/12032 [00:30<00:00, 524.06it/s]\rChecking cached requests:  99%|█████████▊| 11876/12032 [00:30<00:00, 526.17it/s]\rChecking cached requests:  99%|█████████▉| 11929/12032 [00:31<00:00, 520.51it/s]\rChecking cached requests: 100%|█████████▉| 11982/12032 [00:31<00:00, 521.17it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:31<00:00, 384.90it/s]\n2026-01-01:18:36:12 INFO     [api.model:287] Cached requests: 3381, Requests remaining: 8651\n2026-01-01:18:36:12 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-01:18:36:12 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/8651 [00:00<?, ?it/s]', 'page': {'current': 27, 'total': 27}, 'err_code': 0}
INFO:     100.64.74.196:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.195:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 1, 'finishedDataset': 1, 'runningDataset': '', 'runningProgress': ' protein expression. The key difference might be in their restriction sites and the presence of the His-tag. \\n\\nThe question mentions the His-tag is at the C-terminus. So, the cloning strategy should ensure that the His-tag is added to the end of the recombinant protein. Typically, vectors have a His-tag sequence in their multiple cloning sites (MCS). \\n\\nLooking at pET vectors, pET16b and pET24a might have different MCS configurations. For example, pET24a is known to have a His-tag in its MCS, which is usually between BamHI and XhoI. Wait, but I need to confirm. \\n\\nAlternatively, the His-tag could be part of the vector\'s structure. For instance, pET24a has a His-tag that\'s part of the cloning site. If the user wants the His-tag at the C-terminus, the cloning site should be such that the gene is inserted in a way that the His-tag is after the gene. \\n\\nLooking at the options: \\n\\nOption C says cloning in pET24a between BamH1 and Xho1. If the vector\'s MCS has the His-tag between these sites, inserting the gene here would place the His-tag at the C-terminus. \\n\\nOption D is EcoR1 and Xho1. If the vector\'s MCS doesn\'t have the His-tag in that region, then maybe not. \\n\\nAlternatively, pET16b might have the His-tag in a different location. For example, pET16b\'s MCS might have the His-tag between Nde1 and Xho1. But I need to recall the standard cloning sites. \\n\\nWait, pET16b is a vector that uses the T7 promoter for expression. The multiple cloning site (MCS) in pET16b typically includes sites like NdeI, XhoI, and others. However, the His-tag is usually part of the vector\'s structure. For example, pET16b might have the His-tag in the MCS, but I\'m not sure. \\n\\nAlternatively, pET24a is known to have a His-tag in its MCS. The standard cloning sites for pET24a are BamHI and XhoI, which are used to insert the gene. If the gene is cloned between BamHI and XhoI, the His-tag would be at the C-terminus. \\n\\nSo, if the correct cloning sites for the His-tag are BamHI and XhoI in pET24a, then option C would be correct. \\n\\nBut I need to check the options again. The options are between pET16b and pET24a. The user\'s question is about which plasmid to use. \\n\\nIf the His-tag is part of the pET24a vector, then using pET24a would be better. If the His-tag is not present in pET16b, then pET24a is the choice. \\n\\nAssuming that pET24a has the His-tag in its MCS between BamHI and XhoI, then option C is correct. \\n\\nAlternatively, if the user needs to add the His-tag themselves, then the cloning site should allow for that. But the question says the recombinant protein is fused to a His-tag, implying that the vector already has the His-tag sequence. \\n\\nTherefore, the correct answer is likely option C: cloning in pET24a between BamH1 and Xho1.\\n</think>\\n\\n## Step 1: Determine the requirement for the His-tag.  \\nThe recombinant protein must have a His-tag at the C-terminus, which is typically achieved by using a plasmid that includes a His-tag sequence in its multiple cloning site (MCS).  \\n\\n## Step 2: Compare the plasmids\' MCS configurations.  \\npET24a is known to have a His-tag sequence in its MCS, which is typically cloned between **BamH1** and **Xho1**. This ensures the His-tag is added to the C-terminus of the inserted gene. pET16b does not have a built-in His-tag, requiring additional steps to add it.  \\n\\nThe best answer is C.", \'tool_calls\': []}, \'logprobs\': None, \'finish_reason\': \'stop\', \'stop_reason\': None}], \'usage\': {\'prompt_tokens\': 1777, \'total_tokens\': 2806, \'completion_tokens\': 1029, \'prompt_tokens_details\': None}, \'prompt_logprobs\': None, \'kv_transfer_params\': None}, use 76.32005405426025\n\rRequesting API:  38%|███▊      | 450/1192 [20:57:35<16:09:41, 78.41s/it]2026-01-01:18:35:37 INFO     [models.api_models:625] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-01:18:35:37 INFO     [models.api_models:630] send request info (JsonChatStr(prompt=\'[{"role": "user", "content": "Given the following question and four candidate answers (A, B, C and D), choose the best answer.\\\\n\\\\nQuestion: A spin-half particle is in a mixed ensemble. The spin half system is in state |\\\\\\\\psi1 \\\\\\\\rangle  with probabilty (1/3) and in state in state |\\\\\\\\psi2 \\\\\\\\rangle with probability (2/3).\\\\n Here |\\\\\\\\psi1 \\\\\\\\rangle is a state in linear superposition (1/2)|\\\\\\\\uparrow\\\\\\\\rangle+(\\\\\\\\sqrt(3)/2) |\\\\\\\\downarrow\\\\\\\\rangle of its spin-up and spin-down states and \\\\n|\\\\\\\\psi2 \\\\\\\\rangle is linear superposition (1/\\\\\\\\sqrt(2)|\\\\\\\\uparrow\\\\\\\\rangle+(1/\\\\\\\\sqrt(2)) |\\\\\\\\downarrow\\\\\\\\rangle of its spin-up and spin-down states. \\\\nIf |\\\\\\\\uparrow\\\\\\\\rangle and |\\\\\\\\downarrow\\\\\\\\rangle are the eigenstates of \\\\\\\\sigma{z} , then what is the expectation value up to two decimal place, of the operator 10\\\\\\\\sigma{z}+5\\\\\\\\sigma_{x} ? Here, symbols have their usual meanings\\\\nChoices:\\\\n(A) 3.86\\\\n(B) 5.28\\\\n(C) 4.62\\\\n(D) 1.24\\\\n\\\\n- For simple problems:\\\\nDirectly provide the answer with minimal explanation.\\\\n\\\\n- For complex problems:\\\\nUse this step-by-step format:\\\\n## Step 1: [Concise description]\\\\n[Brief explanation]\\\\n## Step 2: [Concise description]\\\\n[Brief explanation]\\\\n\\\\nRegardless of the approach, always conclude with:\\\\nThe best answer is [the_answer_letter].\\\\nwhere the [the_answer_letter] is one of A, B, C or D.\\\\n\\\\nLet\\\'s think step by step."}]\'),), gen_kwargs is {\'until\': [\'</s>\'], \'temperature\': 0.0, \'do_sample\': False, \'max_gen_toks\': 18000}\n2026-01-01:18:35:37 INFO     [models.api_models:362] model_call timeout 3600\n', 'page': {'current': 1452, 'total': 1452}, 'err_code': 0}
INFO:     100.64.74.193:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.203:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.196:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.196:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.165.194:2051 - "POST /resume_evaluation HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.78.207:2049 - "POST /resume_evaluation HTTP/1.1" 200 OK
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.167.207:2053 - "POST /resume_evaluation HTTP/1.1" 200 OK
nohup: ignoring input
INFO:     Started server process [1192425]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:5050 (Press CTRL+C to quit)
eval_model details status
qwen3-8b-cambricon-flagos-1229 [{'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.167.198:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.74.204:2051 - "POST /resume_evaluation HTTP/1.1" 200 OK
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.169.198:2053 - "POST /resume_evaluation HTTP/1.1" 200 OK
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.76.209:2048 - "POST /resume_evaluation HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1229 28607 8a5112ac-2329-41de-8468-e09fd9f3bf34
submit stop batch 28607
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.199:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.64.169.209:2051 - "GET /resume_evaluation HTTP/1.1" 405 Method Not Allowed
batchresumption 28607 qwen3-8b-cambricon-flagos-1229 /root/Qwen3-8B http://10.1.15.238:8020/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 20 10 -1  FlagRelease bj 0
[{'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.169.200:2051 - "POST /resume_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229_1 [{'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.211:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.171.198:2053 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.197:2050 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.202:2053 - "GET /favicon.ico HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8b-cambricon-flagos-1229_1 [{'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.211:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-cambricon-flagos-1229_1 [{'status': 'R', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.76.203:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.163.197:2051 - "GET / HTTP/1.1" 404 Not Found
eval_model details status
qwen3-8b-cambricon-flagos-1229_1 [{'status': 'F', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.161.197:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.238:8020/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-mthreads-flagos-260103' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-mthreads-flagos-260103', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.238:8020/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28657, 'evaluationId': 1455}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1455, 'batch_id': 28657, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1455, 'batch_id': 28657, 'datasize': 14920}
mysql connect
insert success
INFO:     100.67.175.193:2055 - "POST /evaluation HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1229_1 28656 12b807ee-2c11-4468-9460-635a4dd9a900
submit stop batch 28656
[{'status': 'F', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.167.200:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.238:8020/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-mthreads-flagos-260103' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=10 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-mthreads-flagos-260103', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.238:8020/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 10, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.67.151.197:2052 - "POST /evaluation HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1229 28607 8a5112ac-2329-41de-8468-e09fd9f3bf34
submit stop batch 28607
[{'status': 'C', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.76.212:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://10.1.15.238:8020/v1/chat/completions' model='/root/Qwen3-8B' eval_model='qwen3-8b-mthreads-flagos-260103' base_model_name='Qwen3-8B' tokenizer='Qwen/Qwen3-8B' api_key='EMPTY' batch_size=1 num_concurrent=30 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': 'Chat', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-8B'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'qwen3-8b-mthreads-flagos-260103', 'online_model_name': '/root/Qwen3-8B', 'base_model_name': 'Qwen3-8B', 'online_url': 'http://10.1.15.238:8020/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-musr_generative', 'lm_eval-mmlu_pro', 'lm_eval-gpqa_generative_cot', 'lm_eval-aime', 'lm_eval-livebench_new'], 'batch_size': 1, 'num_concurrent': 30, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
tasks {'err_code': 1, 'err_msg': 'flageval server failed with err_code400', 'eval_id': -1, 'batch_id': -1, 'datasize': -1}
INFO:     100.64.161.208:2052 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.72.207:2050 - "GET /evaluation HTTP/1.1" 405 Method Not Allowed
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8b-cambricon-flagos-1229_1 [{'status': 'F', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] C
INFO:     100.64.74.202:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen3-8b-cambricon-flagos-1229_1 28656 12b807ee-2c11-4468-9460-635a4dd9a900
submit stop batch 28656
[{'status': 'F', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.64.76.205:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.64.165.200:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.169.205:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
batchresumption 28612 qwen3-8b-hygon-flagos-1229-01 /root/Qwen3-8B http://10.1.15.95:8004/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 10 10 -1 mtemperature=0.6,top_k=20,top_p=0.95 FlagRelease bj 0
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.149.200:2052 - "POST /resume_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.207:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.134.199:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.209:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.169.209:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.211:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.151.198:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.204:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.134.200:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.167.208:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.67.171.195:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.165.203:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': ':  76%|███████▋  | 9195/12032 [00:33<00:06, 465.37it/s]\rChecking cached requests:  77%|███████▋  | 9243/12032 [00:33<00:05, 467.39it/s]\rChecking cached requests:  77%|███████▋  | 9290/12032 [00:34<00:06, 431.40it/s]\rChecking cached requests:  78%|███████▊  | 9334/12032 [00:34<00:06, 430.25it/s]\rChecking cached requests:  78%|███████▊  | 9378/12032 [00:34<00:06, 425.93it/s]\rChecking cached requests:  78%|███████▊  | 9421/12032 [00:34<00:06, 418.86it/s]\rChecking cached requests:  79%|███████▊  | 9473/12032 [00:34<00:05, 445.85it/s]\rChecking cached requests:  79%|███████▉  | 9526/12032 [00:34<00:05, 468.62it/s]\rChecking cached requests:  80%|███████▉  | 9580/12032 [00:34<00:05, 488.26it/s]\rChecking cached requests:  80%|████████  | 9634/12032 [00:34<00:04, 501.10it/s]\rChecking cached requests:  81%|████████  | 9687/12032 [00:34<00:04, 508.41it/s]\rChecking cached requests:  81%|████████  | 9739/12032 [00:34<00:04, 511.34it/s]\rChecking cached requests:  81%|████████▏ | 9792/12032 [00:35<00:04, 516.79it/s]\rChecking cached requests:  82%|████████▏ | 9844/12032 [00:35<00:04, 514.27it/s]\rChecking cached requests:  82%|████████▏ | 9897/12032 [00:35<00:04, 516.36it/s]\rChecking cached requests:  83%|████████▎ | 9950/12032 [00:35<00:04, 518.38it/s]\rChecking cached requests:  83%|████████▎ | 10004/12032 [00:35<00:03, 523.14it/s]\rChecking cached requests:  84%|████████▎ | 10057/12032 [00:35<00:03, 506.21it/s]\rChecking cached requests:  84%|████████▍ | 10108/12032 [00:35<00:03, 506.81it/s]\rChecking cached requests:  84%|████████▍ | 10160/12032 [00:35<00:03, 508.50it/s]\rChecking cached requests:  85%|████████▍ | 10212/12032 [00:35<00:03, 509.10it/s]\rChecking cached requests:  85%|████████▌ | 10263/12032 [00:36<00:03, 507.84it/s]\rChecking cached requests:  86%|████████▌ | 10314/12032 [00:36<00:03, 505.25it/s]\rChecking cached requests:  86%|████████▌ | 10365/12032 [00:36<00:03, 503.88it/s]\rChecking cached requests:  87%|████████▋ | 10416/12032 [00:36<00:03, 505.66it/s]\rChecking cached requests:  87%|████████▋ | 10468/12032 [00:36<00:03, 507.63it/s]\rChecking cached requests:  87%|████████▋ | 10519/12032 [00:36<00:02, 504.89it/s]\rChecking cached requests:  88%|████████▊ | 10571/12032 [00:36<00:02, 506.45it/s]\rChecking cached requests:  88%|████████▊ | 10622/12032 [00:36<00:02, 502.67it/s]\rChecking cached requests:  89%|████████▊ | 10673/12032 [00:36<00:02, 502.90it/s]\rChecking cached requests:  89%|████████▉ | 10724/12032 [00:36<00:02, 502.84it/s]\rChecking cached requests:  90%|████████▉ | 10775/12032 [00:37<00:02, 502.71it/s]\rChecking cached requests:  90%|████████▉ | 10826/12032 [00:37<00:02, 491.98it/s]\rChecking cached requests:  90%|█████████ | 10877/12032 [00:37<00:02, 496.33it/s]\rChecking cached requests:  91%|█████████ | 10927/12032 [00:37<00:02, 496.68it/s]\rChecking cached requests:  91%|█████████ | 10979/12032 [00:37<00:02, 501.67it/s]\rChecking cached requests:  92%|█████████▏| 11030/12032 [00:37<00:01, 503.55it/s]\rChecking cached requests:  92%|█████████▏| 11081/12032 [00:37<00:01, 482.00it/s]\rChecking cached requests:  93%|█████████▎| 11131/12032 [00:37<00:01, 484.77it/s]\rChecking cached requests:  93%|█████████▎| 11181/12032 [00:37<00:01, 488.05it/s]\rChecking cached requests:  93%|█████████▎| 11232/12032 [00:37<00:01, 492.86it/s]\rChecking cached requests:  94%|█████████▍| 11282/12032 [00:38<00:01, 494.22it/s]\rChecking cached requests:  94%|█████████▍| 11332/12032 [00:38<00:01, 442.99it/s]\rChecking cached requests:  95%|█████████▍| 11378/12032 [00:38<00:01, 395.40it/s]\rChecking cached requests:  95%|█████████▍| 11430/12032 [00:38<00:01, 426.46it/s]\rChecking cached requests:  95%|█████████▌| 11480/12032 [00:38<00:01, 444.62it/s]\rChecking cached requests:  96%|█████████▌| 11529/12032 [00:38<00:01, 455.31it/s]\rChecking cached requests:  96%|█████████▌| 11580/12032 [00:38<00:00, 468.46it/s]\rChecking cached requests:  97%|█████████▋| 11631/12032 [00:38<00:00, 479.54it/s]\rChecking cached requests:  97%|█████████▋| 11682/12032 [00:38<00:00, 487.34it/s]\rChecking cached requests:  98%|█████████▊| 11734/12032 [00:39<00:00, 496.88it/s]\rChecking cached requests:  98%|█████████▊| 11785/12032 [00:39<00:00, 498.97it/s]\rChecking cached requests:  98%|█████████▊| 11836/12032 [00:39<00:00, 502.01it/s]\rChecking cached requests:  99%|█████████▉| 11887/12032 [00:39<00:00, 502.00it/s]\rChecking cached requests:  99%|█████████▉| 11938/12032 [00:39<00:00, 500.59it/s]\rChecking cached requests: 100%|█████████▉| 11989/12032 [00:39<00:00, 491.90it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:39<00:00, 303.44it/s]\n2026-01-03:14:18:29 INFO     [api.model:287] Cached requests: 6597, Requests remaining: 5435\n2026-01-03:14:18:29 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-03:14:18:29 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/5435 [00:00<?, ?it/s]', 'page': {'current': 28, 'total': 28}, 'err_code': 0}
INFO:     100.64.76.210:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.198:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': ':  76%|███████▋  | 9195/12032 [00:33<00:06, 465.37it/s]\rChecking cached requests:  77%|███████▋  | 9243/12032 [00:33<00:05, 467.39it/s]\rChecking cached requests:  77%|███████▋  | 9290/12032 [00:34<00:06, 431.40it/s]\rChecking cached requests:  78%|███████▊  | 9334/12032 [00:34<00:06, 430.25it/s]\rChecking cached requests:  78%|███████▊  | 9378/12032 [00:34<00:06, 425.93it/s]\rChecking cached requests:  78%|███████▊  | 9421/12032 [00:34<00:06, 418.86it/s]\rChecking cached requests:  79%|███████▊  | 9473/12032 [00:34<00:05, 445.85it/s]\rChecking cached requests:  79%|███████▉  | 9526/12032 [00:34<00:05, 468.62it/s]\rChecking cached requests:  80%|███████▉  | 9580/12032 [00:34<00:05, 488.26it/s]\rChecking cached requests:  80%|████████  | 9634/12032 [00:34<00:04, 501.10it/s]\rChecking cached requests:  81%|████████  | 9687/12032 [00:34<00:04, 508.41it/s]\rChecking cached requests:  81%|████████  | 9739/12032 [00:34<00:04, 511.34it/s]\rChecking cached requests:  81%|████████▏ | 9792/12032 [00:35<00:04, 516.79it/s]\rChecking cached requests:  82%|████████▏ | 9844/12032 [00:35<00:04, 514.27it/s]\rChecking cached requests:  82%|████████▏ | 9897/12032 [00:35<00:04, 516.36it/s]\rChecking cached requests:  83%|████████▎ | 9950/12032 [00:35<00:04, 518.38it/s]\rChecking cached requests:  83%|████████▎ | 10004/12032 [00:35<00:03, 523.14it/s]\rChecking cached requests:  84%|████████▎ | 10057/12032 [00:35<00:03, 506.21it/s]\rChecking cached requests:  84%|████████▍ | 10108/12032 [00:35<00:03, 506.81it/s]\rChecking cached requests:  84%|████████▍ | 10160/12032 [00:35<00:03, 508.50it/s]\rChecking cached requests:  85%|████████▍ | 10212/12032 [00:35<00:03, 509.10it/s]\rChecking cached requests:  85%|████████▌ | 10263/12032 [00:36<00:03, 507.84it/s]\rChecking cached requests:  86%|████████▌ | 10314/12032 [00:36<00:03, 505.25it/s]\rChecking cached requests:  86%|████████▌ | 10365/12032 [00:36<00:03, 503.88it/s]\rChecking cached requests:  87%|████████▋ | 10416/12032 [00:36<00:03, 505.66it/s]\rChecking cached requests:  87%|████████▋ | 10468/12032 [00:36<00:03, 507.63it/s]\rChecking cached requests:  87%|████████▋ | 10519/12032 [00:36<00:02, 504.89it/s]\rChecking cached requests:  88%|████████▊ | 10571/12032 [00:36<00:02, 506.45it/s]\rChecking cached requests:  88%|████████▊ | 10622/12032 [00:36<00:02, 502.67it/s]\rChecking cached requests:  89%|████████▊ | 10673/12032 [00:36<00:02, 502.90it/s]\rChecking cached requests:  89%|████████▉ | 10724/12032 [00:36<00:02, 502.84it/s]\rChecking cached requests:  90%|████████▉ | 10775/12032 [00:37<00:02, 502.71it/s]\rChecking cached requests:  90%|████████▉ | 10826/12032 [00:37<00:02, 491.98it/s]\rChecking cached requests:  90%|█████████ | 10877/12032 [00:37<00:02, 496.33it/s]\rChecking cached requests:  91%|█████████ | 10927/12032 [00:37<00:02, 496.68it/s]\rChecking cached requests:  91%|█████████ | 10979/12032 [00:37<00:02, 501.67it/s]\rChecking cached requests:  92%|█████████▏| 11030/12032 [00:37<00:01, 503.55it/s]\rChecking cached requests:  92%|█████████▏| 11081/12032 [00:37<00:01, 482.00it/s]\rChecking cached requests:  93%|█████████▎| 11131/12032 [00:37<00:01, 484.77it/s]\rChecking cached requests:  93%|█████████▎| 11181/12032 [00:37<00:01, 488.05it/s]\rChecking cached requests:  93%|█████████▎| 11232/12032 [00:37<00:01, 492.86it/s]\rChecking cached requests:  94%|█████████▍| 11282/12032 [00:38<00:01, 494.22it/s]\rChecking cached requests:  94%|█████████▍| 11332/12032 [00:38<00:01, 442.99it/s]\rChecking cached requests:  95%|█████████▍| 11378/12032 [00:38<00:01, 395.40it/s]\rChecking cached requests:  95%|█████████▍| 11430/12032 [00:38<00:01, 426.46it/s]\rChecking cached requests:  95%|█████████▌| 11480/12032 [00:38<00:01, 444.62it/s]\rChecking cached requests:  96%|█████████▌| 11529/12032 [00:38<00:01, 455.31it/s]\rChecking cached requests:  96%|█████████▌| 11580/12032 [00:38<00:00, 468.46it/s]\rChecking cached requests:  97%|█████████▋| 11631/12032 [00:38<00:00, 479.54it/s]\rChecking cached requests:  97%|█████████▋| 11682/12032 [00:38<00:00, 487.34it/s]\rChecking cached requests:  98%|█████████▊| 11734/12032 [00:39<00:00, 496.88it/s]\rChecking cached requests:  98%|█████████▊| 11785/12032 [00:39<00:00, 498.97it/s]\rChecking cached requests:  98%|█████████▊| 11836/12032 [00:39<00:00, 502.01it/s]\rChecking cached requests:  99%|█████████▉| 11887/12032 [00:39<00:00, 502.00it/s]\rChecking cached requests:  99%|█████████▉| 11938/12032 [00:39<00:00, 500.59it/s]\rChecking cached requests: 100%|█████████▉| 11989/12032 [00:39<00:00, 491.90it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:39<00:00, 303.44it/s]\n2026-01-03:14:18:29 INFO     [api.model:287] Cached requests: 6597, Requests remaining: 5435\n2026-01-03:14:18:29 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-03:14:18:29 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/5435 [00:00<?, ?it/s]\rRequesting API:   0%|          | 1/5435 [03:15<294:34:48, 195.16s/it]', 'page': {'current': 28, 'total': 28}, 'err_code': 0}
INFO:     100.67.161.194:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.203:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': ':  76%|███████▋  | 9195/12032 [00:33<00:06, 465.37it/s]\rChecking cached requests:  77%|███████▋  | 9243/12032 [00:33<00:05, 467.39it/s]\rChecking cached requests:  77%|███████▋  | 9290/12032 [00:34<00:06, 431.40it/s]\rChecking cached requests:  78%|███████▊  | 9334/12032 [00:34<00:06, 430.25it/s]\rChecking cached requests:  78%|███████▊  | 9378/12032 [00:34<00:06, 425.93it/s]\rChecking cached requests:  78%|███████▊  | 9421/12032 [00:34<00:06, 418.86it/s]\rChecking cached requests:  79%|███████▊  | 9473/12032 [00:34<00:05, 445.85it/s]\rChecking cached requests:  79%|███████▉  | 9526/12032 [00:34<00:05, 468.62it/s]\rChecking cached requests:  80%|███████▉  | 9580/12032 [00:34<00:05, 488.26it/s]\rChecking cached requests:  80%|████████  | 9634/12032 [00:34<00:04, 501.10it/s]\rChecking cached requests:  81%|████████  | 9687/12032 [00:34<00:04, 508.41it/s]\rChecking cached requests:  81%|████████  | 9739/12032 [00:34<00:04, 511.34it/s]\rChecking cached requests:  81%|████████▏ | 9792/12032 [00:35<00:04, 516.79it/s]\rChecking cached requests:  82%|████████▏ | 9844/12032 [00:35<00:04, 514.27it/s]\rChecking cached requests:  82%|████████▏ | 9897/12032 [00:35<00:04, 516.36it/s]\rChecking cached requests:  83%|████████▎ | 9950/12032 [00:35<00:04, 518.38it/s]\rChecking cached requests:  83%|████████▎ | 10004/12032 [00:35<00:03, 523.14it/s]\rChecking cached requests:  84%|████████▎ | 10057/12032 [00:35<00:03, 506.21it/s]\rChecking cached requests:  84%|████████▍ | 10108/12032 [00:35<00:03, 506.81it/s]\rChecking cached requests:  84%|████████▍ | 10160/12032 [00:35<00:03, 508.50it/s]\rChecking cached requests:  85%|████████▍ | 10212/12032 [00:35<00:03, 509.10it/s]\rChecking cached requests:  85%|████████▌ | 10263/12032 [00:36<00:03, 507.84it/s]\rChecking cached requests:  86%|████████▌ | 10314/12032 [00:36<00:03, 505.25it/s]\rChecking cached requests:  86%|████████▌ | 10365/12032 [00:36<00:03, 503.88it/s]\rChecking cached requests:  87%|████████▋ | 10416/12032 [00:36<00:03, 505.66it/s]\rChecking cached requests:  87%|████████▋ | 10468/12032 [00:36<00:03, 507.63it/s]\rChecking cached requests:  87%|████████▋ | 10519/12032 [00:36<00:02, 504.89it/s]\rChecking cached requests:  88%|████████▊ | 10571/12032 [00:36<00:02, 506.45it/s]\rChecking cached requests:  88%|████████▊ | 10622/12032 [00:36<00:02, 502.67it/s]\rChecking cached requests:  89%|████████▊ | 10673/12032 [00:36<00:02, 502.90it/s]\rChecking cached requests:  89%|████████▉ | 10724/12032 [00:36<00:02, 502.84it/s]\rChecking cached requests:  90%|████████▉ | 10775/12032 [00:37<00:02, 502.71it/s]\rChecking cached requests:  90%|████████▉ | 10826/12032 [00:37<00:02, 491.98it/s]\rChecking cached requests:  90%|█████████ | 10877/12032 [00:37<00:02, 496.33it/s]\rChecking cached requests:  91%|█████████ | 10927/12032 [00:37<00:02, 496.68it/s]\rChecking cached requests:  91%|█████████ | 10979/12032 [00:37<00:02, 501.67it/s]\rChecking cached requests:  92%|█████████▏| 11030/12032 [00:37<00:01, 503.55it/s]\rChecking cached requests:  92%|█████████▏| 11081/12032 [00:37<00:01, 482.00it/s]\rChecking cached requests:  93%|█████████▎| 11131/12032 [00:37<00:01, 484.77it/s]\rChecking cached requests:  93%|█████████▎| 11181/12032 [00:37<00:01, 488.05it/s]\rChecking cached requests:  93%|█████████▎| 11232/12032 [00:37<00:01, 492.86it/s]\rChecking cached requests:  94%|█████████▍| 11282/12032 [00:38<00:01, 494.22it/s]\rChecking cached requests:  94%|█████████▍| 11332/12032 [00:38<00:01, 442.99it/s]\rChecking cached requests:  95%|█████████▍| 11378/12032 [00:38<00:01, 395.40it/s]\rChecking cached requests:  95%|█████████▍| 11430/12032 [00:38<00:01, 426.46it/s]\rChecking cached requests:  95%|█████████▌| 11480/12032 [00:38<00:01, 444.62it/s]\rChecking cached requests:  96%|█████████▌| 11529/12032 [00:38<00:01, 455.31it/s]\rChecking cached requests:  96%|█████████▌| 11580/12032 [00:38<00:00, 468.46it/s]\rChecking cached requests:  97%|█████████▋| 11631/12032 [00:38<00:00, 479.54it/s]\rChecking cached requests:  97%|█████████▋| 11682/12032 [00:38<00:00, 487.34it/s]\rChecking cached requests:  98%|█████████▊| 11734/12032 [00:39<00:00, 496.88it/s]\rChecking cached requests:  98%|█████████▊| 11785/12032 [00:39<00:00, 498.97it/s]\rChecking cached requests:  98%|█████████▊| 11836/12032 [00:39<00:00, 502.01it/s]\rChecking cached requests:  99%|█████████▉| 11887/12032 [00:39<00:00, 502.00it/s]\rChecking cached requests:  99%|█████████▉| 11938/12032 [00:39<00:00, 500.59it/s]\rChecking cached requests: 100%|█████████▉| 11989/12032 [00:39<00:00, 491.90it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:39<00:00, 303.44it/s]\n2026-01-03:14:18:29 INFO     [api.model:287] Cached requests: 6597, Requests remaining: 5435\n2026-01-03:14:18:29 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-03:14:18:29 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/5435 [00:00<?, ?it/s]\rRequesting API:   0%|          | 1/5435 [03:15<294:34:48, 195.16s/it]\rRequesting API:   0%|          | 2/5435 [06:41<304:12:13, 201.57s/it]\rRequesting API:   0%|          | 3/5435 [07:12<186:40:22, 123.72s/it]\rRequesting API:   0%|          | 4/5435 [07:25<120:35:54, 79.94s/it] \rRequesting API:   0%|          | 5/5435 [09:10<134:36:36, 89.24s/it]\rRequesting API:   0%|          | 6/5435 [12:11<181:20:44, 120.25s/it]\rRequesting API:   0%|          | 7/5435 [12:46<139:34:46, 92.57s/it] \rRequesting API:   0%|          | 8/5435 [14:28<143:59:16, 95.51s/it]\rRequesting API:   0%|          | 9/5435 [15:30<128:03:52, 84.97s/it]', 'page': {'current': 28, 'total': 28}, 'err_code': 0}
INFO:     100.67.151.203:2054 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.204:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': ':  76%|███████▋  | 9195/12032 [00:33<00:06, 465.37it/s]\rChecking cached requests:  77%|███████▋  | 9243/12032 [00:33<00:05, 467.39it/s]\rChecking cached requests:  77%|███████▋  | 9290/12032 [00:34<00:06, 431.40it/s]\rChecking cached requests:  78%|███████▊  | 9334/12032 [00:34<00:06, 430.25it/s]\rChecking cached requests:  78%|███████▊  | 9378/12032 [00:34<00:06, 425.93it/s]\rChecking cached requests:  78%|███████▊  | 9421/12032 [00:34<00:06, 418.86it/s]\rChecking cached requests:  79%|███████▊  | 9473/12032 [00:34<00:05, 445.85it/s]\rChecking cached requests:  79%|███████▉  | 9526/12032 [00:34<00:05, 468.62it/s]\rChecking cached requests:  80%|███████▉  | 9580/12032 [00:34<00:05, 488.26it/s]\rChecking cached requests:  80%|████████  | 9634/12032 [00:34<00:04, 501.10it/s]\rChecking cached requests:  81%|████████  | 9687/12032 [00:34<00:04, 508.41it/s]\rChecking cached requests:  81%|████████  | 9739/12032 [00:34<00:04, 511.34it/s]\rChecking cached requests:  81%|████████▏ | 9792/12032 [00:35<00:04, 516.79it/s]\rChecking cached requests:  82%|████████▏ | 9844/12032 [00:35<00:04, 514.27it/s]\rChecking cached requests:  82%|████████▏ | 9897/12032 [00:35<00:04, 516.36it/s]\rChecking cached requests:  83%|████████▎ | 9950/12032 [00:35<00:04, 518.38it/s]\rChecking cached requests:  83%|████████▎ | 10004/12032 [00:35<00:03, 523.14it/s]\rChecking cached requests:  84%|████████▎ | 10057/12032 [00:35<00:03, 506.21it/s]\rChecking cached requests:  84%|████████▍ | 10108/12032 [00:35<00:03, 506.81it/s]\rChecking cached requests:  84%|████████▍ | 10160/12032 [00:35<00:03, 508.50it/s]\rChecking cached requests:  85%|████████▍ | 10212/12032 [00:35<00:03, 509.10it/s]\rChecking cached requests:  85%|████████▌ | 10263/12032 [00:36<00:03, 507.84it/s]\rChecking cached requests:  86%|████████▌ | 10314/12032 [00:36<00:03, 505.25it/s]\rChecking cached requests:  86%|████████▌ | 10365/12032 [00:36<00:03, 503.88it/s]\rChecking cached requests:  87%|████████▋ | 10416/12032 [00:36<00:03, 505.66it/s]\rChecking cached requests:  87%|████████▋ | 10468/12032 [00:36<00:03, 507.63it/s]\rChecking cached requests:  87%|████████▋ | 10519/12032 [00:36<00:02, 504.89it/s]\rChecking cached requests:  88%|████████▊ | 10571/12032 [00:36<00:02, 506.45it/s]\rChecking cached requests:  88%|████████▊ | 10622/12032 [00:36<00:02, 502.67it/s]\rChecking cached requests:  89%|████████▊ | 10673/12032 [00:36<00:02, 502.90it/s]\rChecking cached requests:  89%|████████▉ | 10724/12032 [00:36<00:02, 502.84it/s]\rChecking cached requests:  90%|████████▉ | 10775/12032 [00:37<00:02, 502.71it/s]\rChecking cached requests:  90%|████████▉ | 10826/12032 [00:37<00:02, 491.98it/s]\rChecking cached requests:  90%|█████████ | 10877/12032 [00:37<00:02, 496.33it/s]\rChecking cached requests:  91%|█████████ | 10927/12032 [00:37<00:02, 496.68it/s]\rChecking cached requests:  91%|█████████ | 10979/12032 [00:37<00:02, 501.67it/s]\rChecking cached requests:  92%|█████████▏| 11030/12032 [00:37<00:01, 503.55it/s]\rChecking cached requests:  92%|█████████▏| 11081/12032 [00:37<00:01, 482.00it/s]\rChecking cached requests:  93%|█████████▎| 11131/12032 [00:37<00:01, 484.77it/s]\rChecking cached requests:  93%|█████████▎| 11181/12032 [00:37<00:01, 488.05it/s]\rChecking cached requests:  93%|█████████▎| 11232/12032 [00:37<00:01, 492.86it/s]\rChecking cached requests:  94%|█████████▍| 11282/12032 [00:38<00:01, 494.22it/s]\rChecking cached requests:  94%|█████████▍| 11332/12032 [00:38<00:01, 442.99it/s]\rChecking cached requests:  95%|█████████▍| 11378/12032 [00:38<00:01, 395.40it/s]\rChecking cached requests:  95%|█████████▍| 11430/12032 [00:38<00:01, 426.46it/s]\rChecking cached requests:  95%|█████████▌| 11480/12032 [00:38<00:01, 444.62it/s]\rChecking cached requests:  96%|█████████▌| 11529/12032 [00:38<00:01, 455.31it/s]\rChecking cached requests:  96%|█████████▌| 11580/12032 [00:38<00:00, 468.46it/s]\rChecking cached requests:  97%|█████████▋| 11631/12032 [00:38<00:00, 479.54it/s]\rChecking cached requests:  97%|█████████▋| 11682/12032 [00:38<00:00, 487.34it/s]\rChecking cached requests:  98%|█████████▊| 11734/12032 [00:39<00:00, 496.88it/s]\rChecking cached requests:  98%|█████████▊| 11785/12032 [00:39<00:00, 498.97it/s]\rChecking cached requests:  98%|█████████▊| 11836/12032 [00:39<00:00, 502.01it/s]\rChecking cached requests:  99%|█████████▉| 11887/12032 [00:39<00:00, 502.00it/s]\rChecking cached requests:  99%|█████████▉| 11938/12032 [00:39<00:00, 500.59it/s]\rChecking cached requests: 100%|█████████▉| 11989/12032 [00:39<00:00, 491.90it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:39<00:00, 303.44it/s]\n2026-01-03:14:18:29 INFO     [api.model:287] Cached requests: 6597, Requests remaining: 5435\n2026-01-03:14:18:29 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-03:14:18:29 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/5435 [00:00<?, ?it/s]\rRequesting API:   0%|          | 1/5435 [03:15<294:34:48, 195.16s/it]\rRequesting API:   0%|          | 2/5435 [06:41<304:12:13, 201.57s/it]\rRequesting API:   0%|          | 3/5435 [07:12<186:40:22, 123.72s/it]\rRequesting API:   0%|          | 4/5435 [07:25<120:35:54, 79.94s/it] \rRequesting API:   0%|          | 5/5435 [09:10<134:36:36, 89.24s/it]\rRequesting API:   0%|          | 6/5435 [12:11<181:20:44, 120.25s/it]\rRequesting API:   0%|          | 7/5435 [12:46<139:34:46, 92.57s/it] \rRequesting API:   0%|          | 8/5435 [14:28<143:59:16, 95.51s/it]\rRequesting API:   0%|          | 9/5435 [15:30<128:03:52, 84.97s/it]\rRequesting API:   0%|          | 10/5435 [22:52<293:59:59, 195.10s/it]\rRequesting API:   0%|          | 11/5435 [23:31<221:53:29, 147.27s/it]\rRequesting API:   0%|          | 12/5435 [28:41<296:32:04, 196.85s/it]\rRequesting API:   0%|          | 13/5435 [29:19<223:55:42, 148.68s/it]\rRequesting API:   0%|          | 14/5435 [30:08<178:55:02, 118.82s/it]\rRequesting API:   0%|          | 15/5435 [33:00<202:41:19, 134.63s/it]\rRequesting API:   0%|          | 16/5435 [36:34<238:54:30, 158.71s/it]\rRequesting API:   0%|          | 17/5435 [36:54<176:09:09, 117.04s/it]\rRequesting API:   0%|          | 18/5435 [36:55<123:15:25, 81.91s/it] \rRequesting API:   0%|          | 19/5435 [36:55<86:24:54, 57.44s/it] \rRequesting API:   0%|          | 21/5435 [36:56<46:51:50, 31.16s/it]\rRequesting API:   0%|          | 22/5435 [36:57<35:24:27, 23.55s/it]\rRequesting API:   0%|          | 23/5435 [38:05<53:01:36, 35.27s/it]', 'page': {'current': 28, 'total': 28}, 'err_code': 0}
INFO:     100.67.167.195:2058 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.211:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'ng API:   1%|          | 32/5435 [48:53<105:09:15, 70.06s/it]\rRequesting API:   1%|          | 33/5435 [51:06<133:20:53, 88.87s/it]\rRequesting API:   1%|          | 34/5435 [54:42<190:14:34, 126.81s/it]\rRequesting API:   1%|          | 35/5435 [54:56<139:38:59, 93.10s/it] \rRequesting API:   1%|          | 36/5435 [57:41<171:52:22, 114.60s/it]\rRequesting API:   1%|          | 37/5435 [58:29<141:49:23, 94.58s/it] \rRequesting API:   1%|          | 38/5435 [58:47<107:10:42, 71.49s/it]\rRequesting API:   1%|          | 39/5435 [59:15<87:45:31, 58.55s/it] \rRequesting API:   1%|          | 40/5435 [59:56<79:50:19, 53.28s/it]\rRequesting API:   1%|          | 41/5435 [1:00:30<71:02:45, 47.42s/it]\rRequesting API:   1%|          | 42/5435 [1:00:31<50:29:15, 33.70s/it]\rRequesting API:   1%|          | 43/5435 [1:00:43<40:36:53, 27.12s/it]\rRequesting API:   1%|          | 44/5435 [1:00:52<32:27:23, 21.67s/it]\rRequesting API:   1%|          | 45/5435 [1:01:04<27:59:07, 18.69s/it]\rRequesting API:   1%|          | 46/5435 [1:01:20<26:56:10, 17.99s/it]\rRequesting API:   1%|          | 47/5435 [1:01:38<27:02:20, 18.07s/it]\rRequesting API:   1%|          | 48/5435 [1:01:56<26:53:35, 17.97s/it]\rRequesting API:   1%|          | 49/5435 [1:02:07<23:36:23, 15.78s/it]\rRequesting API:   1%|          | 50/5435 [1:02:54<37:42:15, 25.21s/it]\rRequesting API:   1%|          | 51/5435 [1:03:05<31:14:15, 20.89s/it]\rRequesting API:   1%|          | 52/5435 [1:03:13<25:40:59, 17.18s/it]\rRequesting API:   1%|          | 53/5435 [1:03:28<24:32:52, 16.42s/it]\rRequesting API:   1%|          | 54/5435 [1:03:30<18:08:48, 12.14s/it]\rRequesting API:   1%|          | 55/5435 [1:03:34<14:21:09,  9.60s/it]\rRequesting API:   1%|          | 56/5435 [1:04:12<26:59:37, 18.07s/it]\rRequesting API:   1%|          | 57/5435 [1:04:29<26:42:52, 17.88s/it]\rRequesting API:   1%|          | 58/5435 [1:04:38<22:53:11, 15.32s/it]\rRequesting API:   1%|          | 59/5435 [1:04:55<23:23:13, 15.66s/it]\rRequesting API:   1%|          | 60/5435 [1:05:17<26:21:47, 17.66s/it]\rRequesting API:   1%|          | 61/5435 [1:06:06<40:21:42, 27.04s/it]\rRequesting API:   1%|          | 62/5435 [1:06:09<29:19:20, 19.65s/it]\rRequesting API:   1%|          | 63/5435 [1:06:16<23:50:56, 15.98s/it]\rRequesting API:   1%|          | 64/5435 [1:06:32<23:52:53, 16.01s/it]\rRequesting API:   1%|          | 65/5435 [1:06:54<26:43:15, 17.91s/it]\rRequesting API:   1%|          | 66/5435 [1:07:11<26:09:20, 17.54s/it]\rRequesting API:   1%|          | 67/5435 [1:07:19<21:48:48, 14.63s/it]\rRequesting API:   1%|▏         | 68/5435 [1:08:09<37:46:57, 25.34s/it]\rRequesting API:   1%|▏         | 69/5435 [1:08:42<41:06:45, 27.58s/it]\rRequesting API:   1%|▏         | 70/5435 [1:09:01<37:17:44, 25.03s/it]\rRequesting API:   1%|▏         | 71/5435 [1:09:18<33:41:44, 22.61s/it]\rRequesting API:   1%|▏         | 72/5435 [1:09:54<39:46:24, 26.70s/it]\rRequesting API:   1%|▏         | 73/5435 [1:10:11<35:15:55, 23.68s/it]\rRequesting API:   1%|▏         | 74/5435 [1:10:54<43:47:04, 29.40s/it]\rRequesting API:   1%|▏         | 75/5435 [1:10:59<33:03:45, 22.21s/it]\rRequesting API:   1%|▏         | 76/5435 [1:11:29<36:37:36, 24.60s/it]\rRequesting API:   1%|▏         | 77/5435 [1:11:41<30:50:02, 20.72s/it]\rRequesting API:   1%|▏         | 78/5435 [1:12:04<31:43:33, 21.32s/it]\rRequesting API:   1%|▏         | 79/5435 [1:12:23<30:50:36, 20.73s/it]\rRequesting API:   1%|▏         | 80/5435 [1:12:46<31:40:35, 21.30s/it]\rRequesting API:   1%|▏         | 81/5435 [1:13:35<44:19:14, 29.80s/it]\rRequesting API:   2%|▏         | 82/5435 [1:13:39<32:41:17, 21.98s/it]\rRequesting API:   2%|▏         | 83/5435 [1:13:42<24:08:38, 16.24s/it]\rRequesting API:   2%|▏         | 84/5435 [1:14:23<35:07:24, 23.63s/it]\rRequesting API:   2%|▏         | 85/5435 [1:14:26<25:46:39, 17.35s/it]\rRequesting API:   2%|▏         | 86/5435 [1:14:31<20:30:53, 13.81s/it]\rRequesting API:   2%|▏         | 87/5435 [1:14:58<26:16:29, 17.69s/it]\rRequesting API:   2%|▏         | 88/5435 [1:15:03<20:44:21, 13.96s/it]\rRequesting API:   2%|▏         | 89/5435 [1:15:21<22:27:29, 15.12s/it]\rRequesting API:   2%|▏         | 90/5435 [1:15:30<19:54:54, 13.41s/it]\rRequesting API:   2%|▏         | 91/5435 [1:15:31<14:22:27,  9.68s/it]\rRequesting API:   2%|▏         | 92/5435 [1:15:57<21:41:21, 14.61s/it]\rRequesting API:   2%|▏         | 93/5435 [1:16:36<32:28:07, 21.88s/it]\rRequesting API:   2%|▏         | 94/5435 [1:17:12<38:30:30, 25.96s/it]\rRequesting API:   2%|▏         | 95/5435 [1:17:13<27:19:32, 18.42s/it]\rRequesting API:   2%|▏         | 96/5435 [1:17:29<26:32:24, 17.90s/it]\rRequesting API:   2%|▏         | 97/5435 [1:17:50<27:44:17, 18.71s/it]\rRequesting API:   2%|▏         | 98/5435 [1:18:20<32:40:01, 22.04s/it]\rRequesting API:   2%|▏         | 99/5435 [1:18:57<39:37:57, 26.74s/it]\rRequesting API:   2%|▏         | 100/5435 [1:20:08<59:18:19, 40.02s/it]\rRequesting API:   2%|▏         | 101/5435 [1:20:21<47:01:27, 31.74s/it]\rRequesting API:   2%|▏         | 102/5435 [1:20:34<38:50:58, 26.23s/it]\rRequesting API:   2%|▏         | 103/5435 [1:20:44<31:37:48, 21.36s/it]\rRequesting API:   2%|▏         | 104/5435 [1:21:27<41:05:28, 27.75s/it]\rRequesting API:   2%|▏         | 105/5435 [1:22:04<45:26:41, 30.69s/it]\rRequesting API:   2%|▏         | 106/5435 [1:22:24<40:36:23, 27.43s/it]\rRequesting API:   2%|▏         | 107/5435 [1:22:51<40:30:00, 27.37s/it]\rRequesting API:   2%|▏         | 108/5435 [1:22:55<29:53:30, 20.20s/it]\rRequesting API:   2%|▏         | 109/5435 [1:23:34<38:29:15, 26.02s/it]\rRequesting API:   2%|▏         | 110/5435 [1:23:54<35:49:04, 24.21s/it]\rRequesting API:   2%|▏         | 111/5435 [1:23:57<26:17:46, 17.78s/it]\rRequesting API:   2%|▏         | 112/5435 [1:24:24<30:22:22, 20.54s/it]', 'page': {'current': 29, 'total': 29}, 'err_code': 0}
INFO:     100.64.161.202:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.165.211:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'ng API:   1%|          | 32/5435 [48:53<105:09:15, 70.06s/it]\rRequesting API:   1%|          | 33/5435 [51:06<133:20:53, 88.87s/it]\rRequesting API:   1%|          | 34/5435 [54:42<190:14:34, 126.81s/it]\rRequesting API:   1%|          | 35/5435 [54:56<139:38:59, 93.10s/it] \rRequesting API:   1%|          | 36/5435 [57:41<171:52:22, 114.60s/it]\rRequesting API:   1%|          | 37/5435 [58:29<141:49:23, 94.58s/it] \rRequesting API:   1%|          | 38/5435 [58:47<107:10:42, 71.49s/it]\rRequesting API:   1%|          | 39/5435 [59:15<87:45:31, 58.55s/it] \rRequesting API:   1%|          | 40/5435 [59:56<79:50:19, 53.28s/it]\rRequesting API:   1%|          | 41/5435 [1:00:30<71:02:45, 47.42s/it]\rRequesting API:   1%|          | 42/5435 [1:00:31<50:29:15, 33.70s/it]\rRequesting API:   1%|          | 43/5435 [1:00:43<40:36:53, 27.12s/it]\rRequesting API:   1%|          | 44/5435 [1:00:52<32:27:23, 21.67s/it]\rRequesting API:   1%|          | 45/5435 [1:01:04<27:59:07, 18.69s/it]\rRequesting API:   1%|          | 46/5435 [1:01:20<26:56:10, 17.99s/it]\rRequesting API:   1%|          | 47/5435 [1:01:38<27:02:20, 18.07s/it]\rRequesting API:   1%|          | 48/5435 [1:01:56<26:53:35, 17.97s/it]\rRequesting API:   1%|          | 49/5435 [1:02:07<23:36:23, 15.78s/it]\rRequesting API:   1%|          | 50/5435 [1:02:54<37:42:15, 25.21s/it]\rRequesting API:   1%|          | 51/5435 [1:03:05<31:14:15, 20.89s/it]\rRequesting API:   1%|          | 52/5435 [1:03:13<25:40:59, 17.18s/it]\rRequesting API:   1%|          | 53/5435 [1:03:28<24:32:52, 16.42s/it]\rRequesting API:   1%|          | 54/5435 [1:03:30<18:08:48, 12.14s/it]\rRequesting API:   1%|          | 55/5435 [1:03:34<14:21:09,  9.60s/it]\rRequesting API:   1%|          | 56/5435 [1:04:12<26:59:37, 18.07s/it]\rRequesting API:   1%|          | 57/5435 [1:04:29<26:42:52, 17.88s/it]\rRequesting API:   1%|          | 58/5435 [1:04:38<22:53:11, 15.32s/it]\rRequesting API:   1%|          | 59/5435 [1:04:55<23:23:13, 15.66s/it]\rRequesting API:   1%|          | 60/5435 [1:05:17<26:21:47, 17.66s/it]\rRequesting API:   1%|          | 61/5435 [1:06:06<40:21:42, 27.04s/it]\rRequesting API:   1%|          | 62/5435 [1:06:09<29:19:20, 19.65s/it]\rRequesting API:   1%|          | 63/5435 [1:06:16<23:50:56, 15.98s/it]\rRequesting API:   1%|          | 64/5435 [1:06:32<23:52:53, 16.01s/it]\rRequesting API:   1%|          | 65/5435 [1:06:54<26:43:15, 17.91s/it]\rRequesting API:   1%|          | 66/5435 [1:07:11<26:09:20, 17.54s/it]\rRequesting API:   1%|          | 67/5435 [1:07:19<21:48:48, 14.63s/it]\rRequesting API:   1%|▏         | 68/5435 [1:08:09<37:46:57, 25.34s/it]\rRequesting API:   1%|▏         | 69/5435 [1:08:42<41:06:45, 27.58s/it]\rRequesting API:   1%|▏         | 70/5435 [1:09:01<37:17:44, 25.03s/it]\rRequesting API:   1%|▏         | 71/5435 [1:09:18<33:41:44, 22.61s/it]\rRequesting API:   1%|▏         | 72/5435 [1:09:54<39:46:24, 26.70s/it]\rRequesting API:   1%|▏         | 73/5435 [1:10:11<35:15:55, 23.68s/it]\rRequesting API:   1%|▏         | 74/5435 [1:10:54<43:47:04, 29.40s/it]\rRequesting API:   1%|▏         | 75/5435 [1:10:59<33:03:45, 22.21s/it]\rRequesting API:   1%|▏         | 76/5435 [1:11:29<36:37:36, 24.60s/it]\rRequesting API:   1%|▏         | 77/5435 [1:11:41<30:50:02, 20.72s/it]\rRequesting API:   1%|▏         | 78/5435 [1:12:04<31:43:33, 21.32s/it]\rRequesting API:   1%|▏         | 79/5435 [1:12:23<30:50:36, 20.73s/it]\rRequesting API:   1%|▏         | 80/5435 [1:12:46<31:40:35, 21.30s/it]\rRequesting API:   1%|▏         | 81/5435 [1:13:35<44:19:14, 29.80s/it]\rRequesting API:   2%|▏         | 82/5435 [1:13:39<32:41:17, 21.98s/it]\rRequesting API:   2%|▏         | 83/5435 [1:13:42<24:08:38, 16.24s/it]\rRequesting API:   2%|▏         | 84/5435 [1:14:23<35:07:24, 23.63s/it]\rRequesting API:   2%|▏         | 85/5435 [1:14:26<25:46:39, 17.35s/it]\rRequesting API:   2%|▏         | 86/5435 [1:14:31<20:30:53, 13.81s/it]\rRequesting API:   2%|▏         | 87/5435 [1:14:58<26:16:29, 17.69s/it]\rRequesting API:   2%|▏         | 88/5435 [1:15:03<20:44:21, 13.96s/it]\rRequesting API:   2%|▏         | 89/5435 [1:15:21<22:27:29, 15.12s/it]\rRequesting API:   2%|▏         | 90/5435 [1:15:30<19:54:54, 13.41s/it]\rRequesting API:   2%|▏         | 91/5435 [1:15:31<14:22:27,  9.68s/it]\rRequesting API:   2%|▏         | 92/5435 [1:15:57<21:41:21, 14.61s/it]\rRequesting API:   2%|▏         | 93/5435 [1:16:36<32:28:07, 21.88s/it]\rRequesting API:   2%|▏         | 94/5435 [1:17:12<38:30:30, 25.96s/it]\rRequesting API:   2%|▏         | 95/5435 [1:17:13<27:19:32, 18.42s/it]\rRequesting API:   2%|▏         | 96/5435 [1:17:29<26:32:24, 17.90s/it]\rRequesting API:   2%|▏         | 97/5435 [1:17:50<27:44:17, 18.71s/it]\rRequesting API:   2%|▏         | 98/5435 [1:18:20<32:40:01, 22.04s/it]\rRequesting API:   2%|▏         | 99/5435 [1:18:57<39:37:57, 26.74s/it]\rRequesting API:   2%|▏         | 100/5435 [1:20:08<59:18:19, 40.02s/it]\rRequesting API:   2%|▏         | 101/5435 [1:20:21<47:01:27, 31.74s/it]\rRequesting API:   2%|▏         | 102/5435 [1:20:34<38:50:58, 26.23s/it]\rRequesting API:   2%|▏         | 103/5435 [1:20:44<31:37:48, 21.36s/it]\rRequesting API:   2%|▏         | 104/5435 [1:21:27<41:05:28, 27.75s/it]\rRequesting API:   2%|▏         | 105/5435 [1:22:04<45:26:41, 30.69s/it]\rRequesting API:   2%|▏         | 106/5435 [1:22:24<40:36:23, 27.43s/it]\rRequesting API:   2%|▏         | 107/5435 [1:22:51<40:30:00, 27.37s/it]\rRequesting API:   2%|▏         | 108/5435 [1:22:55<29:53:30, 20.20s/it]\rRequesting API:   2%|▏         | 109/5435 [1:23:34<38:29:15, 26.02s/it]\rRequesting API:   2%|▏         | 110/5435 [1:23:54<35:49:04, 24.21s/it]\rRequesting API:   2%|▏         | 111/5435 [1:23:57<26:17:46, 17.78s/it]\rRequesting API:   2%|▏         | 112/5435 [1:24:24<30:22:22, 20.54s/it]\rRequesting API:   2%|▏         | 113/5435 [1:25:11<42:12:43, 28.55s/it]', 'page': {'current': 29, 'total': 29}, 'err_code': 0}
INFO:     100.64.161.207:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.741610738255034, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.208:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': 'ves ahead with Jessie in his car. Understanding it to be a distraction, the trio instead heads inside and is followed by a squad of WF soldiers. Jessie\\\'s nerve and photography skills improve as she becomes desensitized to violence. Jessie explores a nearby car wash, where she finds the men torturing two alleged looters. They are caught in a sniper battle amid the remains of a Christmas fair. Against Sammyâ€™s objection, the other three attempt to negotiate their release, but the leader of the militia executes both Bohai and Tony for not being American. Advancing through the largely-abandoned building and against the few remaining Secret Service agents, they shoot a negotiator who is requesting the president\\\'s safe passage. The trio embeds itself with the WF as they assault Washington, D. undefended beside fanatical remnants of the armed forces and Secret Service. A civil war has engulfed the United States, fought between the federal government led by a third-term president and secessionist movements. C. C. , where Jessie repeatedly exposes herself during fighting to capture photographs, while Lee struggles with combat fatigue. Jessie unemotionally continues into the Oval Office, watching soldiers drag the president from under his desk and prepare to execute him summarily. Continuing, the group spends the night at a refugee camp before passing through a small town where, under watchful guard, residents attempt to live in blissful ignorance. Nearby snipers mock Joel\\\'s questioning what side they are on, instead displaying a cynical kill-or-be-killed attitude. Lee recognizes Jessie\\\'s potential as a war-photographer and begins to mentor her, while Jessie photographs the militia executing loyalist prisoners. The others are saved by Sammy after he rams the group\\\'s truck into members of the militia, but he is mortally wounded during the escape and dies. After the WF breach the White House\\\'s fortified perimeter, the presidential limousine attempts to flee but is quickly intercepted and its occupants (which do not include the president) killed. While trying to dissuade them from heading to the capital, Sammy joins them so that he can reach the frontline at Charlottesville, Virginia. The next morning, Lee finds that Joel has allowed a young aspiring photojournalist who Lee encountered at the bombing, Jessie Cullen, to join them. Joel momentarily stops them to get a quote from the president, who replies, \\\'Don\\\'t let them kill me\\\'. Joel drunkenly lashes out at what he views as Sammy\\\'s pointless death; Lee tells Jessie that Sammy died while doing what he wanted. After departing the city, the group stops at a gas station that is protected by armed men. One of the guards follows Jessie, but Lee defuses the situation by taking a photo of the man posing with his victims. Jessie steps into the line of fire while taking photos, as Lee sees imminent danger, intercedes and takes a fatal gun shot; Jessie photographs Lee\\\'s death as she pushes Jessie to safety. The others catch up to find the pair held at gunpoint by unknown uniformed militia who are burying bodies in a mass grave. C. Later, Jessie berates herself for being too scared to take photos. Following an overnight stop near ongoing fighting, the group documents combat the next day as secessionist militiamen assault a loyalist-held building. While driving, the four encounter two Hongkonger reporters who they know, Tony and Bohai. Joel learns from Lee\\\'s British reporter friend Anya that most remaining loyalists have surrendered, leaving D. Lee deletes a photo that she took of his body."}]\'),), gen_kwargs is {\'until\': [\'</s>\'], \'do_sample\': False, \'temperature\': 0.0, \'max_gen_toks\': 28000}\n2026-01-03:15:50:59 INFO     [models.api_models:362] model_call timeout 3600\n', 'page': {'current': 5030, 'total': 5030}, 'err_code': 0}
INFO:     100.64.134.200:2053 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.741610738255034, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.163.210:2060 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': 'ng captured and taken to their prison. The base crew, distracted by a March Madness game, dismisses Kinney\\\'s call and redirects him to Grimm\\\'s private phone. Captain Eddie ‘Reaper’ Grimm, a US Air Force drone pilot, supported by Staff Sergeant Nia Branson, provides air support from a Reaper to a US Army Delta Force team sent to rescue a CIA spy in the southern Philippines. Using Sweet\\\'s radio, Kinney contacts Grimm, who schedules three bombings to hit the base, each 15 minutes apart, before Grimm and Branson are forced by their superiors to take a leave for having exceeded their shift. Grimm does not answer, being in a call with his very pregnant wife while grocery shopping, so Kinney leaves a voice mail, and leaves seeking the other prisoners. Sweet is executed right as the first superficial bombing hits, and Kinney is taken to be tortured, where the rebel leader does not believe his warning about the upcoming bombings. As no one answers, Grimm is forced to rush to the control room and order the B-1 Lancer pilot to abort the bombing, right as it flies in front of Kinney, Bishop, and the CIA agent reaching the cave\\\'s entrance. Once Kinney arrives, he is intercepted by the Abu Sayyaf, depleting the ammunition of Grimm\\\'s drone (consisting of AGM-114 Hellfire and BLU-118 rockets) and forcing the endangered extraction helicopter to leave. When the bombs hit, Kinney survives due to having been dunked in a water tub, while his captors are caught in the flames. Returning to Bishop and searching for a way out, they also find the CIA operative, whom Grimm and Branson had been lied to that he was found elsewhere by another agency\\\'s operation. Afterwards he convenes with Branson in a hangar, where she asks him to walk her down the aisle in her wedding, and he agrees and leads her in a dance. Kinney grabs a machete and kills the surviving leader, taking his satellite phone and calling Nellis Air Force Base for Grimm to call off the third bombing, before the battery runs out. As the soldiers are finally extracted in the Philippines, Grimm complains to the rest of the base crew and his superiors that three men nearly died because they were too distracted to hear their calls, despite being repeatedly asked to pay attention to the phone because of his pregnant wife, and he smashes the break room\\\'s main television in anger. Trying to reach another extraction point, Kinney falls down a hill and loses his rifle, runs out of ammunition for his pistol, and then gets captured."}]\'),), gen_kwargs is {\'until\': [\'</s>\'], \'do_sample\': False, \'temperature\': 0.0, \'max_gen_toks\': 28000}\n2026-01-03:15:52:58 INFO     [models.api_models:362] model_call timeout 3600\n', 'page': {'current': 5033, 'total': 5033}, 'err_code': 0}
INFO:     100.67.175.205:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.209:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'ng API:   1%|          | 32/5435 [48:53<105:09:15, 70.06s/it]\rRequesting API:   1%|          | 33/5435 [51:06<133:20:53, 88.87s/it]\rRequesting API:   1%|          | 34/5435 [54:42<190:14:34, 126.81s/it]\rRequesting API:   1%|          | 35/5435 [54:56<139:38:59, 93.10s/it] \rRequesting API:   1%|          | 36/5435 [57:41<171:52:22, 114.60s/it]\rRequesting API:   1%|          | 37/5435 [58:29<141:49:23, 94.58s/it] \rRequesting API:   1%|          | 38/5435 [58:47<107:10:42, 71.49s/it]\rRequesting API:   1%|          | 39/5435 [59:15<87:45:31, 58.55s/it] \rRequesting API:   1%|          | 40/5435 [59:56<79:50:19, 53.28s/it]\rRequesting API:   1%|          | 41/5435 [1:00:30<71:02:45, 47.42s/it]\rRequesting API:   1%|          | 42/5435 [1:00:31<50:29:15, 33.70s/it]\rRequesting API:   1%|          | 43/5435 [1:00:43<40:36:53, 27.12s/it]\rRequesting API:   1%|          | 44/5435 [1:00:52<32:27:23, 21.67s/it]\rRequesting API:   1%|          | 45/5435 [1:01:04<27:59:07, 18.69s/it]\rRequesting API:   1%|          | 46/5435 [1:01:20<26:56:10, 17.99s/it]\rRequesting API:   1%|          | 47/5435 [1:01:38<27:02:20, 18.07s/it]\rRequesting API:   1%|          | 48/5435 [1:01:56<26:53:35, 17.97s/it]\rRequesting API:   1%|          | 49/5435 [1:02:07<23:36:23, 15.78s/it]\rRequesting API:   1%|          | 50/5435 [1:02:54<37:42:15, 25.21s/it]\rRequesting API:   1%|          | 51/5435 [1:03:05<31:14:15, 20.89s/it]\rRequesting API:   1%|          | 52/5435 [1:03:13<25:40:59, 17.18s/it]\rRequesting API:   1%|          | 53/5435 [1:03:28<24:32:52, 16.42s/it]\rRequesting API:   1%|          | 54/5435 [1:03:30<18:08:48, 12.14s/it]\rRequesting API:   1%|          | 55/5435 [1:03:34<14:21:09,  9.60s/it]\rRequesting API:   1%|          | 56/5435 [1:04:12<26:59:37, 18.07s/it]\rRequesting API:   1%|          | 57/5435 [1:04:29<26:42:52, 17.88s/it]\rRequesting API:   1%|          | 58/5435 [1:04:38<22:53:11, 15.32s/it]\rRequesting API:   1%|          | 59/5435 [1:04:55<23:23:13, 15.66s/it]\rRequesting API:   1%|          | 60/5435 [1:05:17<26:21:47, 17.66s/it]\rRequesting API:   1%|          | 61/5435 [1:06:06<40:21:42, 27.04s/it]\rRequesting API:   1%|          | 62/5435 [1:06:09<29:19:20, 19.65s/it]\rRequesting API:   1%|          | 63/5435 [1:06:16<23:50:56, 15.98s/it]\rRequesting API:   1%|          | 64/5435 [1:06:32<23:52:53, 16.01s/it]\rRequesting API:   1%|          | 65/5435 [1:06:54<26:43:15, 17.91s/it]\rRequesting API:   1%|          | 66/5435 [1:07:11<26:09:20, 17.54s/it]\rRequesting API:   1%|          | 67/5435 [1:07:19<21:48:48, 14.63s/it]\rRequesting API:   1%|▏         | 68/5435 [1:08:09<37:46:57, 25.34s/it]\rRequesting API:   1%|▏         | 69/5435 [1:08:42<41:06:45, 27.58s/it]\rRequesting API:   1%|▏         | 70/5435 [1:09:01<37:17:44, 25.03s/it]\rRequesting API:   1%|▏         | 71/5435 [1:09:18<33:41:44, 22.61s/it]\rRequesting API:   1%|▏         | 72/5435 [1:09:54<39:46:24, 26.70s/it]\rRequesting API:   1%|▏         | 73/5435 [1:10:11<35:15:55, 23.68s/it]\rRequesting API:   1%|▏         | 74/5435 [1:10:54<43:47:04, 29.40s/it]\rRequesting API:   1%|▏         | 75/5435 [1:10:59<33:03:45, 22.21s/it]\rRequesting API:   1%|▏         | 76/5435 [1:11:29<36:37:36, 24.60s/it]\rRequesting API:   1%|▏         | 77/5435 [1:11:41<30:50:02, 20.72s/it]\rRequesting API:   1%|▏         | 78/5435 [1:12:04<31:43:33, 21.32s/it]\rRequesting API:   1%|▏         | 79/5435 [1:12:23<30:50:36, 20.73s/it]\rRequesting API:   1%|▏         | 80/5435 [1:12:46<31:40:35, 21.30s/it]\rRequesting API:   1%|▏         | 81/5435 [1:13:35<44:19:14, 29.80s/it]\rRequesting API:   2%|▏         | 82/5435 [1:13:39<32:41:17, 21.98s/it]\rRequesting API:   2%|▏         | 83/5435 [1:13:42<24:08:38, 16.24s/it]\rRequesting API:   2%|▏         | 84/5435 [1:14:23<35:07:24, 23.63s/it]\rRequesting API:   2%|▏         | 85/5435 [1:14:26<25:46:39, 17.35s/it]\rRequesting API:   2%|▏         | 86/5435 [1:14:31<20:30:53, 13.81s/it]\rRequesting API:   2%|▏         | 87/5435 [1:14:58<26:16:29, 17.69s/it]\rRequesting API:   2%|▏         | 88/5435 [1:15:03<20:44:21, 13.96s/it]\rRequesting API:   2%|▏         | 89/5435 [1:15:21<22:27:29, 15.12s/it]\rRequesting API:   2%|▏         | 90/5435 [1:15:30<19:54:54, 13.41s/it]\rRequesting API:   2%|▏         | 91/5435 [1:15:31<14:22:27,  9.68s/it]\rRequesting API:   2%|▏         | 92/5435 [1:15:57<21:41:21, 14.61s/it]\rRequesting API:   2%|▏         | 93/5435 [1:16:36<32:28:07, 21.88s/it]\rRequesting API:   2%|▏         | 94/5435 [1:17:12<38:30:30, 25.96s/it]\rRequesting API:   2%|▏         | 95/5435 [1:17:13<27:19:32, 18.42s/it]\rRequesting API:   2%|▏         | 96/5435 [1:17:29<26:32:24, 17.90s/it]\rRequesting API:   2%|▏         | 97/5435 [1:17:50<27:44:17, 18.71s/it]\rRequesting API:   2%|▏         | 98/5435 [1:18:20<32:40:01, 22.04s/it]\rRequesting API:   2%|▏         | 99/5435 [1:18:57<39:37:57, 26.74s/it]\rRequesting API:   2%|▏         | 100/5435 [1:20:08<59:18:19, 40.02s/it]\rRequesting API:   2%|▏         | 101/5435 [1:20:21<47:01:27, 31.74s/it]\rRequesting API:   2%|▏         | 102/5435 [1:20:34<38:50:58, 26.23s/it]\rRequesting API:   2%|▏         | 103/5435 [1:20:44<31:37:48, 21.36s/it]\rRequesting API:   2%|▏         | 104/5435 [1:21:27<41:05:28, 27.75s/it]\rRequesting API:   2%|▏         | 105/5435 [1:22:04<45:26:41, 30.69s/it]\rRequesting API:   2%|▏         | 106/5435 [1:22:24<40:36:23, 27.43s/it]\rRequesting API:   2%|▏         | 107/5435 [1:22:51<40:30:00, 27.37s/it]\rRequesting API:   2%|▏         | 108/5435 [1:22:55<29:53:30, 20.20s/it]\rRequesting API:   2%|▏         | 109/5435 [1:23:34<38:29:15, 26.02s/it]\rRequesting API:   2%|▏         | 110/5435 [1:23:54<35:49:04, 24.21s/it]\rRequesting API:   2%|▏         | 111/5435 [1:23:57<26:17:46, 17.78s/it]\rRequesting API:   2%|▏         | 112/5435 [1:24:24<30:22:22, 20.54s/it]\rRequesting API:   2%|▏         | 113/5435 [1:25:11<42:12:43, 28.55s/it]\rRequesting API:   2%|▏         | 114/5435 [1:25:35<39:46:48, 26.91s/it]\rRequesting API:   2%|▏         | 115/5435 [1:26:52<62:14:44, 42.12s/it]\rRequesting API:   2%|▏         | 116/5435 [1:27:50<69:03:48, 46.74s/it]\rRequesting API:   2%|▏         | 117/5435 [1:28:56<77:55:25, 52.75s/it]\rRequesting API:   2%|▏         | 118/5435 [1:29:44<75:29:17, 51.11s/it]\rRequesting API:   2%|▏         | 119/5435 [1:31:03<88:05:27, 59.66s/it]\rRequesting API:   2%|▏         | 120/5435 [1:31:15<66:53:15, 45.30s/it]\rRequesting API:   2%|▏         | 121/5435 [1:31:26<51:29:08, 34.88s/it]\rRequesting API:   2%|▏         | 122/5435 [1:32:56<76:04:23, 51.55s/it]\rRequesting API:   2%|▏         | 123/5435 [1:35:08<111:28:57, 75.55s/it]\rRequesting API:   2%|▏         | 124/5435 [1:36:17<108:32:31, 73.57s/it]\rRequesting API:   2%|▏         | 125/5435 [1:38:23<131:50:27, 89.38s/it]\rRequesting API:   2%|▏         | 126/5435 [1:39:15<115:18:32, 78.19s/it]', 'page': {'current': 29, 'total': 29}, 'err_code': 0}
INFO:     100.67.175.208:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.173.205:2054 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.173.201:2060 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.195:2051 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://172.26.226.221:8885/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_8885' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_8885', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.26.226.221:8885/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28658, 'evaluationId': 1456}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28658, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28658, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.167.208:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-mthreads-flagos-260103 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.167.201:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
taskinfo eval_url='http://172.26.226.221:8885/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_8885' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_8885', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.26.226.221:8885/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28659, 'evaluationId': 1456}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28659, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28659, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.161.211:2052 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.198:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '\rChecking cached requests:  83%|████████▎ | 10036/12032 [00:42<00:04, 418.42it/s]\rChecking cached requests:  84%|████████▍ | 10079/12032 [00:42<00:05, 358.35it/s]\rChecking cached requests:  84%|████████▍ | 10126/12032 [00:42<00:04, 386.37it/s]\rChecking cached requests:  85%|████████▍ | 10175/12032 [00:43<00:04, 411.93it/s]\rChecking cached requests:  85%|████████▍ | 10218/12032 [00:43<00:05, 339.92it/s]\rChecking cached requests:  85%|████████▌ | 10256/12032 [00:43<00:05, 298.05it/s]\rChecking cached requests:  86%|████████▌ | 10289/12032 [00:43<00:05, 300.25it/s]\rChecking cached requests:  86%|████████▌ | 10327/12032 [00:43<00:05, 317.32it/s]\rChecking cached requests:  86%|████████▌ | 10361/12032 [00:43<00:05, 288.06it/s]\rChecking cached requests:  86%|████████▋ | 10392/12032 [00:43<00:06, 269.22it/s]\rChecking cached requests:  87%|████████▋ | 10421/12032 [00:43<00:06, 262.75it/s]\rChecking cached requests:  87%|████████▋ | 10449/12032 [00:44<00:06, 251.60it/s]\rChecking cached requests:  87%|████████▋ | 10494/12032 [00:44<00:05, 301.45it/s]\rChecking cached requests:  88%|████████▊ | 10534/12032 [00:44<00:04, 325.57it/s]\rChecking cached requests:  88%|████████▊ | 10569/12032 [00:44<00:04, 331.51it/s]\rChecking cached requests:  88%|████████▊ | 10604/12032 [00:44<00:04, 293.42it/s]\rChecking cached requests:  88%|████████▊ | 10635/12032 [00:44<00:05, 272.75it/s]\rChecking cached requests:  89%|████████▉ | 10682/12032 [00:44<00:04, 321.61it/s]\rChecking cached requests:  89%|████████▉ | 10731/12032 [00:44<00:03, 365.14it/s]\rChecking cached requests:  90%|████████▉ | 10780/12032 [00:45<00:03, 397.79it/s]\rChecking cached requests:  90%|█████████ | 10829/12032 [00:45<00:02, 421.74it/s]\rChecking cached requests:  90%|█████████ | 10878/12032 [00:45<00:02, 439.52it/s]\rChecking cached requests:  91%|█████████ | 10923/12032 [00:45<00:02, 417.91it/s]\rChecking cached requests:  91%|█████████ | 10966/12032 [00:45<00:02, 413.05it/s]\rChecking cached requests:  91%|█████████▏| 11008/12032 [00:45<00:02, 402.38it/s]\rChecking cached requests:  92%|█████████▏| 11055/12032 [00:45<00:02, 418.05it/s]\rChecking cached requests:  92%|█████████▏| 11104/12032 [00:45<00:02, 436.79it/s]\rChecking cached requests:  93%|█████████▎| 11149/12032 [00:45<00:02, 427.61it/s]\rChecking cached requests:  93%|█████████▎| 11193/12032 [00:45<00:02, 419.27it/s]\rChecking cached requests:  93%|█████████▎| 11236/12032 [00:46<00:01, 419.39it/s]\rChecking cached requests:  94%|█████████▍| 11280/12032 [00:46<00:01, 425.25it/s]\rChecking cached requests:  94%|█████████▍| 11323/12032 [00:46<00:02, 346.20it/s]\rChecking cached requests:  94%|█████████▍| 11361/12032 [00:46<00:02, 311.27it/s]\rChecking cached requests:  95%|█████████▍| 11407/12032 [00:46<00:01, 346.78it/s]\rChecking cached requests:  95%|█████████▌| 11453/12032 [00:46<00:01, 374.60it/s]\rChecking cached requests:  96%|█████████▌| 11501/12032 [00:46<00:01, 402.03it/s]\rChecking cached requests:  96%|█████████▌| 11544/12032 [00:46<00:01, 370.90it/s]\rChecking cached requests:  96%|█████████▋| 11583/12032 [00:47<00:01, 372.92it/s]\rChecking cached requests:  97%|█████████▋| 11630/12032 [00:47<00:01, 397.95it/s]\rChecking cached requests:  97%|█████████▋| 11679/12032 [00:47<00:00, 421.39it/s]\rChecking cached requests:  97%|█████████▋| 11728/12032 [00:47<00:00, 439.46it/s]\rChecking cached requests:  98%|█████████▊| 11774/12032 [00:47<00:00, 444.67it/s]\rChecking cached requests:  98%|█████████▊| 11822/12032 [00:47<00:00, 452.37it/s]\rChecking cached requests:  99%|█████████▊| 11868/12032 [00:47<00:00, 451.55it/s]\rChecking cached requests:  99%|█████████▉| 11916/12032 [00:47<00:00, 457.26it/s]\rChecking cached requests:  99%|█████████▉| 11963/12032 [00:47<00:00, 458.52it/s]\rChecking cached requests: 100%|█████████▉| 12011/12032 [00:47<00:00, 461.99it/s]\rChecking cached requests: 100%|██████████| 12032/12032 [00:48<00:00, 250.57it/s]\n2026-01-04:12:45:30 INFO     [api.model:287] Cached requests: 9044, Requests remaining: 2988\n2026-01-04:12:45:30 INFO     [models.api_models:679] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-04:12:45:30 INFO     [models.api_models:484] get_batched_requests timeout 3600\n\rRequesting API:   0%|          | 0/2988 [00:00<?, ?it/s]\rRequesting API:   0%|          | 1/2988 [00:26<22:10:14, 26.72s/it]\rRequesting API:   0%|          | 2/2988 [00:53<22:16:10, 26.85s/it]\rRequesting API:   0%|          | 3/2988 [00:59<14:19:40, 17.28s/it]\rRequesting API:   0%|          | 4/2988 [01:01<9:17:36, 11.21s/it] \rRequesting API:   0%|          | 5/2988 [01:14<9:44:32, 11.76s/it]\rRequesting API:   0%|          | 6/2988 [02:49<33:23:59, 40.32s/it]\rRequesting API:   0%|          | 7/2988 [02:51<22:54:22, 27.66s/it]\rRequesting API:   0%|          | 8/2988 [02:54<16:20:59, 19.75s/it]\rRequesting API:   0%|          | 9/2988 [03:48<25:21:01, 30.63s/it]\rRequesting API:   0%|          | 10/2988 [04:35<29:24:24, 35.55s/it]\rRequesting API:   0%|          | 11/2988 [05:18<31:09:58, 37.69s/it]\rRequesting API:   0%|          | 12/2988 [05:20<22:17:13, 26.96s/it]\rRequesting API:   0%|          | 13/2988 [05:23<16:10:47, 19.58s/it]\rRequesting API:   0%|          | 14/2988 [06:45<31:53:54, 38.61s/it]\rRequesting API:   1%|          | 15/2988 [08:02<41:23:49, 50.13s/it]\rRequesting API:   1%|          | 16/2988 [08:06<29:54:00, 36.22s/it]\rRequesting API:   1%|          | 17/2988 [09:50<46:40:09, 56.55s/it]\rRequesting API:   1%|          | 18/2988 [09:53<33:33:03, 40.67s/it]\rRequesting API:   1%|          | 19/2988 [10:39<34:52:03, 42.28s/it]\rRequesting API:   1%|          | 20/2988 [10:41<24:43:07, 29.98s/it]\rRequesting API:   1%|          | 21/2988 [12:48<48:40:48, 59.07s/it]\rRequesting API:   1%|          | 22/2988 [14:30<59:20:55, 72.03s/it]\rRequesting API:   1%|          | 23/2988 [15:36<57:50:20, 70.23s/it]\rRequesting API:   1%|          | 24/2988 [16:37<55:35:31, 67.52s/it]\rRequesting API:   1%|          | 25/2988 [17:20<49:27:09, 60.08s/it]', 'page': {'current': 29, 'total': 29}, 'err_code': 0}
INFO:     100.64.72.204:2051 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.741610738255034, 'rawDetails': {}}, {'status': 'R', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.161.203:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 2, 'finishedDataset': 2, 'runningDataset': '', 'runningProgress': 'the constraints and deduce the attributes of each of the three individuals in the line, numbered from left to right as positions 1, 2, and 3.\\n\\n---\\n\\n### Step-by-Step Deduction\\n\\n#### **Step 1: Music Genre Constraints**\\n\\n- **Premise 2**: The person who listens to **pop** is not anywhere to the right of the person who listens to **electronic**.  \\n  → This implies **pop is to the left of electronic**.\\n\\n- **Premise 3**: The person with a **dog** is not anywhere to the left of the person who listens to **electronic**.  \\n  → This implies **dog is to the right of electronic**.\\n\\n- **Premise 1**: The person with a **dog** is to the left of the **mexican**.  \\n  → So, **dog < mexican**.\\n\\nCombining these, we get:\\n- **pop < electronic < dog < mexican**\\n\\nSince there are only 3 positions, the only valid arrangement is:\\n- **pop in position 1**\\n- **electronic in position 2**\\n- **dog in position 2**\\n- **mexican in position 3**\\n\\nThis satisfies all three constraints.\\n\\n---\\n\\n#### **Step 2: Hiking and Pet Constraints**\\n\\n- **Premise 4**: The person who listens to **electronic** is to the right of the person who likes **hiking**.  \\n  → So, **hiking is in position 1**, and **electronic is in position 2**.\\n\\n- **Premise 5**: The person who likes **hiking** does not own a **snake**.  \\n  → So, the person in position 1 (who likes hiking) does **not** own a snake.\\n\\n- **Premise 6**: The **malaysian** is not to the right of the person who likes **hiking**.  \\n  → So, **malaysian must be in position 1** (since position 1 is the only one not to the right of position 1).\\n\\n- **Premise 7**: The person who likes **baking** is not mexican, or the mexican does not own a snake, or both.  \\n  → The mexican is in position 3, and the person in position 3 owns a **snake** (since the other two pets are already assigned: guinea-pig and dog).  \\n  → So, the **mexican does own a snake**, which makes the second part of the disjunction false.  \\n  → Therefore, the **person who likes baking must not be mexican**.  \\n  → Since the mexican is in position 3, the person who likes baking must be in **position 2**.\\n\\n---\\n\\n#### **Step 3: Assigning Hobbies**\\n\\n- Position 1: **hiking**\\n- Position 2: **baking**\\n- Position 3: **collecting** (by elimination)\\n\\n---\\n\\n### Final Assignments\\n\\n| Position | Nationality | Hobby     | Pet       | Music Genre |\\n|----------|-------------|-----------|-----------|-------------|\\n| 1        | Malaysian   | Hiking    | Guinea-pig| Pop         |\\n| 2        | Japanese    | Baking    | Dog       | Electronic |\\n| 3        | Mexican     | Collecting| Snake     | Funk        |\\n\\n---\\n\\n### Final Answer\\n\\nThe person who likes **collecting** is in **position 3**.\\n\\n$$\\n\\\\boxed{3}\\n$$\', \'tool_calls\': []}, \'logprobs\': None, \'finish_reason\': \'stop\', \'stop_reason\': None}], \'usage\': {\'prompt_tokens\': 302, \'total_tokens\': 5938, \'completion_tokens\': 5636, \'prompt_tokens_details\': None}, \'prompt_logprobs\': None, \'kv_transfer_params\': None}, use 112.63051629066467\n\rRequesting API:  99%|█████████▉| 904/910 [37:49:07<19:46, 197.83s/it]2026-01-04:13:09:51 INFO     [models.api_models:625] Tokenized requests are disabled. Context + generation length is not checked.\n2026-01-04:13:09:51 INFO     [models.api_models:630] send request info (JsonChatStr(prompt=\'[{"role": "user", "content": "There are 3 people standing in a line numbered 1 through 3 in a left to right order.\\\\nEach person has a set of attributes: Transport, Pet, Job.\\\\nThe attributes have the following possible values:\\\\n- Transport: train, jet-ski, car\\\\n- Pet: mouse, horse, lizard\\\\n- Job: dancer, lawyer, videographer\\\\nand exactly one person in the line has a given value for an attribute.\\\\n\\\\nGiven the following premises about the line of people:\\\\n- the person that has a horse is immediately between the person who is a videographer and the person that travels by jet-ski\\\\n- the person who is a videographer is somewhere to the left of the person that has a mouse\\\\n- the person that has a horse is on the immediate left or immediate right of the person that travels by car\\\\n- the person that travels by jet-ski is somewhere to the right of the person who is a lawyer\\\\n\\\\nAnswer the following question:\\\\nWhat job does the person that travels by car have? Return your answer as a single word, in the following format: ***X***, where X is the answer."}]\'),), gen_kwargs is {\'until\': [\'</s>\'], \'do_sample\': False, \'temperature\': 0.0, \'max_gen_toks\': 28000}\n2026-01-04:13:09:51 INFO     [models.api_models:362] model_call timeout 3600\n', 'page': {'current': 6417, 'total': 6417}, 'err_code': 0}
INFO:     100.64.76.203:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.203:2051 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.197:2056 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.198:2055 - "GET /login HTTP/1.1" 404 Not Found
Qwen3-Next-80B-A3B-Instruct_8885 28659 9fe19fe6-9e27-4a3a-bbc4-e39d282e6e6d
submit stop batch 28659
[{'status': 'R', 'dataset': 'CMMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.167.201:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/root/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-260104' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/root/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-260104' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-260104', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/root/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-260104', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/root/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28660,"evaluationId":1457}
{'id': 28660, 'evaluationId': 1457}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1457, 'batch_id': 28660, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.78.198:2052 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-260104 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.167.210:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-260104 28660 b2a52ac3-dcff-4275-a08f-0617467b7e70
submit stop batch 28660
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.72.202:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/nfs/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-260104' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/nfs/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-260104' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-260104', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/nfs/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-260104', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/nfs/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28661,"evaluationId":1457}
{'id': 28661, 'evaluationId': 1457}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1457, 'batch_id': 28661, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.169.205:2052 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-260104 [] R
INFO:     100.64.72.196:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-260104 28661 7d992574-e8e7-4562-b77d-3e141dbe8bfe
submit stop batch 28661
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.165.201:2050 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/nfs/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='/nfs/Qwen2.5-vl' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/nfs/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': '/nfs/Qwen2.5-vl', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28662,"evaluationId":1458}
{'id': 28662, 'evaluationId': 1458}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1458, 'batch_id': 28662, 'datasize': 22301}
mysql connect
insert success
INFO:     100.67.171.206:2051 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.151.193:2059 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.74.193:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.173.195:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.151.201:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.163.209:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.76.195:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.134.205:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.134.199:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.72.194:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-26010402 28662 64c621d8-3244-4031-8084-fe0199d67223
submit stop batch 28662
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.134.195:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.64.76.199:2049 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-mthreads-flagos-260103 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.134.199:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-mthreads-flagos-260103 [{'status': 'R', 'dataset': 'AIME', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'GPQA', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'LiveBench', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.74.205:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010402' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010402', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28663,"evaluationId":1458}
{'id': 28663, 'evaluationId': 1458}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1458, 'batch_id': 28663, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.161.211:2053 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.161.196:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.167.195:2059 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.161.210:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.175.199:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.64.165.194:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010402 [] R
INFO:     100.67.167.197:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-26010402 28663 ba80636b-04a9-4869-85f8-d760c131d55e
submit stop batch 28663
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.78.194:2051 - "POST /stop_evaluation HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-26010402 28662 64c621d8-3244-4031-8084-fe0199d67223
submit stop batch 28662
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 0
INFO:     100.67.151.201:2053 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28664,"evaluationId":1459}
{'id': 28664, 'evaluationId': 1459}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1459, 'batch_id': 28664, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.74.207:2052 - "POST /evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.64.72.210:2054 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010403 [] R
INFO:     100.67.171.201:2054 - "GET /evaldiffs HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010403' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010403', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"detail":"A job is still running"}
tasks {'err_code': 1, 'err_msg': 'A job is still running'}
INFO:     100.64.74.196:2053 - "POST /evaluation HTTP/1.1" 200 OK
qwen2-5-vl-mx-flagos-26010403 28664 807a61a0-60cd-44b4-8165-5e53854ae524
submit stop batch 28664
[{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.161.200:2048 - "POST /stop_evaluation HTTP/1.1" 200 OK
INFO:     100.67.175.200:2052 - "GET / HTTP/1.1" 404 Not Found
get a new request
taskinfo eval_url='http://172.24.178.148:8885/v1/chat/completions' model='/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct' eval_model='Qwen3-Next-80B-A3B-Instruct_8885' base_model_name='Qwen3-Next-80B-A3B-Instruct' tokenizer='Qwen/Qwen3-Next-80B-A3B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=1 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
{'user_id': 0, 'model_type': '', 'tokenizer': {'tokenizer_name': 'Qwen/Qwen3-Next-80B-A3B-Instruct'}, 'gpus_queue_id': 'uuid', 'sence': 'EA', 'model_id': 'Qwen3-Next-80B-A3B-Instruct_8885', 'online_model_name': '/share/project/ldwang/WorkSpace/models/Qwen3-Next-80B-A3B-Instruct', 'base_model_name': 'Qwen3-Next-80B-A3B-Instruct', 'online_url': 'http://172.24.178.148:8885/v1/chat/completions', 'online_api_key': 'EMPTY', 'dataset': ['lm_eval-mmlu', 'lm_eval-cmmlu'], 'batch_size': 1, 'num_concurrent': 1, 'num_retry': 10, 'max_gen_toks': -1, 'gen_kwargs': '', 'joint_region': 'sz', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
{'id': 28665, 'evaluationId': 1456}
{'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28665, 'datasize': 14920}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1456, 'batch_id': 28665, 'datasize': 14920}
mysql connect
insert success
INFO:     100.64.74.202:2050 - "POST /evaluation HTTP/1.1" 200 OK
Qwen3-Next-80B-A3B-Instruct_8885 28665 78736864-42ec-48d7-a3bb-d65b2c0465fe
submit stop batch 28665
[] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.67.151.211:2052 - "POST /stop_evaluation HTTP/1.1" 200 OK
get a new request
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010405' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.4:9010/v1/chat/completions' model='qwenvl32-nv-flagos' eval_model='qwen2-5-vl-mx-flagos-26010405' base_model_name='qwenvl_32_instruct' tokenizer='Qwen/Qwen2.5-VL-32B-Instruct' api_key='EMPTY' batch_size=1 num_concurrent=20 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010405', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': 'qwen2-5-vl-mx-flagos-26010405', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.4:9010/v1/chat/completions', 'online_model_name': 'qwenvl32-nv-flagos', 'base_model_name': 'qwenvl_32_instruct', 'batch_size': 1, 'num_concurrent': 20, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28666,"evaluationId":1460}
{'id': 28666, 'evaluationId': 1460}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1460, 'batch_id': 28666, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.167.199:2050 - "POST /evaluation HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.167.207:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.165.203:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.169.210:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.167.201:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.72.195:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.67.151.203:2055 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.161.205:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.165.196:2051 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.64.74.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [] R
INFO:     100.67.171.209:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.161.212:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
eval_model details status
qwen2-5-vl-mx-flagos-26010405 [{'status': 'R', 'dataset': 'CMMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_standard', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMMU_Pro_vision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MM-Vet v2', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'OCRBench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'MathVision', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'CII-Bench', 'accuracy': '', 'rawDetails': {}}, {'status': 'R', 'dataset': 'Blink', 'accuracy': '', 'rawDetails': {}}] R
INFO:     100.64.134.204:2050 - "GET /evaldiffs HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.204:2055 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.200:2056 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.161.207:2053 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.169.203:2055 - "POST /sdk HTTP/1.1" 404 Not Found
INFO:     100.67.161.197:2051 - "HEAD / HTTP/1.1" 404 Not Found
INFO:     100.67.173.206:2054 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.161.200:2057 - "GET /nmaplowercheck1767581330 HTTP/1.1" 404 Not Found
INFO:     100.67.173.200:2053 - "GET /evox/about HTTP/1.1" 404 Not Found
INFO:     100.67.161.203:2051 - "GET /HNAP1 HTTP/1.1" 404 Not Found
INFO:     100.67.171.202:2054 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.175.193:2056 - "GET / HTTP/1.0" 404 Not Found
INFO:     100.67.175.196:2054 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] OOR
INFO:     100.67.163.202:2056 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.78.193:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8B-cambricon-flagos-1231-001 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 48.741610738255034, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.917807002723386, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.72.205:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': 'nd inclusive styles of management, and have few (if any) levels of management between the workers and managers.  The answer is (A).\\\\n\\\\nQuestion:\\\\nAlthough the content and quality can be as controlled as direct mail, response rates of this medium are lower because of the lack of a personal address mechanism. This media format is known as:\\\\nOptions:\\\\nA. Online banners.\\\\nB. Television advertising.\\\\nC. Email marketing.\\\\nD. Care lines.\\\\nE. Direct mail.\\\\nF. Inserts.\\\\nG. Door to door.\\\\nH. Radio advertising.\\\\nI. Billboards.\\\\nJ. Social media advertising.\\\\nAnswer: Let\\\'s think step by step.  We refer to Wikipedia articles on marketing for help. Door to door marketing delivers non-addressed items within all buildings within a geographic area. While it can control the content and quality as well as direct mail marketing, its response rate is lower because of the lack of a personal address mechanism. The answer is (G).\\\\n\\\\nQuestion:\\\\nIn an organization, the group of people tasked with buying decisions is referred to as the _______________.\\\\nOptions:\\\\nA. Procurement centre.\\\\nB. Chief executive unit.\\\\nC. Resources allocation group.\\\\nD. Marketing department.\\\\nE. Purchasing department.\\\\nF. Supply chain management team.\\\\nG. Outsourcing unit.\\\\nH. Decision-making unit.\\\\nI. Operations unit.\\\\nJ. Financial management team.\\\\nAnswer: Let\\\'s think step by step.  We refer to Wikipedia articles on marketing for help. In an organization, the group of the people tasked with buying decision is referred to as the decision-making unit. The answer is (H).\\\\n\\\\nQuestion:\\\\nEdward\\\'s Electronics had a March 1 inventory of $42,000, with a planned inventory of $36,000 for March 31. The store plans sales for the month of $22,000, with an additional $2,000 in planned markdowns. The store already has a $6,000 commitment to purchase inventory during the month. What is the store\\\'s open-to-buy?\\\\nOptions:\\\\nA. $30,000\\\\nB. $6,000\\\\nC. $14,000\\\\nD. $48,000\\\\nE. $8,000\\\\nF. $60,000\\\\nG. $18,000\\\\nH. $12,000\\\\nI. $20,000\\\\nJ. $10,000\\\\nAnswer: Let\\\'s think step by step."}]\'),), gen_kwargs is {\'until\': [\'</s>\'], \'do_sample\': False, \'temperature\': 0.0, \'max_gen_toks\': 28000}\n2026-01-05:11:31:00 INFO     [models.api_models:362] model_call timeout 3600\n', 'page': {'current': 8560, 'total': 8560}, 'err_code': 0}
INFO:     100.67.149.205:2053 - "POST /evaluation_progress HTTP/1.1" 200 OK
INFO:     100.67.163.203:2052 - "GET / HTTP/1.1" 404 Not Found
batchresumption 28612 qwen3-8b-hygon-flagos-1229-01 /root/Qwen3-8B http://10.1.15.95:8004/v1/chat/completions Qwen/Qwen3-8B EMPTY 1 10 10 -1 mtemperature=0.6,top_k=20,top_p=0.95 FlagRelease bj 0
[{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] <class 'list'> <class 'str'>
更新成功，影响行数: 1
INFO:     100.64.74.197:2051 - "POST /resume_evaluation HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'F', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'C', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.78.212:2049 - "GET /evaldiffs HTTP/1.1" 200 OK
INFO:     100.64.134.196:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.161.200:2058 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': "-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n+ sed -i -e 's;/home/qinbowen/lm-evaluation-harness-flageval/lm_eval/tasks/s8/s8.json;/share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/s8.json;' /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/s8/_template_yaml.yaml\n+ ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/livebench /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/livebench&& ln -sf /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19/musr_generative /root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/lm_eval/tasks/musr_generative\n/root/online_third_party/env/venv.28612-lmeval/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2026-01-05:13:36:17 INFO     [__main__:338] Including path: /share/project/f6a24c02-4c11-46d6-a12f-cc1f09d71df1/2025-02-19\n2026-01-05:13:36:18 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2026-01-05:13:36:19 INFO     [tasks:476] The tag 'TheoremQA' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n2026-01-05:13:36:19 INFO     [__main__:422] Selected Tasks: ['mmlu_pro']\n2026-01-05:13:36:19 INFO     [evaluator:180] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n2026-01-05:13:36:19 WARNING  [evaluator:192] generation_kwargs: {'mtemperature': 0.6, 'top_k': 20, 'top_p': 0.95} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!\n2026-01-05:13:36:19 INFO     [evaluator:218] Initializing openai-chat-completions model, with arguments: {'model': '/root/Qwen3-8B', 'base_url': 'http://10.1.15.95:8004/v1/chat/completions', 'num_concurrent': 10, 're_try': 10}\n2026-01-05:13:36:19 WARNING  [models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.\n2026-01-05:13:36:19 INFO     [models.api_models:116] Using max length 2048 - 1\n2026-01-05:13:36:19 INFO     [models.api_models:134] Using tokenizer None\n2026-01-05:13:36:19 INFO     [evaluator:238] Using cache at /share/project/flageval/eval_caches//root/Qwen3-8B/mmlu_pro_rank0.db\n", 'page': {'current': 23, 'total': 23}, 'err_code': 0}
INFO:     100.64.169.205:2052 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.209:2053 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '\rRequesting API:   0%|          | 3/1436 [00:47<6:07:44, 15.40s/it]\rRequesting API:   0%|          | 5/1436 [01:16<5:57:56, 15.01s/it]\rRequesting API:   0%|          | 6/1436 [01:27<5:26:02, 13.68s/it]', 'page': {'current': 30, 'total': 30}, 'err_code': 0}
INFO:     100.64.165.205:2049 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.169.202:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '\rRequesting API:   0%|          | 3/1436 [00:47<6:07:44, 15.40s/it]\rRequesting API:   0%|          | 5/1436 [01:16<5:57:56, 15.01s/it]\rRequesting API:   0%|          | 6/1436 [01:27<5:26:02, 13.68s/it]\rRequesting API:   0%|          | 7/1436 [01:47<6:08:57, 15.49s/it]\rRequesting API:   1%|          | 8/1436 [02:09<6:53:18, 17.37s/it]\rRequesting API:   1%|          | 9/1436 [02:12<5:16:19, 13.30s/it]\rRequesting API:   1%|          | 10/1436 [02:33<6:12:28, 15.67s/it]\rRequesting API:   1%|          | 11/1436 [02:44<5:37:25, 14.21s/it]\rRequesting API:   1%|          | 12/1436 [03:25<8:45:48, 22.16s/it]\rRequesting API:   1%|          | 13/1436 [03:34<7:13:52, 18.29s/it]', 'page': {'current': 30, 'total': 30}, 'err_code': 0}
INFO:     100.67.171.202:2055 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.64.165.206:2048 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '\rRequesting API:   0%|          | 3/1436 [00:47<6:07:44, 15.40s/it]\rRequesting API:   0%|          | 5/1436 [01:16<5:57:56, 15.01s/it]\rRequesting API:   0%|          | 6/1436 [01:27<5:26:02, 13.68s/it]\rRequesting API:   0%|          | 7/1436 [01:47<6:08:57, 15.49s/it]\rRequesting API:   1%|          | 8/1436 [02:09<6:53:18, 17.37s/it]\rRequesting API:   1%|          | 9/1436 [02:12<5:16:19, 13.30s/it]\rRequesting API:   1%|          | 10/1436 [02:33<6:12:28, 15.67s/it]\rRequesting API:   1%|          | 11/1436 [02:44<5:37:25, 14.21s/it]\rRequesting API:   1%|          | 12/1436 [03:25<8:45:48, 22.16s/it]\rRequesting API:   1%|          | 13/1436 [03:34<7:13:52, 18.29s/it]\rRequesting API:   1%|          | 14/1436 [03:50<6:54:31, 17.49s/it]\rRequesting API:   1%|          | 15/1436 [04:00<6:01:37, 15.27s/it]\rRequesting API:   1%|          | 16/1436 [04:10<5:22:34, 13.63s/it]\rRequesting API:   1%|          | 17/1436 [04:12<3:59:06, 10.11s/it]\rRequesting API:   1%|▏         | 18/1436 [04:40<6:07:19, 15.54s/it]\rRequesting API:   1%|▏         | 19/1436 [05:11<7:59:23, 20.30s/it]\rRequesting API:   1%|▏         | 20/1436 [05:20<6:35:26, 16.76s/it]\rRequesting API:   1%|▏         | 21/1436 [05:35<6:22:34, 16.22s/it]\rRequesting API:   2%|▏         | 22/1436 [05:55<6:54:04, 17.57s/it]\rRequesting API:   2%|▏         | 23/1436 [06:01<5:29:57, 14.01s/it]\rRequesting API:   2%|▏         | 24/1436 [06:09<4:49:06, 12.29s/it]\rRequesting API:   2%|▏         | 25/1436 [06:13<3:47:23,  9.67s/it]\rRequesting API:   2%|▏         | 26/1436 [06:16<2:57:40,  7.56s/it]', 'page': {'current': 30, 'total': 30}, 'err_code': 0}
INFO:     100.64.72.193:2050 - "POST /evaluation_progress HTTP/1.1" 200 OK
eval_model details status
qwen3-8b-hygon-flagos-1229-01 [{'status': 'S', 'dataset': 'AIME', 'accuracy': 73.33333333333333, 'rawDetails': {}}, {'status': 'S', 'dataset': 'GPQA', 'accuracy': 51.42617449664429, 'rawDetails': {}}, {'status': 'S', 'dataset': 'LiveBench', 'accuracy': 48.692650747047125, 'rawDetails': {}}, {'status': 'R', 'dataset': 'MMLU', 'accuracy': None, 'rawDetails': {}}, {'status': 'P', 'dataset': 'MuSR', 'accuracy': None, 'rawDetails': {}}] R
INFO:     100.67.173.197:2052 - "GET /evaldiffs HTTP/1.1" 200 OK
loginfos {'finished': True, 'totalDatasets': 3, 'finishedDataset': 3, 'runningDataset': '', 'runningProgress': '\rRequesting API:   0%|          | 3/1436 [00:47<6:07:44, 15.40s/it]\rRequesting API:   0%|          | 5/1436 [01:16<5:57:56, 15.01s/it]\rRequesting API:   0%|          | 6/1436 [01:27<5:26:02, 13.68s/it]\rRequesting API:   0%|          | 7/1436 [01:47<6:08:57, 15.49s/it]\rRequesting API:   1%|          | 8/1436 [02:09<6:53:18, 17.37s/it]\rRequesting API:   1%|          | 9/1436 [02:12<5:16:19, 13.30s/it]\rRequesting API:   1%|          | 10/1436 [02:33<6:12:28, 15.67s/it]\rRequesting API:   1%|          | 11/1436 [02:44<5:37:25, 14.21s/it]\rRequesting API:   1%|          | 12/1436 [03:25<8:45:48, 22.16s/it]\rRequesting API:   1%|          | 13/1436 [03:34<7:13:52, 18.29s/it]\rRequesting API:   1%|          | 14/1436 [03:50<6:54:31, 17.49s/it]\rRequesting API:   1%|          | 15/1436 [04:00<6:01:37, 15.27s/it]\rRequesting API:   1%|          | 16/1436 [04:10<5:22:34, 13.63s/it]\rRequesting API:   1%|          | 17/1436 [04:12<3:59:06, 10.11s/it]\rRequesting API:   1%|▏         | 18/1436 [04:40<6:07:19, 15.54s/it]\rRequesting API:   1%|▏         | 19/1436 [05:11<7:59:23, 20.30s/it]\rRequesting API:   1%|▏         | 20/1436 [05:20<6:35:26, 16.76s/it]\rRequesting API:   1%|▏         | 21/1436 [05:35<6:22:34, 16.22s/it]\rRequesting API:   2%|▏         | 22/1436 [05:55<6:54:04, 17.57s/it]\rRequesting API:   2%|▏         | 23/1436 [06:01<5:29:57, 14.01s/it]\rRequesting API:   2%|▏         | 24/1436 [06:09<4:49:06, 12.29s/it]\rRequesting API:   2%|▏         | 25/1436 [06:13<3:47:23,  9.67s/it]\rRequesting API:   2%|▏         | 26/1436 [06:16<2:57:40,  7.56s/it]\rRequesting API:   2%|▏         | 27/1436 [06:44<5:24:34, 13.82s/it]\rRequesting API:   2%|▏         | 28/1436 [06:51<4:33:38, 11.66s/it]\rRequesting API:   2%|▏         | 29/1436 [07:04<4:43:44, 12.10s/it]\rRequesting API:   2%|▏         | 30/1436 [07:19<5:03:09, 12.94s/it]\rRequesting API:   2%|▏         | 31/1436 [07:19<3:35:08,  9.19s/it]\rRequesting API:   2%|▏         | 32/1436 [07:40<4:53:47, 12.56s/it]\rRequesting API:   2%|▏         | 33/1436 [07:49<4:30:54, 11.59s/it]\rRequesting API:   2%|▏         | 34/1436 [08:20<6:47:39, 17.45s/it]\rRequesting API:   2%|▏         | 35/1436 [08:47<7:52:49, 20.25s/it]', 'page': {'current': 30, 'total': 30}, 'err_code': 0}
INFO:     100.64.169.203:2048 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.149.194:2050 - "GET / HTTP/1.1" 404 Not Found
WARNING:  Invalid HTTP request received.
WARNING:  Invalid HTTP request received.
INFO:     100.67.169.206:2056 - "GET /security.txt HTTP/1.1" 404 Not Found
INFO:     100.64.165.194:2052 - "POST /evaluation HTTP/1.1" 422 Unprocessable Entity
get a new request
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='/nfs/hcr/models/BAAI/RoboBrain2.0-3B' eval_model='/nfs/hcr/models/BAAI/RoboBrain2.0-3B' base_model_name='BAAI/RoboBrain2.0-3B' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
eval_url='http://10.1.15.124:9010/v1/chat/completions' model='/nfs/hcr/models/BAAI/RoboBrain2.0-3B' eval_model='/nfs/hcr/models/BAAI/RoboBrain2.0-3B' base_model_name='BAAI/RoboBrain2.0-3B' tokenizer='BAAI/RoboBrain2.0-3B' api_key='EMPTY' batch_size=8 num_concurrent=4 num_retry=10 max_gen_toks=-1 gen_kwargs='' thinking=False retry_time=-1 chip='Nvidia-H100'
FlagRelease ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2']
{'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': '/nfs/hcr/models/BAAI/RoboBrain2.0-3B', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': '/nfs/hcr/models/BAAI/RoboBrain2.0-3B', 'base_model_name': 'BAAI/RoboBrain2.0-3B', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}} <class 'dict'>
submit mm evaluation {'user_id': 0, 'require_gpus': 0, 'priority': 'high', 'gpus_queue_id': 'uuid', 'hfUserId': None, 'modelId': '/nfs/hcr/models/BAAI/RoboBrain2.0-3B', 'online_api_key': 'EMPTY', 'online_url': 'http://10.1.15.124:9010/v1/chat/completions', 'online_model_name': '/nfs/hcr/models/BAAI/RoboBrain2.0-3B', 'base_model_name': 'BAAI/RoboBrain2.0-3B', 'batch_size': 8, 'num_concurrent': 4, 'num_retry': 10, 'mmdataset': ['MMMU', 'CMMMU', 'MMMU_Pro_standard', 'MMMU_Pro_vision', 'OCRBench', 'MathVision', 'CII-Bench', 'Blink', 'MM-Vet v2'], 'joint_region': 'bj', 'special_event': 'Chips', 'special_event_meta': {'chip': 'Nvidia-H100'}, 'retry_time': 3600}
submit_evaluation response {"id":28667,"evaluationId":1461}
{'id': 28667, 'evaluationId': 1461}
tasks {'err_code': 0, 'err_msg': 'New evaluation is created', 'eval_id': 1461, 'batch_id': 28667, 'datasize': 22301}
mysql connect
insert success
INFO:     100.64.169.207:2049 - "POST /evaluation HTTP/1.1" 200 OK
INFO:     100.64.169.198:2054 - "POST /evaluation_progress HTTP/1.1" 200 OK
WARNING:  Invalid HTTP request received.
INFO:     100.67.171.210:2049 - "GET / HTTP/1.1" 404 Not Found
INFO:     100.67.151.195:2056 - "GET /favicon.ico HTTP/1.1" 404 Not Found
INFO:     100.67.175.208:2053 - "GET / HTTP/1.1" 404 Not Found
